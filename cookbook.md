<!-- MarkdownTOC -->

- 1. Структуры данных и алгоритмы
	- 1.1. Распаковка последовательности в отдельные переменные
	- 1.2. Распаковка элементов из последовательностей произвольной длины
	- 1.3. Оставление N последних элементов
	- 1.4. Поиск N максимальных и минимальных элементов
	- 1.5. Имплементация очереди с приоритетом
	- 1.6. Отображение ключей на множественные значения в словаре
	- 1.7. Поддержание порядка в словарях
	- 1.8. Вычисления в словарях
	- 1.9. Поиск общих элементов в двух словарях
	- 1.10. Удаление дубликатов из последовательности с сохранением порядка элементов
	- 1.11. Присваивание имён срезам
	- 1.12. Определение наиболее часто встречающихся элементов в последовательности
	- 1.13. Сортировка списка словарей по общему ключу
	- 1.14. Сортировка объектов, не поддерживающих сравнение
	- 1.15. Группировка записей на основе полей
	- 1.16. Фильтрование элементов последовательности
	- 1.17. Извлечение подмножества из словаря
	- 1.18. Отображение имен на последовательность элементов
	- 1.19. Одновременное преобразование и сокращение данных
	- 1.20. Объединение нескольких отображений в одно
- 2. Строки и текст
	- 2.1. Разрезание строк, разделенных различными разделителями
	- 2.2. Поиск текста в начале и в конце строки
	- 2.3. Поиск строк с использованием масок оболочки (shell)
	- 2.4. Поиск совпадений и поиск текстовых паттернов
	- 2.5. Поиск и замена текста
	- 2.6. Поиск и замена текста без учета регистра
	- 2.7. Определение регулярных выражений для поиска кратчайшего совпадения
	- 2.8. Написание регулярного выражения для многострочных шаблонов
	- 2.9. Приведение текста в Unicode к стандартному представлению (нормализация)
	- 2.10. Использование символов Unicode в регулярных выражениях
	- 2.11. Убирание нежелательных символов из строк
	- 2.12. Чистка строк
	- 2.13. Выравнивание текстовых строк
	- 2.14. Объединение и конкатенация строк
	- 2.15. Интерполяция переменных в строках
	- Задача
	- 2.16. Разбивка текста на фиксированное количество колонок
	- 2.17. Работа с HTML- и XML-сущностями в тексте
	- 2.18. Токенизация текста
	- 2.19. Написание простого парсера на основе метода рекурсивного спуска
	- 2.20. Выполнение текстовых операций над байтовыми строками
- 3. Числа, даты и время
	- 3.1. Округление числовых значений
	- 3.2. Выполнение точных десятичных вычислений
	- 3.3. Форматирование чисел для вывода
	- 3.4. Работа с бинарными, восьмеричными и шестнадцатеричными целыми числами
	- 3.5. Упаковка и распаковка больших целых чисел из байтовых строк
	- 3.6. Вычисления с комплексными числами
	- 3.7. Работа с бесконечными значениями и NaN
	- 3.8. Вычисления с дробями
	- 3.9. Вычисления на больших массивах чисел
	- 3.10. Вычисления с матрицами и линейная алгебра
	- 3.11. Случайный выбор
	- 3.12. Перевод дней в секунды и другие базовые методы конвертации времени
	- 3.13. Определение даты последней пятницы
	- 3.14. Поиск диапазона дат для текущего месяца
	- 3.15. Конвертирование строк в даты и время
	- 3.16. Манипулирование датами с учётом таймзон
- 4. Итераторы и генераторы
	- 4.1. Ручное прохождение по итератору
	- 4.2. Делегирование итерации
	- 4.3. Создание новых итерационных паттернов с помощью генераторов
	- 4.4. Реализация протокола итератора
	- 4.5. Итерирование в обратном порядке
	- 4.6. Определение генератора с дополнительным состоянием
	- 4.7. Получение среза итератора
	- Задача
	- 4.9. Итерирование по всем возможным комбинациям и перестановкам
	- 4.10. Итерирование по парам «индекс-значение» последовательности
	- 4.11. Одновременное итерирование по нескольким последовательностям
	- 4.12. Интерирования по элементам, находящимся в отдельных контейнерах
	- 4.13. Создание каналов для обработки данных
	- 4.14. Превращение вложенной последовательности в плоскую
	- 4.15. Последовательное итерирование по слитым отсортированным итерируемым объектам
	- 4.16. Замена бесконечных циклов while итератором
- 5. Файлы и ввод-вывод
	- 5.1. Чтение и запись текстовых данных
	- 5.2. Перенаправление вывода в файл
	- 5.3. Вывод с другим разделителем или символом конца строки
	- 5.4. Чтение и запись бинарных данных
	- 5.5. Запись в файл, которого ещё нет
	- 5.6. Выполнение операций ввода-вывода над строками
	- 5.7. Чтение и запись сжатых файлов с данными
	- 5.8. Итерирование по записям фиксированного размера
	- 5.9. Чтение бинарных данных в изменяемый (мутабельный) буфер
	- 5.10. Отображаемые в память бинарные файлы

<!-- /MarkdownTOC -->



*Прим. перев.: Комментарии в коде не переведены сознательно, поскольку комментарии в коде всегда должны быть написаны на английском языке.*

# 1. Структуры данных и алгоритмы

Python предоставляет широкий спектр встроенных структур данных, таких как списки, множества и словари. Использовать эти структуры по большей части просто. Однако часто возникают общие вопросы, касающиеся поиска, сортировки, изменения порядка элементов и фильтрования. Цель этой главы — обсудить обычные стуктуры данных и алгоритмы. Также будет дано введение в разнообразные структуры данных из модуля *collections*.

## 1.1. Распаковка последовательности в отдельные переменные

### Проблема
У вас есть кортеж из N элементов или последовательность, которую вы хотите распаковать в коллекцию из N переменных.

### Решение
Любая последовательность (или итерируемый объект) могут быть распакованы в переменные с помощью простого присваивания. Единственное обязательное условие заключается в том, чтобы количество и структура переменных совпадали с последовательностью. Например:
``` python
>>> p = (4, 5)
>>> x, y = p
>>> x
4
>>> y
5
>>>
```

``` python
>>> data = ['ACME', 50, 91.1, (2012, 12, 21)]
>>> name, shares, price, date = data
>>> name
'ACME'
>>> date
(2012, 12, 21)
```

``` python
>>> name, shares, price, (year, mon, day) = data
>>> name
'ACME'
>>> year
2012
>>> mon
12
>>> day
21
>>>
```

При несовпадении количества элементов вы получите ошибку. Например:
``` python
>>> p = (4, 5)
>>> x, y, z = p
Traceback (most recent call last):
   File "<stdin>", line 1, in <module>
ValueError: need more than 2 values to unpack
>>>
```

### Обсуждение
Распаковка работает с любым итерируемым объектом, а не только с кортежами и списками. Это строки, файлы, итераторы и генераторы. Например:
``` python
>>> s = 'Hello'
>>> a, b, c, d, e = s
>>> a
'H'
>>> b
'e'
>>> e
'o'
>>>
```

При распаковке вы иногда можете захотеть отбраковать некоторые значения. Специального синтаксиса для этого в Python нет, но вы можете назначить «выбрасываемые» переменные. Например:
``` python
>>> data = [ 'ACME', 50, 91.1, (2012, 12, 21) ]
>>> _, shares, price, _ = data
>>> shares
50
>>> price
91.1
>>>
```

Но убедитесь, что вы уже не использовали где-то эту переменную.


## 1.2. Распаковка элементов из последовательностей произвольной длины 

### Проблема
Вам нужно распаковать N элементов из итерируемого объекта, но этот объект может содержать больше N элементов, что вызывает исключение “too many values to unpack” («слишком много значений для распаковки»).

### Решение
Для решения этой задачи могут быть использованы «выражения со звёздочкой». Предположим, например, что вы ведете учебный курс и решаете в конце семестра, что вы не будете принимать во внимание оценки за первое и последнее домашние задания, а по остальным оценкам посчитаете среднее значение. Если у вас было четыре задания, то можно просто распаковать все четыре. Но что делать, если их 24? Выражения со звёздочкой позволяют легко решить проблему:
``` python
def drop_first_last(grades):
	first, *middle, last = grades
	return avg(middle)
```

Рассмотрим еще один пример: предположим, что у вас есть записи о юзерах, которые состоят из имени и email, за которыми следует произвольное количество телефонных номеров. Вы можете распаковать записи так:
``` python
>>> record = ('Dave', 'dave@example.com', '773-555-1212', '847-555-1212')
>>> name, email, *phone_numbers = user_record
>>> name
'Dave'
>>> email
'dave@example.com'
>>> phone_numbers
['773-555-1212', '847-555-1212']
>>>
```

Стоит отметить, что переменная phone_numbers всегда будет списком, несмотря на то, сколько телефонных номеров распаковано (даже если и ни одного). Любой код, который использует phone_numbers не должен учитывать возможность, что в этой будет не список, или производить дополнительные проверки.

Переменная со звёздочкой также может быть первой в списке. Например, у вас есть последовательность значений, представляющая продажи вашей компании за последние восемь кварталов. Если вы хотите посмотреть, как последний квартал соотносится со средним значением по первым семи, вы можете сделать так:
```python
*trailing_qtrs, current_qtr = sales_record
trailing_avg = sum(trailing_qtrs) / len(trailing_qtrs)
return avg_comparison(trailing_avg, current_qtr)
```

Интерпретатор Python выдаст:
```python
>>> *trailing, current = [10, 8, 7, 1, 9, 5, 10, 3]
>>> trailing
[10, 8, 7, 1, 9, 5, 10]
>>> current
3
```

### Обсуждение
Расширенная распаковка отлично подходит для распаковки итерируемых объектов неизвестной или произвольной длины. Часто эти объекты имеют некоторые известные элементы или паттерны (например, «всё, что после элемента 1, является телефонным номером»), и распаковка со звёздочкой позволяет программисту легко использовать эти паттерны — вместо того, чтобы исполнять акробатические трюки для извлечения нужных элементов из итерируемого объекта.

Стоит отметить, что синтаксис звёздочки может быть особенно полезен при итерировании по последовательности кортежей переменной длины. Например, возможна такая последовательность кортежей с тегами:
```python
records = [
	('foo', 1, 2),
	('bar', 'hello'),
	('foo', 3, 4),
]

def do_foo(x, y):
	print('foo', x, y)

def do_bar(s):
	print('bar', s)

for tag, *args in records:
	if tag == 'foo':
		do_foo(*args)
	elif tag == 'bar':
		do_bar(*args)
```

Распаковка со звёздочкой также может быть полезна в комбинации с операциями обработки строк, такими как разрезание. Например:
```python
>>> line = 'nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false'
>>> uname, *fields, homedir, sh = line.split(':')
>>> uname
'nobody'
>>> homedir
'/var/empty'
>>> sh
'/usr/bin/false'
>>>
```

Иногда вам может быть нужно распаковать значения и выбросить их. Вы не можете просто определить голую \* при распаковке, но вы можете использовать обычное для выбрасывания имя переменной, такое как _ или ign (ignored). Например:
```python
>>> record = ('ACME', 50, 123.45, (12, 18, 2012))
>>> name, *_, (*_, year) = record
>>> name
'ACME'
>>> year
2012
>>>
```

Есть некоторая схожесть между распаковкой со звёздочкой и обработкой списков в функциональных языках. Например, если у вас есть список, то вы можете легко разделить его на «хвост» и «голову»:
```python
>>> items = [1, 10, 7, 4, 5, 9]
>>> head, *tail = items
>>> head
1
>>> tail
[10, 7, 4, 5, 9]
>>>
```

Можно представить себе функцию, которая произведет такое разрезание с помощью хитрого рекурсивного алгоритма. Например:
```python
>>> def sum(items):
...   head, *tail = items
...   return head + sum(tail) if tail else head
...
>>> sum(items)
36
>>>
```

Однако вам следует знать, что рекурсия не относится к числу сильных сторон Python из-за внутреннего лимита на рекурсию. Поэтому последний пример на практике оказывается просто любопытным предметом для размышления.


## 1.3. Оставление N последних элементов
### Задача
Вы хотите хранить ограниченную историю из нескольких последних элементов, полученных в ходе итерации или какого-то другого процесса обработки данных.

### Решение 
Хранение ограниченной истории — отличный повод применить *collections.deque*. Например, следующий отрывок кода производит простое сопоставление текста с последовательностью строк и при совпадении выдает совпадающие строки вместе с N предыдущими строками контекста:
```python
from collections import deque
def search(lines, pattern, history=5):
	previous_lines = deque(maxlen=history)
	for line in lines:
		if pattern in line:
			yield line, previous_lines
		previous_lines.append(line)

# Example use on a file
if __name__ == '__main__':
	with open('somefile.txt') as f:
		for line, prevlines in search(f, 'python', 5):
			for pline in prevlines:
				print(pline, end='')
		print(line, end='')
		print('-'*20)
```

### Обсуждение
При написании программы для поиска элементов обычно используют функцию-генератор, содержащую *yield* (как и показано в вышеприведенном примере). Это отделяет процесс поиска от кода, который использует результаты. Если вы новичок в обращении с генераторами, см. **Рецепт 4.3.**

Использование *deque(maxlen=N)* создает очередь фиксированной длины. Когда новые элементы добавлены и очередь заполнена, самый старый элемент автоматически удаляется. Пример:
```python
>>> q = deque(maxlen=3)
>>> q.append(1)
>>> q.append(2)
>>> q.append(3)
>>> q
deque([1, 2, 3], maxlen=3)
>>> q.append(4)
>>> q
deque([2, 3, 4], maxlen=3)
>>> q.append(5)
>>> q
deque([3, 4, 5], maxlen=3)
```

Хотя вы можете вручную производить такие операции над списком (то есть добавление в конец, удаление и т.п.), решение с использованием очереди элегантнее и работает намного быстрее.

Обобщим: дека может быть использована в любом случае, когда вам нужна простая очередь. Если вы не задатите максимальную длину, вы получите бесконечную очередь, которая позволит вам добавлять и удалять элементы с обоих концов. Например:
```python
>>> q = deque()
>>> q.append(1)
>>> q.append(2)
>>> q.append(3)
>>> q
deque([1, 2, 3])
>>> q.appendleft(4)
>>> q
deque([4, 1, 2, 3])
>>> q.pop()
3
>>> q
deque([4, 1, 2])
>>> q.popleft()
4
```

Добавление или удаление элементов с любого из концов очереди имеет сложность O(1). А вот добавление или удаление элемента в начало списка имеет сложность O(N).


## 1.4. Поиск N максимальных и минимальных элементов 
### Задача 
Вы хотите создать список N максимальных или минимальных элементов коллекции.

### Решение 
У модуля *heapq* есть две функции, nlargest() и nsmallest(), которые делают именно то, что вам нужно. Например:
```python
import heapq

nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]
print(heapq.nlargest(3, nums))  # Prints [42, 37, 23]
print(heapq.nsmallest(3, nums)) # Prints [-4, 1, 2]
```

Обе функции таке принимают параметр key, который позволяет использовать их с более сложными структурами данных. Например:
```python
portfolio = [
	{'name': 'IBM', 'shares': 100, 'price': 91.1},
	{'name': 'AAPL', 'shares': 50, 'price': 543.22},
	{'name': 'FB', 'shares': 200, 'price': 21.09},
	{'name': 'HPQ', 'shares': 35, 'price': 31.75},
	{'name': 'YHOO', 'shares': 45, 'price': 16.35},
	{'name': 'ACME', 'shares': 75, 'price': 115.65}
]
cheap = heapq.nsmallest(3, portfolio, key=lambda s: s['price'])
expensive = heapq.nlargest(3, portfolio, key=lambda s: s['price'])
```

### Обсуждение 
Если вы ищете N наименьших или N наибольших элементов, причем N невелико по сравнению с общим размером коллекции, эти функции покажут великолепную производительность. «Под капотом» они начинают работу с конвертирования данных в список, где данные упорядочены как куча. Например:
```python
>>> nums = [1, 8, 2, 23, 7, -4, 18, 23, 42, 37, 2]
>>> import heapq
>>> heap = list(nums)
>>> heapq.heapify(heap)
>>> heap
[-4, 2, 1, 23, 7, 2, 18, 23, 42, 37, 8]
>>>
``` 

Самое важная возможность кучи состоит в том, что *heap[0]* всегда будет наименьшим элементом. Кроме того, последующие элементы могут быть легко найдены с помощью метода *heapq.heappop()*, который удаляет первый элемент и заменяет его следующим наименьшим элементом (это требует O(log N) операций, где N — размер кучи). Например, чтобы найти три наименьших элемента, вы могли бы сделать это:
```python
>>> heapq.heappop(heap)
-4
>>> heapq.heappop(heap)
1
>>> heapq.heappop(heap)
2
```

Функции *nlargest()* и *nsmallest()* лучше всего подходят, если вы пытаетесь найти относительно небольшое количество элементов. Если вы просто хотите найти один наибольший или наименьший элемент (N = 1), функции *min()* и *max()* будут быстрее. Похожим образом, если N сопоставимо с размером самой коллекции, обычно будет быстрее отсортировать их и взять срез (то есть сделать *sorted(items)[:N]* или *sorted(items)[-N:]*). Стоит отметить, что реальная имплементация *nlargest()* и *nsmallest()* работает гибко и выполняет некоторые из этих оптимизаций самостоятельно (например, использует сортировку, если размер N близок к размеру входящих данных).

Хотя использовать этот рецепт необязательно, имплементация кучи интересна и заслуживает изучения. Информацию об этом можно найти в любой приличной книге по алгоритмам и структурам данных. В документации модуля *heapq* также обсуждаются детали внутренней имплементации.

## 1.5. Имплементация очереди с приоритетом 
### Задача 
Вы хотите реализовать очередь, которая сортирует элементы по заданному приоритету и всегда возвращает элемент с наивысшим приоритетом при каждой операции получения (удаления) элемента.

### Решение
Приведенный ниже класс использует модуль *heapq* для реализации простой очереди с приоритетом.

```python
import heapq

class PriorityQueue:
	def __init__(self):
		self._queue = []
		self._index = 0
	
	def push(self, item, priority):
		heapq.heappush(self._queue, (-priority, self._index, item))
		self._index += 1

def pop(self):
		return heapq.heappop(self._queue)[-1]
```

А вот пример использования:
```python
>>> class Item:
...   def __init__(self, name):
...   self.name = name
...   def __repr__(self):
...   return 'Item({!r})'.format(self.name)
...
>>> q = PriorityQueue()
>>> q.push(Item('foo'), 1)
>>> q.push(Item('bar'), 5)
>>> q.push(Item('spam'), 4)
>>> q.push(Item('grok'), 1)
>>> q.pop()
Item('bar')
>>> q.pop()
Item('spam')
>>> q.pop()
Item('foo')
>>> q.pop()
Item('grok')
>>>
```    

Посмотрите, как первая операция *pop()* возвращает элемент с наивысшим приоритетом. Также пронаблюдайте, как два элемента с одинаковым приоритетом (foo и grok) были возвращены в том же порядке, в каком они были помещены в очередь.

### Обсуждение 
Суть этого рецепта заключается в использовании модуля *heapq*. Функции *heapq.heappush()* и *heapq.heappop()* вставляют и удаляют элементы из *list_queue* таким образом, что первый элемент в списке имеет наименьший приоритет (как обсуждалось в **рецепте 1.4.**). Метод heappop() всегда возвращает «наименьший» элемент, что является ключом к тому, чтобы заставить очередь удалять правильные элементы. Кроме того, так как операции вталкивания и снятия имеют сложность O(log N), где N — число элементов в куче, то они являются вполне эффективными даже для весьма больших значений N.

В этом рецепте очередь состоит из кортежей формата *(-priority, index, item)*. Значение приоритета сделано отрицательным, чтобы заставить очередь сортировать элементы от наибольшего к наименьшему приоритету. Это противоположно обычному порядку сортировки кучи (от наименьшего к наибольшему значению).

Роль переменной *index* заключается в установлении правильного порядка элементов с одинаковым приоритетом. Поддержание постоянно увеличивающегося индекса позволяет сортировать элементы в соответствии с порядком, в каком они были вставлены. Однако индекс такде выполняет важную роль в выполнении операций сравнения при работе с элементами с одинаковыми значениями приоритета. 

Если остановиться на этом подробнее, то отметим, что экземпляры класса *Item* не могут быть упорядочены. Например:
```python
>>> a = Item('foo')
>>> b = Item('bar')
>>> a < b
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
TypeError: unorderable types: Item() < Item()
>>>
```

Если вы создаете кортежи *(priority, item)*, то их можно сравнивать до тех пор, пока приоритеты различны. Однако же если сравниваются два кортежа с равными приоритетами, то сравнение не может быть проведено (как и ранее). Например:
```python
>>> a = (1, Item('foo'))
>>> b = (5, Item('bar'))
>>> a < b
True
>>> c = (1, Item('grok'))
>>> a < c
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
TypeError: unorderable types: Item() < Item()
>>>
```

Вводя дополнительный индекс и создавая кортежи *(priority, index, item)*, вы избегаете этой проблемы полностью, поскольку два кортежа никогда не будут иметь одинаковые значения переменной *index* (и Python никогда не будет сравнивать остальные значения в кортежах, если результат сравнения уже определен):
```python
>>> a = (1, 0, Item('foo'))
>>> b = (5, 1, Item('bar'))
>>> c = (1, 2, Item('grok'))
>>> a < b
True
>>> a < c
True
>>>
```

Если вы хотите использовать эту очередь для коммуникации между потоками (тредами), вы должны добавить правильную блокировку и передачу сигналов (cм. **рецепт 12.3.**).  

Документация модуля *heapq* содержит дополнительные примеры и обсуждения теории и имплементации куч.


## 1.6. Отображение ключей на множественные значения в словаре 
### Задача 
Вы хотите создать словарь, который отображает ключи на более чем одно значение (так называемый «мультисловарь», multidict).

### Решение
Словарь — это отображение, где каждый ключ отображен на единственное значение. Если вы хотите отобразить ключи на множественные значения, вам нужно хранить множественные значения в другом контейнере, таком как список или множество. Например, вы можете создавать такие словари:
```python
d = {
	'a' : [1, 2, 3],
	'b' : [4, 5]
}

e = {
	'a' : {1, 2, 3},
	'b' : {4, 5}
}
```

Выбор того, использовать или не использовать списки или множества, зависит от того, как будет использован мультисловарь. Применяйте список, если вы хотите сохранить порядок, в котором добавлены элементы. Применяйте множество, если вы хотите устранить дубликаты (и при этом не беспокоитесь о порядке элементов).

Чтобы легко создавать такие словари, вы можете использовать *defaultdict* из модуля *collections*. Фишка *defautdict* заключается в автоматической инициализации первого значения, так что вы можете сосредоточиться на добавлении элементов. Например:
```python
from collections import defaultdict

d = defaultdict(list)
d['a'].append(1)
d['a'].append(2)
d['b'].append(4)
...

d = defaultdict(set)
d['a'].add(1)
d['a'].add(2)
d['b'].add(4)
...
```

Одно предупреждение: *defaultdict* автоматически создаст записи словаря для ключей, к которым позже будет осуществлен доступ (даже если их в данный момент в словаре нет). Если такое поведение нежелательно, вы можете использовать *setdefault()* на обычном словаре. Например:
```python
d = {}  # A regular dictionary
d.setdefault('a', []).append(1)
d.setdefault('a', []).append(2)
d.setdefault('b', []).append(4)
...
```

Однако многие программисты находят *setdefault()* несколько неестественным — и это если не учитывать тот факт, что он всегда создает новый экземпляр первоначального значения при каждом вызове (в примере это пустой список []).

### Обсуждение 
Конструирование словарей с множественными значениями не является чем-то сложным. Однако инициализация первого значения может быть запутанной, если вы пытаетесь сделать это самостоятельно. Например, вы можете написать что-то такое:
```python
d = {}
for key, value in pairs:
	if key not in d:
		d[key] = []
	d[key].append(value)
``` 

Использование *defaultdict* приводит к намного более чистому коду:
```python
d = defaultdict(list)
for key, value in pairs:
	d[key].append(value)
```

Этот рецепт сильно связан с проблемой группировки записей в задачах обработки данных. Посмотрите, например, рецепт **1.15.**

## 1.7. Поддержание порядка в словарях 
### Задача
Вы хотите создать словарь, и вы также хотите контролировать порядок элементов при итерировании или сериализации.

### Решение
Чтобы контролировать порядок элементов в словаре, вы можете использовать *OrderedDict* из модуля *collections*. Он в точности сохраняет изначальный порядок добавления данных при итерировании. Например:
```python
 from collections import OrderedDict

d = OrderedDict()
d['foo'] = 1
d['bar'] = 2
d['spam'] = 3
d['grok'] = 4

# Outputs "foo 1", "bar 2", "spam 3", "grok 4"
for key in d:
	print(key, d[key])
```

*OrderedDict* особенно полезен, когда вы хотите создать отображение, которое вы в дальнейшем собираетесь сериализовать или закодировать в другой формат. Например, если вы хотите строго контролировать порядок полей, выводимых в JSON, вам нужно просто создать *OrderedDict* с нужными данными:
```python
>>> import json

>>> json.dumps(d)
'{"foo": 1, "bar": 2, "spam": 3, "grok": 4}'
>>>
```

### Обсуждение
*OrderedDict* внутри себя поддерживает двусвязный список, который упорядочивает ключи в соответствии с порядком добавления. Когда новый элемент вставляется впервые, он помещается в конец этого списка. Последующее связывание значения с существующим ключом не изменяет порядок.

Заметьте, что размер *OrderedDict* более чем в два раза превышает размер обычного словаря из-за содержащегося внутри дополнительного списка. А если вы собираетесь создать структуру данных, в которой будет большое число экземпляров *OrderedDict* (например, вы хотите прочитать 100 000 строк CSV-файла в список экземпляров *OrderedDict*), вам стоит изучить требования вашего приложения, чтобы решить, перевесят ли преимущества использования *OrderedDict* оверхед на дополнительную память. 

## 1.8. Вычисления в словарях
### Задача
Вы хотите проводить различные вычисления (например, поиск минимального и максимального значения, сортировку) в словаре с данными.

### Решение
Рассмотрим словарь, который отображает тикеры (названия) акций на цены:
```python
prices = {
	'ACME': 45.23,
	'AAPL': 612.78,
	'IBM': 205.55,
	'HPQ': 37.20,
	'FB': 10.75
}
```

Чтобы выполнить вычисления на содержимом словаря, часто бывает полезно обратить ключи и значения, используя функцию *zip()*. Например, вот так можно найти минимальную и максимальную цену, а также соответствующий тикер:
```python
min_price = min(zip(prices.values(), prices.keys()))
# min_price is (10.75, 'FB')

max_price = max(zip(prices.values(), prices.keys()))
# max_price is (612.78, 'AAPL')
```

Похожим образом для ранжирования данных можно использовать *zip()* с sorted(), как показано ниже:
```python
prices_sorted = sorted(zip(prices.values(), prices.keys()))
# prices_sorted is [(10.75, 'FB'), (37.2, 'HPQ'),
# 					(45.23, 'ACME'), (205.55, 'IBM'),
# 					(612.78, 'AAPL')]
``` 

Когда вы производите эти вычисления, обратите внимание, что *zip()* создает итератор, по которому можно пройти только один раз. Например, следующий фрагмент кода — неправильный:
```python
prices_and_names = zip(prices.values(), prices.keys())
print(min(prices_and_names))  # OK
print(max(prices_and_names))  # ValueError: max() arg is an empty sequence
```

### Обсуждение 
Если вы попытаетесь выполнить обычные обработки данных на словаре, то вы обнаружите, что они обрабатывают только ключи, но не значения. Например:
```python
min(prices)  # Returns 'AAPL'
max(prices)  # Returns 'IBM'
```

Вероятно, это не то, чего вы хотели добиться, поскольку вы пытались выполнить вычисления с использованием значений словаря. Вы можете попробовать исправить это, используя метод словаря *values()*:
```python
min(prices.values())  # Returns 10.75
max(prices.values())  # Returns 612.78
``` 

К несчастью, это часто тоже не позволит вам добиться желаемого. Например, вы можете хотеть знать соответствующие ключи (т.е., у каких акций самая низкая цена?)

Вы можете получить ключ, соответствующий минимальному или максимальному значению, если вы передадите функцию в функции *min()* и *max()*. Например:
```python
min(prices, key=lambda k: prices[k])  # Returns 'FB'
max(prices, key=lambda k: prices[k])  # Returns 'AAPL'
```

Однако чтобы получить минимальное значение, вам потребуется дополнительное обращение. Например:
```python
min_value = prices[min(prices, key=lambda k: prices[k])]
```

Решение с использованием функции *zip()* решает задачу путем «обращения» словаря в последовательность пар (value, key). Когда выполняется сравнение таких кортежей, элемент value сравнивается первым, а key — следующим. Это дает вам то самое поведение, которое вы хотите, и которое позволяет проводить обработки и сортировку словаря с использованием единственного выражения.

Стоит отметить, что в вычислениях с использованием пар (value, key) key будет использован, чтобы определить результат в экземплярах, где множественные записи имеют одинаковые value. Например, в вычислениях *min()* и *max()* запись с наименьшим или наибольшим ключом будет возвращена, если найдутся дублированные (одинаковые) значения (value). Например:
```python
>>> prices = { 'AAA' : 45.23, 'ZZZ': 45.23 }
>>> min(zip(prices.values(), prices.keys()))
(45.23, 'AAA')
>>> max(zip(prices.values(), prices.keys()))
(45.23, 'ZZZ')
>>>
```  

## 1.9. Поиск общих элементов в двух словарях
### Задача
У вас два словаря, и вы хотите выяснить, что у них общего (одинаковые ключи, значения и т.п.)

### Решение
Рассмотрим два словаря:
```python
a = {
	'x' : 1,
	'y' : 2,
	'z' : 3
}

b = {
	'w' : 10,
	'x' : 11,
	'y' : 2
}
```

Чтобы найти общие элементы, просто выполните обычный набор операций с использовением методов *keys()* и *items()*. Например:
```python
# Find keys in common
a.keys() & b.keys()  # { 'x', 'y' }
# Find keys in a that are not in b
a.keys() - b.keys()  # { 'z' }
# Find (key,value) pairs in common
a.items() & b.items() # { ('y', 2) }
```

Операции такого типа также могут быть использованы для изменения или фильтрования содержимого словаря. Предположим, например, что вы хотите создать новый словарь, в котором некоторые ключи удалены. Взгляните на этот пример кода генератора словаря (dictionary comprehension):
```python
# Make a new dictionary with certain keys removed
c = {key:a[key] for key in a.keys() - {'z', 'w'}}
# c is {'x': 1, 'y': 2}
```

### Обсуждение
Словарь — это отображение множества ключей на множество значений. Метод словаря *keys()* возвращает объект просмотра ключей (keys-view object). Малоизвестная особенность этих объектов заключается в том, что они поддерживают набор операций над множествами (объединения, пересечения, разности и т.п.) Так что если вам нужно выполнить этот набор операций над ключами словаря, вы можете использовать объект просмотра напрямую, без предварительного конвертирования в множество.

Метод словаря *items()* возвращает объект просмотра элементов, состоящий из пар (key, value). Этот объект поддерживает похожий набор операций и может быть использован для выполнения таких операций, как поиск того, какие пары ключ-значение являются общими для двух словарей.

Хотя метод словаря *values()* похож на предыдущие, он не поддерживает операции над множествами, описанные выше в этом рецепте. Это происходит, в частности, по причине того, что, в отличие от ключей, элементы объекта просмотра значений могут быть и не уникальными. Один этот факт делает применение к ним операций над множествами малополезным. Если же, однако, вы вынуждены выполнить такие операции, этого можно добиться путем простой предварительного конвертирования значений в множество.

## 1.10. Удаление дубликатов из последовательности с сохранением порядка элементов
### Задача
Вы хотите исключить дублирующиеся значения из последовательности, но при этом сохранить порядок следования оставшихся элементов. 

### Решение 
Если значения в последовательности являются хэшируемыми, задача может быть легко решена с использованием множества и генератора. Например:
```python
def dedupe(items):
	seen = set()
	for item in items:
		if item not in seen:
			yield item
			seen.add(item)
```

Вот пример использования этой функции:
```python
>>> a = [1, 5, 2, 1, 9, 1, 5, 10]
>>> list(dedupe(a))
[1, 5, 2, 9, 10]
>>>
```

Это будет работать только в том случае, если элементы последовательности хэшируются. Если вы пытаетесь удалить дубликаты в последовательности из нехэшируемых типов (таких как словари), вы можете внести небольшое изменение в этот рецепт. Например, такое:
```python
def dedupe(items, key=None):
	seen = set()
	for item in items:
		val = item if key is None else key(item)
		if val not in seen:
			yield item
			seen.add(val)
```

Аргумент *key* здесь нужен для определения функции, которая конвертирует элементы последовательности в хэшируемый тип, подходящий для поиска дубликатов. Вот как это работает:
```python
>>> a = [ {'x':1, 'y':2}, {'x':1, 'y':3}, {'x':1, 'y':2}, {'x':2, 'y':4}]
>>> list(dedupe(a, key=lambda d: (d['x'],d['y'])))
[{'x': 1, 'y': 2}, {'x': 1, 'y': 3}, {'x': 2, 'y': 4}]
>>> list(dedupe(a, key=lambda d: d['x']))
[{'x': 1, 'y': 2}, {'x': 2, 'y': 4}]
>>>
```

Последнее решение также отлично работает, если вам нужно удалить дубликаты, базируясь на значении одного поля или атрибута или более крупной структуры данных.

### Обсуждение
Если всё, что вы хотите сделать, это просто удалить дубликаты, то часто достаточно создать множество. Например:
```python
>>> a
[1, 5, 2, 1, 9, 1, 5, 10]
>>> set(a)
{1, 2, 10, 5, 9}
>>>
```

Однако этот поход не сохраняет какой бы то ни было порядок, поэтому результат будет перемешан. Показанный выше решения помогают избежать этого. 

Использование функции-генератора в этом рецепте отражает тот факт, что вы наверняка хотите написать функцию максимально широкого назначения, а не напрямую привязанную к обработке списков. Например, если вы хотите читать файл, удаляя дублирующиеся строки, вы можете сделать так:
```python
with open(somefile,'r') as f:
	for line in dedupe(f):
		...
```

Передача функции в аргументе *key* имитирует похожую возможность во встроенных функциях, таких как *sorted()*, *min()* и *max()*. См., например, рецепты **1.8** и **1.13.**

## 1.11. Присваивание имён срезам
### Задача
Ваша программа превратилась в нечитабельную массу индексов срезов, и вы хотите всё это расчистить.

### Решение
Предположим, что у вас есть код, который вытаскивает определенные поля с данными из строковых записей с фиксированным набором полей (то есть из файла с плоской структурой или похожего формата):
```python
###### 0123456789012345678901234567890123456789012345678901234567890'
record = '....................100 .......513.25 ..........'
cost = int(record[20:32]) * float(record[40:48])
``` 

Вместо этого вы вполне можете присвоить срезам имена:
```python
SHARES = slice(20,32)
PRICE  = slice(40,48)

cost = int(record[SHARES]) * float(record[PRICE])
```

В последнем примере вы избежали появления кучи загадочных индексов, и код стал проще и яснее.

### Обсуждение
Общее правило таково: написание кода с большим количеством неоформленных индексов ведет к проблемам с читабельностью и поддерживаемостью. Например, если вы вернетесь к такому коду через год, то наверняка не сразу вспомните, как и о чём вы думали, когда всё это писали. Приведённое выше решение — простой путь к более ясному обозначению того, что делает ваш код. 

В общем, встроенная функция slice() создает объект среза, который может быть использован везде, где можно бы использовать обычные срезы. Например:
```python
>>> items = [0, 1, 2, 3, 4, 5, 6]
>>> a = slice(2, 4)
>>> items[2:4]
[2, 3]
>>> items[a]
[2, 3]
>>> items[a] = [10,11]
>>> items
[0, 1, 10, 11, 4, 5, 6]
>>> del items[a]
>>> items
[0, 1, 4, 5, 6]
```

Если у вас есть экземпляр *slice* s, вы можете получить больше информации о нём, если посмотрите на атрибуты *s.start*, *s.stop* и *s.step*. Например:
```python
>>> a = slice(10, 50, 2)
>>> a.start
10
>>> a.stop
50
>>> a.step
2
>>>
```

Также вы можете наложить срез на последовательность определенного размера, используя его метод *indices(size)*. Он возвращает кортеж (start, stop, step), где все значения соответственно ограничены, чтобы вписаться в границы (для избегания исключений *IndexError* при индексировании). Например:
```python
>>> s = 'HelloWorld'
>>> a.indices(len(s))
(5, 10, 2)
>>> for i in range(*a.indices(len(s))):
...   print(s[i])
...
W
r
d
>>>
```

## 1.12. Определение наиболее часто встречающихся элементов в последовательности
### Проблема
У вас есть последовательность элементов, и вы хотите узнать, какие элементы встречаются в ней чаще всего.

### Решение
Класс *collections.Counter* разработан как раз решения для подобных задач. В нем даже есть удобный метод *most_common()*, который сразу выдаст вам ответ.

Чтобы проиллюстрировать это, предположим, что у вас есть список слов, и вы хотите найти наиболее часто встречающееся. Вот как можно это сделать:
```python
words = [
	'look', 'into', 'my', 'eyes', 'look', 'into', 'my', 'eyes',
	'the', 'eyes', 'the', 'eyes', 'the', 'eyes', 'not', 'around', 'the',
	'eyes', "don't", 'look', 'around', 'the', 'eyes', 'look', 'into',
	'my', 'eyes', "you're", 'under'
]

from collections import Counter

word_counts = Counter(words)
top_three = word_counts.most_common(3)
print(top_three)
# Outputs [('eyes', 8), ('the', 5), ('look', 4)]
```

### Обсуждение
На входе объектам класса *Counter* можно скормить любую последовательность хэшируемых элементов. Под капотом *Counter* — это словарь, который отображает элементы на количество вхождений. Например:
```python
>>> word_counts['not']
1
>>> word_counts['eyes']
8
>>>
```

Если вы хотите увеличить счёт вручную, используйте сложение:
```python
>>> morewords = ['why','are','you','not','looking','in','my','eyes']
>>> for word in morewords:
...   word_counts[word] += 1
...
>>> word_counts['eyes']
9
>>>
```

Или же вы можете использовать метод *update()*:
```python
>>> word_counts.update(morewords)
>>>
```

Малоизвестная возможность экземпляров *Counter* состоит в том, что они могут быть легко скомбинированы с использованием разнообразных математических операций. Например:
```python
>>> a = Counter(words)
>>> b = Counter(morewords)
>>> a
Counter({'eyes': 8, 'the': 5, 'look': 4, 'into': 3, 'my': 3, 'around': 2,
		"you're": 1, "don't": 1, 'under': 1, 'not': 1})
>>> b
Counter({'eyes': 1, 'looking': 1, 'are': 1, 'in': 1, 'not': 1, 'you': 1,
		'my': 1, 'why': 1})

>>> # Combine counts
>>> c = a + b
>>> c
Counter({'eyes': 9, 'the': 5, 'look': 4, 'my': 4, 'into': 3, 'not': 2,
		'around': 2, "you're": 1, "don't": 1, 'in': 1, 'why': 1,
		'looking': 1, 'are': 1, 'under': 1, 'you': 1})

>>> # Subtract counts
>>> d = a - b
>>> d
Counter({'eyes': 7, 'the': 5, 'look': 4, 'into': 3, 'my': 2, 'around': 2,
		"you're": 1, "don't": 1, 'under': 1})
>>>
```

Нет смысла упоминать, что объекты *Counter* — невероятно полезный инструмент для практически любых задач, где вам нужно перевести данные в табличную форму и посчитать их. Рекомендуем использовать этот способ, а не писать вручную решения на основе словарей.

## 1.13. Сортировка списка словарей по общему ключу
### Задача
У вас есть список словарей, и вы хотите отсортировать записи согласно одному или более словарным значениям.

### Решение
Сортировка структур этого типа легко выполняется с помощью функции *itemgetter* из модуля *operator*. Предположим, вы выполнили запрос к таблице базы данных, чтобы получить список зарегистрированных пользователей вашего сайта, и получили в ответ вот такую структуру данных:
```python
rows = [
	{'fname': 'Brian', 'lname': 'Jones', 'uid': 1003},
	{'fname': 'David', 'lname': 'Beazley', 'uid': 1002},
	{'fname': 'John', 'lname': 'Cleese', 'uid': 1001},
	{'fname': 'Big', 'lname': 'Jones', 'uid': 1004}
]
```  

Можно достаточно легко вывести эти строки упорядоченно по любому из полей, общих для всех словарей. Например:
```python
from operator import itemgetter

rows_by_fname = sorted(rows, key=itemgetter('fname'))
rows_by_uid = sorted(rows, key=itemgetter('uid'))

print(rows_by_fname)
print(rows_by_uid)
```

Вышеприведенный код выведет следующее:
```python
[{'fname': 'Big', 'uid': 1004, 'lname': 'Jones'},
{'fname': 'Brian', 'uid': 1003, 'lname': 'Jones'},
{'fname': 'David', 'uid': 1002, 'lname': 'Beazley'},
{'fname': 'John', 'uid': 1001, 'lname': 'Cleese'}]

[{'fname': 'John', 'uid': 1001, 'lname': 'Cleese'},
{'fname': 'David', 'uid': 1002, 'lname': 'Beazley'},
{'fname': 'Brian', 'uid': 1003, 'lname': 'Jones'},
{'fname': 'Big', 'uid': 1004, 'lname': 'Jones'}]
```

Функция *itemgetter()* также может принимать несколько ключей. Пример кода:
```python
rows_by_lfname = sorted(rows, key=itemgetter('lname','fname'))
print(rows_by_lfname)
```

Вышеприведенный код выведет:
```python
[{'fname': 'David', 'uid': 1002, 'lname': 'Beazley'},
{'fname': 'John', 'uid': 1001, 'lname': 'Cleese'},
{'fname': 'Big', 'uid': 1004, 'lname': 'Jones'},
{'fname': 'Brian', 'uid': 1003, 'lname': 'Jones'}]
```

### Обсуждение
В этом примере строки передаются встроенной функции *sorted()*, которая принимает именованный аргумент *key*. Этот аргумент должен быть вызываемым объектом, который принимает один элемент из *rows* и возвращает значение, которое будет использовано в качестве основы для сортировки. Функция *itemgetter()* создает такой вызываемый объект. **(Прим. пер.: вызываемый объект — это объект, который имеет метод __call__).**

Функция *operator.itemgetter()* принимает в качестве аргументов индексы, которые используются для извлечения желаемых значений из записей в *rows*. Это может быть ключ словаря, номер элемента в списке или любое другое значение, которое может быть скормлено методу *__getitem()__*. Если вы передадите несколько индексов функции *itemgetter()*, вызываемый объект, который она создаст, вернет кортеж со всеми элементами, и функция *sorted()* упорядочит выводимые элементы в соответствии с отсортированным порядком кортежей. Это может быть полезно, если вы хотите провести сортировку сразу по нескольким полям (в примере это имя и фамилия):
```python
rows_by_fname = sorted(rows, key=lambda r: r['fname'])
rows_by_lfname = sorted(rows, key=lambda r: (r['lname'],r['fname']))
```

Это решение в большинстве случаев работает отлично. Однако решение с использованием *itemgetter()* обычно выполняется быстрее. Так что обратите на него внимание, если производительность в фокусе вашего внимания.

Последнее по порядку, но не по значению: не забудьте, что описанная в этом рецепте техника может быть применена к таким функциям, как *min()* и *max()*. Например:
```python
>>> min(rows, key=itemgetter('uid'))
{'fname': 'John', 'lname': 'Cleese', 'uid': 1001}
>>> max(rows, key=itemgetter('uid'))
{'fname': 'Big', 'lname': 'Jones', 'uid': 1004}
>>>
```

## 1.14. Сортировка объектов, не поддерживающих сравнение
### Задача
Вы хотите отсортировать объекты одного класса, но они не поддерживают операции сравнения.

### Решение
Встроенная функция *sorted()* принимает аргумент *key*, в котором может быть передан вызываемый объект, который будет возвращать некоторое значение из объектов, которое *sorted()* будет использовать для сравнения этих объектов. Например, если у вас в приложении есть последовательность экземпляров класса *User*, и вы хотите отсортировать их по атрибуту *user_id*, то вы могли бы предоставить вызываемый объект, который принимает экземпляр класса *User* и возвращает атрибут *user_id*. Например:  
```python
>>> class User:
...  def __init__(self, user_id):
...  	self.user_id = user_id
...  def __repr__(self):
...  	return 'User({})'.format(self.user_id)
...
>>> users = [User(23), User(3), User(99)]
>>> users
[User(23), User(3), User(99)]
>>> sorted(users, key=lambda u: u.user_id)
[User(3), User(23), User(99)]
>>>
```

Вместо лямбды можно применить альтернативный подход с использованием *operator.attrgetter()*: 
```python
>>> from operator import attrgetter
>>> sorted(users, key=attrgetter('user_id'))
[User(3), User(23), User(99)]
>>>
```

### Обсуждение
Использовать или не использовать лямбду или *attrgetter()* — вопрос личных предпочтений. Однако *attrgetter()* часто оказывается немного быстрее, а также добавляет возможность одновременного извлечения нескольких полей. Это аналогично использованию *operator.itemgetter()* для словарей (см. **рецепт 1.13.**). Например, если экземпляры класса User также имеют атрибуты *first_name* и *last_name*, вы можете выполнить вот такую сортировку:
```python
by_name = sorted(users, key=attrgetter('last_name', 'first_name'))
```

Также стоит отметить, что использованный в этом рецепте приём может быть применён к таким функциям, как *min()* и *max()*. Например:
```python
>>> min(users, key=attrgetter('user_id')
User(3)
>>> max(users, key=attrgetter('user_id')
User(99)
>>>
``` 

## 1.15. Группировка записей на основе полей
### Задача
У вас есть последовательность словарей или экземпляров, и вы хотите итерировать по данным в группах, основываясь на значении конкретного поля (например, на дате).

### Решение
Функция *itertools.groupby()* особенно полезна для такого типа группировки данных. Предположим, что у вас есть список словарей:
```python
rows = [
	{'address': '5412 N CLARK', 'date': '07/01/2012'},
	{'address': '5148 N CLARK', 'date': '07/04/2012'},
	{'address': '5800 E 58TH', 'date': '07/02/2012'},
	{'address': '2122 N CLARK', 'date': '07/03/2012'},
	{'address': '5645 N RAVENSWOOD', 'date': '07/02/2012'},
	{'address': '1060 W ADDISON', 'date': '07/02/2012'},
	{'address': '4801 N BROADWAY', 'date': '07/01/2012'},
	{'address': '1039 W GRANVILLE', 'date': '07/04/2012'},
]
```

Предположим также, что вы хотите проитерировать по данным, причем сгруппированными по дате кусочками. Проведем отсортировку по нужному полю (в данном случае по дате), а потом применим *itertools.groupby()*:
```python
from operator import itemgetter
from itertools import groupby

# Sort by the desired field first
rows.sort(key=itemgetter('date'))

# Iterate in groups
for date, items in groupby(rows, key=itemgetter('date')):
	print(date)
	for i in items:
		print(' ', i)
```    

Вывод будет таким:
```python
07/01/2012
	{'date': '07/01/2012', 'address': '5412 N CLARK'}
	{'date': '07/01/2012', 'address': '4801 N BROADWAY'}
07/02/2012
	{'date': '07/02/2012', 'address': '5800 E 58TH'}
	{'date': '07/02/2012', 'address': '5645 N RAVENSWOOD'}
	{'date': '07/02/2012', 'address': '1060 W ADDISON'}
07/03/2012
	{'date': '07/03/2012', 'address': '2122 N CLARK'}
07/04/2012
	{'date': '07/04/2012', 'address': '5148 N CLARK'}
	{'date': '07/04/2012', 'address': '1039 W GRANVILLE'}
```

### Обсуждение
Функция *groupby()* работает так: сканирует последовательность и ищет последовательные «партии» одинаковых значений (или значений, возвращенных переданной через *key* функцией). В каждой итерации функции возвращает значение вместе с итератором, который выводит все элементы в группу с одинаковым значением.

Важным предварительным шагом тут является сортировка данных по интересующему нас полю. Поскольку *groupby()* проверяет только последовательные элементы, без предварительной сортировки группировка записей выполнена не будет.

Если ваша цель — просто сгруппировать данные вместе в крупную структуру данных с произвольным доступом, то вам больше поможет *defaultdict()*, которая создает «мультисловарь», как описано в **рецепте 1.6**. Например:
```python
from collections import defaultdict
rows_by_date = defaultdict(list)
for row in rows:
	rows_by_date[row['date']].append(row)
```

Это позволяет легко получить доступ к записям для каждой даты:
```python
>>> for r in rows_by_date['07/01/2012']:
...   print(r)
...
{'date': '07/01/2012', 'address': '5412 N CLARK'}
{'date': '07/01/2012', 'address': '4801 N BROADWAY'}
>>>
```

В последнем примере предварительная сортировка записей не обязательна. Но если вы не заботитесь о потреблении памяти, то может оказаться быстрее сделать это с помощью предварительной сортировки и итерированию с использованием *groupby()*.  

## 1.16. Фильтрование элементов последовательности
### Задача
У вас есть данные внутри последовательности, и вы хотите извлечь значения или уменьшить последовательность по какому-либо критерию.

### Решение
Самый простой способ фильтрования последовательности — использовать генератор списка (list comprehension). Например:
```python
>>> mylist = [1, 4, -5, 10, -7, 2, 3, -1]
>>> [n for n in mylist if n > 0]
[1, 4, 10, 2, 3]
>>> [n for n in mylist if n < 0]
[-5, -7, -1]
>>>
```

Потенциальная проблема с использованием генераторов списоков заключается в том, что они могут создать большой результат, если размер входных данных тоже большой. Если это вас беспокоит, вы можете использовать выражения-генераторы для итеративного возврата отфильтрованных значений. Например:
```python
>>> pos = (n for n in mylist if n > 0)
>>> pos
<generator object <genexpr> at 0x1006a0eb0>
>>> for x in pos:
...   print(x)
...
1
4
10
2
3
>>>
```
Иногда критерий фильтрования не может быть легко выражен в форме генератора списка или выражения-генератора. Предположим, например, что процесс фильтрования включает обработку исключений или какой-то другой сложный момент. Чтобы справиться с этим, поместите фильтрующий код в функцию и используйте встроенную функцию *filter()*. Например: 
```python
values = ['1', '2', '-3', '-', '4', 'N/A', '5']

def is_int(val):
	try:
		x = int(val)
		return True
	except ValueError:
		return False

ivals = list(filter(is_int, values))
print(ivals)
# Outputs ['1', '2', '-3', '4', '5']
```

*filter()* создает итератор, так что если вы хотите получить список результатов, не забудьте использовать *list()*, как показано выше.

### Обсуждение
Генераторы списков и выражения-генераторы часто являются самым лёгким и прямым способом фильтрования простых данных. Но у них также есть дополнительная способность одновременного изменения данных. Например:
```python
>>> mylist = [1, 4, -5, 10, -7, 2, 3, -1]
>>> import math
>>> [math.sqrt(n) for n in mylist if n > 0]
[1.0, 2.0, 3.1622776601683795, 1.4142135623730951, 1.7320508075688772]
>>>
```  

Одна из разновидностей фильтрования включает замену значений, которые не подходят под определенный критерий, другим значением (вместо отбраковки неподходящих). Например, вместо простого поиска положительных значений, вы также хотите обрезать «плохие» значения, чтобы они попадали в определенный диапазон. В большинстве случаев это легко сделать с помощью перемещения критерия фильтрования в условное выражение:
```python
>>> clip_neg = [n if n > 0 else 0 for n in mylist]
>>> clip_neg
[1, 4, 0, 10, 0, 2, 3, 0]
>>> clip_pos = [n if n < 0 else 0 for n in mylist]
>>> clip_pos
[0, 0, -5, 0, -7, 0, 0, -1]
>>>
```

Другой важный инструмент для фильтрации — *itertools.compress()*, который принимает итерируемый объект вместе с последовательностью-селектором из булевых значений. На выходе функция выдает все элементы итерируемого объекта, для которых совпадающий элемент в селекторе — True. Это может быть полезно, если вы пытаетесь применить результаты фильтрования одной последовательности к другой связанной последовательности. Например, у вас есть две колонки данных:
```python
addresses = [
	'5412 N CLARK',
	'5148 N CLARK',
	'5800 E 58TH',
	'2122 N CLARK'
	'5645 N RAVENSWOOD',
	'1060 W ADDISON',
	'4801 N BROADWAY',
	'1039 W GRANVILLE',
]

counts = [ 0, 3, 10, 4, 1, 7, 6, 1]
```

Теперь предположим, что вы хотите создать список всех адресов, где соответствующие значение из *counts* больше 5. Вот как это можно сделать:
```python
>>> from itertools import compress
>>> more5 = [n > 5 for n in counts]
>>> more5
[False, False, True, False, False, True, True, False]
>>> list(compress(addresses, more5))
['5800 E 58TH', '4801 N BROADWAY', '1039 W GRANVILLE']
>>>
``` 

Ключевой момент — сначала создать последовательность булевых значений, которые будут указывать, какие элементы удовлетворяют заданному условию. Далее функция *compress()* выберет элементы, соответствующие значениям True.

Как и *filter()*, функция *compress()* возвращает итератор. Поэтому если вы хотите на выходе получить список, вам придется использовать *list()*.  

## 1.17. Извлечение подмножества из словаря
### Задача
Вы хотите создать словарь, который будет подмножеством другого словаря.

### Решение
Эту задачу можно легко решить с помощью генератора словаря (dictionary comprehension). Например:
```python
prices = {
	'ACME': 45.23,
	'AAPL': 612.78,
	'IBM': 205.55,
	'HPQ': 37.20,
	'FB': 10.75
}

# Make a dictionary of all prices over 200
p1 = { key:value for key, value in prices.items() if value > 200 }

# Make a dictionary of tech stocks
tech_names = { 'AAPL', 'IBM', 'HPQ', 'MSFT' }
p2 = { key:value for key,value in prices.items() if key in tech_names }
```

### Обсуждение
Большая часть того, что можно сделать с помощью генераторов словарей, можно осуществить путём создания последовательности кортежей и передачи их в функцию *dict()*. Например:
```python
p1 = dict((key, value) for key, value in prices.items() if value > 200)
```

Однако решение на основе генератора словаря немного яснее и работает немного быстрее (в рассмотренном выше примере генератор отработал в два раза быстрее). 

Иногда существует множество путей решить задачу. Например, второй пример можно переписать так:
```python
# Make a dictionary of tech stocks
tech_names = { 'AAPL', 'IBM', 'HPQ', 'MSFT' }
p2 = { key:prices[key] for key in prices.keys() & tech_names }
```

Однако подсчет времени выполнения открывает нам, что это решение почти в 1,6 раза медленнее, чем первое. Если производительность для вас важна, обычно стоит потратить немного времени на изучение таких вопросов. См. **рецепт 14.13.**, чтобы получить детальную информацию о подсчете времени и профилировании.

## 1.18. Отображение имен на последовательность элементов
### Задача
У вас есть код, который осуществляет доступ к элементам в списке или кортеже по позиции, но такой подход часто делает программу нечитабельной. Также вы можете захотеть уменьшить зависимость от позиции в структуре данных путём перехода к доступу к элементам по имени.

### Решение
*collections.namedtuple()* предоставляет такую возможность, добавляя минимальный оверхед по сравнению с использованием обычного кортежа. *collections.namedtuple()* — это фабричный метод, который возвращает подкласс стандартного пайтоновского типа tuple (кортеж). Вы скармливаете этому методу имя типа и поля, которые он должен иметь, и он возвращает класс, который может порождать экземпляры с полями, которые вы определили, и значениями этих полей, которые вы передадите при порождении. Например:
```python
>>> from collections import namedtuple
>>> Subscriber = namedtuple('Subscriber', ['addr', 'joined'])
>>> sub = Subscriber('jonesy@example.com', '2012-10-19')
>>> sub
Subscriber(addr='jonesy@example.com', joined='2012-10-19')
>>> sub.addr
'jonesy@example.com'
>>> sub.joined
'2012-10-19'
>>>
```

Хотя экземпляр *namedtuple* (именованного кортежа) выглядит так же, как и обычный экземпляр класса, он взаимозаменяем с кортежем и поддерживает все обычные операции кортежей, такие как индексирование и распаковка. Например:
```python
>>> len(sub)
2
>>> addr, joined = sub
>>> addr
'jonesy@example.com'
>>> joined
'2012-10-19'
>>>
```  

Самый частый случай использования именованного кортежа — отвязка вашего кода от работы с позициями элементов, которыми он манипулирует. Так что если вы получаете большой список кортежей в ответ на запрос к базе данных, а потом манипулируете ими через позиционное обращение к элементам, ваш код может сломаться, если вы, скажем, добавите новую колонку в таблицу. Этого можно избежать, если вы сначала превратите полученные кортежи в именованные кортежи.

Чтобы проиллюстрировать это, приведём пример кода, использующего обычные кортежи:
```python
def compute_cost(records):
	total = 0.0
	for rec in records:
		total += rec[1] * rec[2]
	return total
```

Использование позиционного обращения к элементам часто делает код немного менее выразительным и более зависимым от структуры записей. А вот версия с использованием именованного кортежа:
```python
from collections import namedtuple

Stock = namedtuple('Stock', ['name', 'shares', 'price'])
def compute_cost(records):
	total = 0.0
	for rec in records:
		s = Stock(*rec)
		total += s.shares * s.price
	return total
```

Естественно, вы можете избежать явной конвертации в именованный кортеж *Stock*, если последовательность *records* из примера уже содержит такие экземпляры. 

### Обсуждение
Возможное использование именованного кортежа — замена словаря, который требует больше места для хранения. Так что если создаете крупные структуры данных с использованием словарей, применение именованных кортежей будет более эффективным. Однако не забудьте, что именнованные кортежи неизменяемы (в отличие от словарей). Например:
```python
>>> s = Stock('ACME', 100, 123.45)
>>> s
Stock(name='ACME', shares=100, price=123.45)
>>> s.shares = 75
Traceback (most recent call last):
File "<stdin>", line 1, in <module>
AttributeError: can't set attribute
>>>
```

Если вам нужно изменить любой из атрибутов, это может быть сделано с помощью метода *_replace()*, которым обладают экземпляры именованных кортежей. Он создает полностью новый именованный кортеж, в котором указанные значения заменены. Например:
```python
>>> s = s._replace(shares=75)
>>> s
Stock(name='ACME', shares=75, price=123.45)
>>>
```

Тонкость использования метода *_replace()* заключается в том, что он может стать удобным способом наполнить значениями именованный кортеж, у которого есть опциональные или отсутствующие поля. Чтобы сделать это, создайте прототип кортежа, содержащий значения по умолчанию, а затем применяйте *_replace()* для создания новых экземпляров с замененными значениями. Например:
```python
from collections import namedtuple

Stock = namedtuple('Stock', ['name', 'shares', 'price', 'date', 'time'])

# Create a prototype instance
stock_prototype = Stock('', 0, 0.0, None, None)

# Function to convert a dictionary to a Stock
def dict_to_stock(s):
	return stock_prototype._replace(**s)
```   

Вот пример работы этого кода:
```python
>>> a = {'name': 'ACME', 'shares': 100, 'price': 123.45}
>>> dict_to_stock(a)
Stock(name='ACME', shares=100, price=123.45, date=None, time=None)
>>> b = {'name': 'ACME', 'shares': 100, 'price': 123.45, 'date': '12/17/2012'}
>>> dict_to_stock(b)
Stock(name='ACME', shares=100, price=123.45, date='12/17/2012', time=None)
>>>
```

Последнее, но важное замечание: стоит отметить, что если вашей целью является создание эффективной структуры данных, где вы сможете менять различные атрибуты экземпляров, использование именованных кортежей — не лучший вариант. Вместо них стоит определить класс с использованием \__slots__ (см. **рецепт 8.4.**)


## 1.19. Одновременное преобразование и сокращение данных
### Задача
Вам нужно выполнить функцию сокращения (т.е. sum(), min(), max()), но сначала необходимо преобразовать или отфильтровать данные.

### Решение
Есть весьма элегантное решение для объединения сокращения и преобразования данных — выражение-генератор в аргументе. Например, если вы хотите подсчитать сумму квадратов, попробуйте следующее:
```python
nums = [1, 2, 3, 4, 5]
s = sum(x * x for x in nums)
``` 

Вот еще несколько примеров:
```python
# Determine if any .py files exist in a directory
import os
files = os.listdir('dirname')
if any(name.endswith('.py') for name in files):
	print('There be python!')
else:
	print('Sorry, no python.')

# Output a tuple as CSV
s = ('ACME', 50, 123.45)
print(','.join(str(x) for x in s))

# Data reduction across fields of a data structure
portfolio = [
	{'name':'GOOG', 'shares': 50},
	{'name':'YHOO', 'shares': 75},
	{'name':'AOL', 'shares': 20},
	{'name':'SCOX', 'shares': 65}
]
min_shares = min(s['shares'] for s in portfolio)
```

### Обсуждение
Решение демонстрирует тонкий синтаксический аспект выражений-генераторов, связанный с передачей их как единственного аргумента в функцию — повторяющиеся скобки не нужны. Например, следующие инструкции эквивалентны:
```python
s = sum((x * x for x in nums))  # Pass generator-expr as argument
s = sum(x * x for x in nums)  # More elegant syntax
```

Использование аргумента-генератора часто будет более эффективным и элегантным, нежели предварительное создание временного списка. Например, если вы не используете выражение-генератор, вы можете поразмыслить над этой альтернативной имплементацией:
```python
nums = [1, 2, 3, 4, 5]
s = sum([x * x for x in nums])
```

Это работает, но вводит лишний шаг и создает лишний список. Для небольшого списка из примера это не имеет значения, но если *nums* был огромным, вы получите крупную временную структуру данных, которая будет использована только один раз, а потом выброшена. Решение с генератором обрабатывает данные итеративно и потому намного более эффективно с точки зрения использования памяти.

Некоторые функции сокращения, такие как *min()* и *max()*, принимают аргумент *key*, что может оказаться полезным в ситуациях, когда вы склоняетесь к использованию генератора. Например, в этом примере вы можете попробовать альтернативный подход:
```python
# Original: Returns 20
min_shares = min(s['shares'] for s in portfolio)

# Alternative: Returns {'name': 'AOL', 'shares': 20}
min_shares = min(portfolio, key=lambda s: s['shares'])
```

## 1.20. Объединение нескольких отображений в одно
### Задача
У вас есть много словарей или отображений, которые вы хотите логически объединить в одно отображение, чтобы выполнить некоторые операции, такие как поиск значений или проверка существования ключей.

### Решение
Предположим, у вас есть два словаря:
```python
a = {'x': 1, 'z': 3 }
b = {'y': 2, 'z': 4 }
```

А теперь предположим, что вы хотите провести поиски, в которых вы хотите проверить оба словаря (то есть сначала проверить в словаре *a*, а потом в *b*, если в первом словаре искомое не найдено). Простой способ сделать это — использовать класс *ChainMap* из модуля *collections*. Например:
```python
from collections import ChainMap
c = ChainMap(a,b)
print(c['x'])  # Outputs 1 (from a)
print(c['y'])  # Outputs 2 (from b)
print(c['z'])  # Outputs 3 (from a)
```

### Обсуждение
*ChainMap* принимает несколько отображений и делает так, что они логически становятся единым целым. Однако в буквальном смысле они не сливаются. Вместо этого *ChainMap* просто содержит список отображений и переопределяет обычные операции над словарями для сканирования этого списка. Большинство операций работают. Например:
```python
>>> len(c)
3
>>> list(c.keys())
['x', 'y', 'z']
>>> list(c.values())
[1, 2, 3]
>>>
``` 

В случае появления одинаковых ключей будут использованы значения из первого словаря. Например, *c['z']* в примере всегда будет ссылаться на значение из словаря *a*, а не из *b*.

Операции, которые изменяют отображение, всегда действуют на первое отображение в списке. Например:
```python
>>> c['z'] = 10
>>> c['w'] = 40
>>> del c['x']
>>> a
{'w': 40, 'z': 10}
>>> del c['y']
Traceback (most recent call last):
...
KeyError: "Key not found in the first mapping: 'y'"
>>>
``` 

*ChainMap* особенно полезны для работы с ограниченным набором значений, таких как переменные языка программирования (глобальные, локальные и т.п.) На самом деле даже существуют методы, которые всё упрощают:
```python
>>> values = ChainMap()
>>> values['x'] = 1
>>> # Add a new mapping
>>> values = values.new_child()
>>> values['x'] = 2
>>> # Add a new mapping
>>> values = values.new_child()
>>> values['x'] = 3
>>> values
ChainMap({'x': 3}, {'x': 2}, {'x': 1})
>>> values['x']
3
>>> # Discard last mapping
>>> values = values.parents
>>> values['x']
2
>>> # Discard last mapping
>>> values = values.parents
>>> values['x']
1
>>> values
ChainMap({'x': 1})
>>>
```  

В качестве альтернативы *ChainMap* вы можете обдумать слияние словарей с использованием метода update(). Например:
```python
>>> a = {'x': 1, 'z': 3 }
>>> b = {'y': 2, 'z': 4 }
>>> merged = dict(b)
>>> merged.update(a)
>>> merged['x']
1
>>> merged['y']
2
>>> merged['z']
3
>>>
``` 

Это работает, но требует от вас создания полностью нового объекта словаря (или необратимого изменения одного из существующих). В этом случае при изменении одного из первоначальных словарей новый объект объединенного словаря изменения не затронут. Например:
```python
>>> a['x'] = 13
>>> merged['x']
1
``` 

*ChainMap* использует первоначальные словари, поэтому не подвержен такому поведению. Например:
```python
>>> a = {'x': 1, 'z': 3 }
>>> b = {'y': 2, 'z': 4 }
>>> merged = ChainMap(a, b)
>>> merged['x']
1
>>> a['x'] = 42
>>> merged['x']  # Notice change to merged dicts
42
>>>
```

# 2. Строки и текст
Практически любая полезная программа включает тот или иной вид обработки текста: от парсинга данных до генерации вывода. Эта глава рассматривает обычные задачи манипулирования текстом, такие как разбивка строк, поиск, подстановка, лексический анализ и парсинг. Многие из этих задач могут быть легко решены с использованием встроенных строковых методов. Однако более сложные операции могут потребовать использования регулярных выражений ии создания полноценного парсера. Все эти темы разобраны в данной главе. Также мы обратим внимание на несколько хитрых аспектов работы с Unicode.

## 2.1. Разрезание строк, разделенных различными разделителями
### Задача
Вам нужно разделить строку на поля, но разделители (и пробелы вокруг них) внутри строки не одинаковые.

### Решение
Функция *re.split()* будет в этом случае весьма полезной, поскольку вы сможете определить многочисленные шаблоны разделителей. Например, как показано в решении, разделитель может быть либо запятой (,), точкой с запятой (;) или пробелом, за которым следует любое количество дополнительных пробелов. Какой бы из этих шаблонов ни был найден, совпадение становится разделителем. Результатом будет просто список полей, точно такой же, какой создает строковый метод *str.split()*.

При применении *re.split()* вы должны быть осторожными, если шаблон регулярного выражения использует группу, заключенную в скобки. При использовании групп совпавший с шаблоном текст также включается в результат. Например:
```python
>>> fields = re.split(r'(;|,|\s)\s*', line)
>>> fields
['asdf', ' ', 'fjdk', ';', 'afed', ',', 'fjek', ',', 'asdf', ',', 'foo']
>>>
```

Получение символов-разделителей может быть полезным в некоторых обстоятельствах. Например, вам могут потребоваться эти символы позже — для переформатирования выводимой строки:
```python
>>> values = fields[::2]
>>> delimiters = fields[1::2] + ['']
>>> values
['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']
>>> delimiters
[' ', ';', ',', ',', ',', '']

>>> # Reform the line using the same delimiters
>>> ''.join(v+d for v,d in zip(values, delimiters))
'asdf fjdk;afed,fjek,asdf,foo'
>>>
```

Если вы не хотите, чтобы разделители попали в результат, но при этом вам нужно применить группы в шаблоне регулярного выражения, убедитесь, что вы используете незахватывающую (noncapture) группу, которая определяется так: (?:...). Например:
```python
>>> re.split(r'(?:,|;|\s)\s*', line)
['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']
>>>
```

## 2.2. Поиск текста в начале и в конце строки
### Задача
Вам нужно проверить начало или конец строки на содержание неких текстовых шаблонов, таких как расширения файлов, схемы URL и т.д.

### Решение
Простой способ проверить начало или конец строки — применить методы *str.startswith()* или *str.endswith()*. Например:
```python
>>> filename = 'spam.txt'
>>> filename.endswith('.txt')
True
>>> filename.startswith('file:')
False
>>> url = 'http://www.python.org'
>>> url.startswith('http:')
True
>>>
```

Если вам нужно проверить несколько вариантов, передайте кортеж с ними в *startswith()* или *endswith()*:
```python
>>> import os
>>> filenames = os.listdir('.')
>>> filenames
[ 'Makefile', 'foo.c', 'bar.py', 'spam.c', 'spam.h' ]
>>> [name for name in filenames if name.endswith(('.c', '.h')) ]
['foo.c', 'spam.c', 'spam.h'
>>> any(name.endswith('.py') for name in filenames)
True
>>>
```

А вот другой пример:
```python
from urllib.request import urlopen

def read_data(name):
	if name.startswith(('http:', 'https:', 'ftp:')):
		return urlopen(name).read()
	else:
		with open(name) as f:
		return f.read()
```

Любопытно, что в этом случае на вход нужно подавать именно кортеж. Если так случилось, что варианты выбора собраны у вас в списке или множестве, сначала сконвертируйте их с помощью *tuple()*. Например:
```python
>>> choices = ['http:', 'ftp:']
>>> url = 'http://www.python.org'
>>> url.startswith(choices)
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
TypeError: startswith first arg must be str or a tuple of str, not list
>>> url.startswith(tuple(choices))
True
>>>
```

### Обсуждение
Методы *startswith()* и *endswith()* предоставляют весьма удобный способ проверки префиксов и окончаний. Такие же операции можно осуществить с помощью срезов, но это намного менее элегантно. Например:
```python
>>> filename = 'spam.txt'
>>> filename[-4:] == '.txt'
True
>>> url = 'http://www.python.org'
>>> url[:5] == 'http:' or url[:6] == 'https:' or url[:4] == 'ftp:'
True
>>>
```

Вы также можете склониться к использованию регулярных выражений в качестве альтернативы. Например:
```python
>>> import re
>>> url = 'http://www.python.org'
>>> re.match('http:|https:|ftp:', url)
<_sre.SRE_Match object at 0x101253098>
>>>
```

Такой подход работает, но часто это будет огнем из пушки по воробьям. Использование вышеописанного рецепта проще и работает быстрее.

И последнее: методы *startswith()* и *endswith()* отлично работают вместе с другими операциями, такими как обычные сокращения данных. Например, это выражение проверяет каталог на присутствие файлов определенных типов:
```python
if any(name.endswith(('.c', '.h')) for name in listdir(dirname)):
...
```  

## 2.3. Поиск строк с использованием масок оболочки (shell)
### Задача
Вы хотите найти текст, используя те же маски, которые обычно используются в оболочках Unix (например, *.py, Dat[0-9]*.csv и т.д.)

### Решение
Модуль *fnmatch* предоставляет две функции: *fnmatch()* и *fnmatchcase()*, которые можно использовать для такого поиска. Всё просто:
```python
>>> from fnmatch import fnmatch, fnmatchcase
>>> fnmatch('foo.txt', '*.txt')
True
>>> fnmatch('foo.txt', '?oo.txt')
True
>>> fnmatch('Dat45.csv', 'Dat[0-9]*')
True
>>> names = ['Dat1.csv', 'Dat2.csv', 'config.ini', 'foo.py']
>>> [name for name in names if fnmatch(name, 'Dat*.csv')]
['Dat1.csv', 'Dat2.csv']
>>>
```

По умолчанию *fnmatch()* использует те же чувствительные к регистру правила, как и файловая система текущей операционной системы (то есть правила меняются от системы к системе). Например:
```python
>>> # On OS X (Mac)
>>> fnmatch('foo.txt', '*.TXT')
False

>>> # On Windows
>>> fnmatch('foo.txt', '*.TXT')
True
>>>
```

Если это различие важно, используйте метод *fnmatchcase()*. Он ищет именно такие совпадения заглавных и строчных букв, которые вы предоставите:
```python
>>> fnmatchcase('foo.txt', '*.TXT')
False
>>>
```

Часто упускается из вида возможность использования этих функций на строках, получаемых при обработке данных, или на строках, не являющихся именами файлов. Например, у вас есть список адресов:
```python
addresses = [
	'5412 N CLARK ST',
	'1060 W ADDISON ST',
	'1039 W GRANVILLE AVE',
	'2122 N CLARK ST',
	'4802 N BROADWAY',
]
``` 

Вы можете написать такой генератор списка (list comprehension):
```python
>>> from fnmatch import fnmatchcase
>>> [addr for addr in addresses if fnmatchcase(addr, '* ST')]
['5412 N CLARK ST', '1060 W ADDISON ST', '2122 N CLARK ST']
>>> [addr for addr in addresses if fnmatchcase(addr, '54[0-9][0-9] *CLARK*')]
['5412 N CLARK ST']
>>>
```

### Обсуждение
Поиск совпадений с использованием *fnmatch* занимает нишу между возможностями простых строковых методов и полной мощью регулярных выражений. Если вы просто хотите простой механизм для применения масок в обработке данных, он часто является подходящим решением.

Если же вы пишете код для поиска имён файлов, используйте модуль *glob* (см. **рецепт 5.13.**)

## 2.4. Поиск совпадений и поиск текстовых паттернов
### Задача
Вы хотите отыскать совпадение или провести поиск по определенному шаблону.

### Решение
Если текст, который вы хотите найти, является простым литералом, в большинстве случаев вам подойдут базовые строковые методы, такие как *str.find()*, *str.endswith()*, *str.startwith()* и другие подобные. Например:
```python
>>> text = 'yeah, but no, but yeah, but no, but yeah'

>>> # Exact match
>>> text == 'yeah'
False

>>> # Match at start or end
>>> text.startswith('yeah')
True
>>> text.endswith('no')
False

>>> # Search for the location of the first occurrence
>>> text.find('no')
10
>>>
```

Для более сложного поиска совпадений используйте регулярные выражения и модуль *re*. Чтобы проиллюстрировать базовые механики использования регулярных выражений, предположим, что вы хотите найти даты, определенные цифрами, такие как «11/27/2012.» Вот пример того, как вы можете это сделать:
```python
>>> text1 = '11/27/2012'
>>> text2 = 'Nov 27, 2012'
>>>
>>> import re
>>> # Simple matching: \d+ means match one or more digits
>>> if re.match(r'\d+/\d+/\d+', text1):
...   print('yes')
... else:
...   print('no')
...
yes
>>> if re.match(r'\d+/\d+/\d+', text2):
...   print('yes')
... else:
...   print('no')
...
no
>>>
```

Если вы собираетесь много раз искать по одному и тому же шаблону, часто окупается предварительная компиляция шаблона регулярного выражения в объект шаблона. Например:
```python
>>> datepat = re.compile(r'\d+/\d+/\d+')
>>> if datepat.match(text1):
...   print('yes')
... else:
...   print('no')
...
yes
>>> if datepat.match(text2):
...   print('yes')
... else:
...   print('no')
...
no
>>>
```

*match()* всегда пытается найти совпадения в начале строки. Если вы хотите провести поиск по всем случаям соответствия шаблону, используйте метод *findall()*. Например:
```python
>>> text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'
>>> datepat.findall(text)
['11/27/2012', '3/13/2013']
>>>
```

При составлении регулярных выражений, часто нужно использовать захватывающие группы, заключая части шаблона в скобки. Например:
```python
>>> datepat = re.compile(r'(\d+)/(\d+)/(\d+)')
>>>
```

Захватывающие группы часто упрощают последующую обработку найденного текста, поскольку содержимое каждой группы может быть извлечено отдельно. Например:
```python
>>> m = datepat.match('11/27/2012')
>>> m
<_sre.SRE_Match object at 0x1005d2750>

>>> # Extract the contents of each group
>>> m.group(0)
'11/27/2012'
>>> m.group(1)
'11'
>>> m.group(2)
'27'
>>> m.group(3)
'2012'
>>> m.groups()
('11', '27', '2012')
>>> month, day, year = m.groups()
>>>

>>> # Find all matches (notice splitting into tuples)
>>> text
'Today is 11/27/2012. PyCon starts 3/13/2013.'
>>> datepat.findall(text)
[('11', '27', '2012'), ('3', '13', '2013')]
>>> for month, day, year in datepat.findall(text):
...   print('{}-{}-{}'.format(year, month, day))
...
2012-11-27
2013-3-13
>>>
```

Метод *findall()* проходит по тексту и находит все совпадения, возвращая их в списке. Если вы хотите искать совпадения итеративно, используйте метод *finditer()*:
```python
>>> for m in datepat.finditer(text):
...   print(m.groups())
...
('11', '27', '2012')
('3', '13', '2013')
>>>
```

### Обсуждение
Вводного курса в теорию регулярных выражений в этой книге вы не найдете. Однако этот рецепт демонстрирует простейшие примеры использования модуля re для поиска совпадений в тексте. Самые основные приёмы — компилирование шаблонов с использованием *re.compile()* и последующее использование таких методов как *match()*, *findall()* или *finditer()*.  

При составлении шаблонов часто нужно использовать «сырые» (raw) строки, такие как r'(\d+)/(\d+)/(\d+)'. Такие строки оставляют символы обратных слэшей необработанными, что может быть полезно в контесте применения регулярных выражений. С другой стороны, вы можете использовать двойные обратные слэши: '(\\d+)/(\\d+)/(\\d+)'. 

Учтите, что метод *match()* проверяет только начало строки. Возможно, что он найдет вещи, которые вы не ожидаете. Например:
```python
>>> m = datepat.match('11/27/2012abcdef')
>>> m
<_sre.SRE_Match object at 0x1005d27e8>
>>> m.group()
'11/27/2012'
>>>
```

Если вам нужно точное совпадение, убедитесь, что шаблон включает символ завершения ($), как в примере ниже:
```python
>>> datepat = re.compile(r'(\d+)/(\d+)/(\d+)$')
>>> datepat.match('11/27/2012abcdef')
>>> datepat.match('11/27/2012')
<_sre.SRE_Match object at 0x1005d2750>
>>>
```

И последнее: если вы просто проводите простые операции поиска, вы часто можете пропустить шаг компиляции и использовать функции уровня модуля из модуля *re*. Например:
```python
>>> re.findall(r'(\d+)/(\d+)/(\d+)', text)
[('11', '27', '2012'), ('3', '13', '2013')]
>>>
``` 

Обратите внимание, что если вы проводите много операций поиска совпадений, часто окупается компилирование шаблона и многократное его использование. Функции уровня модуля поддерживают кэш недавно скомпилированных паттернов, так что вы не получите огромного выигрыша в производительности, но вы сэкономите несколько обращений и избежите лишней обработки, используя ваш собственный скомпилированный шаблон.

## 2.5. Поиск и замена текста
### Задача
Вы хотите найти в строке и заменить текст, соответствующий некому шаблону. 

### Решение
Для простых литеральных шаблонов используйте метод *str.replace()*. Например:
```python
>>> text = 'yeah, but no, but yeah, but no, but yeah'

>>> text.replace('yeah', 'yep')
'yep, but no, but yep, but no, but yep'
>>>
```

Для более сложных шаблонов используйте функции/методы *sub()* из модуля *re*. Предположим, вы хотите перезаписать даты, чтобы перевести из их формата “11/27/2012” в “2012-11-27.” Вот пример того, как это можно сделать:
```python
>>> text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'
>>> import re
>>> re.sub(r'(\d+)/(\d+)/(\d+)', r'\3-\1-\2', text)
'Today is 2012-11-27. PyCon starts 2013-3-13.'
>>>
```

Первый аргумент, передаваемый в *sub()*, это шаблон для поиска, а второй — шаблон, которым нужно заменять найденное. Цифры, перед которыми поставлен обратный слэш (такие как \3), ссылаются на номера захватывающих групп в шаблоне.

Если вы собираетесь многократно выполнять подстановку по одному и тому же шаблону, рекомендуем скомпилировать его для увеличения производительности. Например:
```python
>>> import re
>>> datepat = re.compile(r'(\d+)/(\d+)/(\d+)')
>>> datepat.sub(r'\3-\1-\2', text)
'Today is 2012-11-27. PyCon starts 2013-3-13.'
>>>
```

В случае более сложных подстановок можно определить подстановочную функцию с обратным вызовом (callback function). Например:
```python
>>> from calendar import month_abbr
>>> def change_date(m):
...   mon_name = month_abbr[int(m.group(1))]
...   return '{} {} {}'.format(m.group(2), mon_name, m.group(3))
...
>>> datepat.sub(change_date, text)
'Today is 27 Nov 2012. PyCon starts 13 Mar 2013.'
>>>
```

На вход подстановочному коллбэку в аргументе передается объект поиска совпадений, возвращенный функцией *match()* или *find()*. Используйте метод *.group()* для извлечения определенных частей совпадения. Функция должна возвращать текст замены (replacement text). 

Если вы хотите знать, сколько подстановок было сделано в дополнение к получению текста замены (replacement text), используйте *re.subn()*. Например:
```python
>>> newtext, n = datepat.subn(r'\3-\1-\2', text)
>>> newtext
'Today is 2012-11-27. PyCon starts 2013-3-13.'
>>> n
2
>>>
```

### Обсуждение
В поиске совпадений с помощью регулярных выражений не особо много чего-то дополнительного к показанному примеру с использованием метода *sub()*. Самое сложное — это составление шаблона регулярного выражения, и это мы оставляем читателю в качестве упражнений.


## 2.6. Поиск и замена текста без учета регистра
### Задача
Вам необходимо найти и, возможно, заменить текст, не обращая внимания на регистр букв.

### Решение
Для выполнения действий над текстом без учёта регистра вам понадобится модуль *re* и флаг *re.IGNORECASE*, который можно применять в различных операциях. Например:
```python
>>> text = 'UPPER PYTHON, lower python, Mixed Python'
>>> re.findall('python', text, flags=re.IGNORECASE)
['PYTHON', 'python', 'Python']
>>> re.sub('python', 'snake', text, flags=re.IGNORECASE)
'UPPER snake, lower snake, Mixed snake'
>>>
``` 

Последний пример раскрывает ограничение: текст замены не будет совпадать по регистру с заменяемым текстом. Если вам нужно исправить такое поведение, используйте поддерживающую функцию:
```python
def matchcase(word):
	def replace(m):
		text = m.group()
		if text.isupper():
			return word.upper()
		elif text.islower():
			return word.lower()
		elif text[0].isupper():
			return word.capitalize()
		else:
			return word
	return replace
```

А вот пример использования этой функции:
```python
>>> re.sub('python', matchcase('snake'), text, flags=re.IGNORECASE)
'UPPER SNAKE, lower snake, Mixed Snake'
>>>
```

### Обсуждение
В простых случаях простого использования *re.INGNORECASE* достаточно для поиска совпадений без учёта регистра. Однако обратите внимание, что этого может оказаться недостаточно для некоторых случаев работы с Unicode, использующих выравнивание регистров (case folding). См. **рецепт 2.10.**


## 2.7. Определение регулярных выражений для поиска кратчайшего совпадения
### Задача
Вы пытаетесь найти совпадение по текстовому шаблону, используя регулярное выражение, но оно находит самое длинное из всех возможных совпадений. Вы же хотите найти самое короткое из всех возможных.

### Решение
Эта проблема часто возникает в шаблонах, которые пытаются найти текст, заключенный в пару открывающих и закрывающих разделителей (например, строка в кавычках). Рассмотрим следующий пример:
```python
>>> str_pat = re.compile(r'\"(.*)\"')
>>> text1 = 'Computer says "no."'
>>> str_pat.findall(text1)
['no.']
>>> text2 = 'Computer says "no." Phone says "yes."'
>>> str_pat.findall(text2)
['no." Phone says "yes.']
>>>
```

В этом примере шаблон r'\"(\.\*)\"' пытается найти текст, заключенный в кавычки. Однако оператор \* в регулярном выражении является жадным, поэтому поиск получается поиском самого длинного из возможных совпадений. Поэтому во втором примере с переменной *text2* неверно выполняется сопоставление двух строк в кавычках.

Чтобы исправить это, добавьте модификатор ? после оператора \* в шаблоне:
```python
>>> str_pat = re.compile(r'\"(.*?)\"')
>>> str_pat.findall(text2)
['no.', 'yes.']
>>>
```
Это делает поиск совпадений нежадным и выводит кратчайшее из найденных совпадений.

### Обсуждение
Этот рецепт решает одну из часто встречающихся при написании регулярных выражений с символом точки (\.) задач. В шаблоне точка соотвествует любому символу за исключением символа новой строки. Однако если вы окружите точку открывающим и закрывающим текстом (таким как кавычки), поиск будет пытаться найти самое длинное из возможных совпадений. Это вызывает многочисленные случаи пропуска открывающего и закрывающего текста и включения в результаты самого длинного совпадения. Добавление ? сразу после таких операторов как \* или \+ заставляет алгоритм поиска искать самое короткое совпадение.

## 2.8. Написание регулярного выражения для многострочных шаблонов
### Вы пытаетесь провести поиск по блоку текстов с использованием регулярного выражения, но вам нужно, чтобы совпадение охватывало несколько строк.

### Решение
Эта проблема обычно возникает в шаблонах, которые используют точку (\.) для поиска совпадения с любым символом. Многие забывают, что точка не может совпадать с символом новой строки. Например, вы пытаетесь найти совпадения в комментариях в стиле языка С:
```python
>>> comment = re.compile(r'/\*(.*?)\*/')
>>> text1 = '/* this is a comment */'
>>> text2 = '''/* this is a
... multiline comment */
... '''
>>>
>>> comment.findall(text1)
[' this is a comment ']
>>> comment.findall(text2)
[]
>>>
```

Чтобы исправить проблему, вам нужно добавить поддержку символов новой строки. Например:
```python
>>> comment = re.compile(r'/\*((?:.|\n)*?)\*/')
>>> comment.findall(text2)
[' this is a\n multiline comment ']
>>>
```

В этом шаблоне (?:.|\n) определяет незахватывающую группу (то есть выражение определяет группу для целей поиска совпадений, но эта группа не захватывается и не подсчитывается).

### Обсуждение
Функция *re.compile()* принимает полезный в данном случае флаг *re.DOTALL*. Он заставляет . в регулярном выражении совпадать с любыми символами, включая символ новой строки. Например:
```python
>>> comment = re.compile(r'/\*(.*?)\*/', re.DOTALL)
>>> comment.findall(text2)
[' this is a\n multiline comment ']
```

Использование флага *re.DOTALL* отличное работает в простых случаях, но это может быть проблематично при работе с очень сложными шаблонами или сочетанием отдельных регулярных выражений, которые должны объединяться друг с другом для токенизации (как описано в **рецепте 2.18.**) Если у вас есть выбор, обычно лучше определить шаблон регулярного выражения так, чтобы он работал правильно без необходимости в дополнительных флагах.

## 2.9. Приведение текста в Unicode к стандартному представлению (нормализация)
### Задача
Вы работате со строками Unicode и хотите убедиться, что все эти строки имеют одинаковое внутреннее представление.

### Решение
В Unicode некоторые символы могут быть представлены несколькими допустимыми кодирующими последовательностями. Рассмотрим пример:
```python
>>> s1 = 'Spicy Jalape\u00f1o'
>>> s2 = 'Spicy Jalapen\u0303o'
>>> s1
'Spicy Jalapeño'
>>> s2
'Spicy Jalapeño'
>>> s1 == s2
False
>>> len(s1)
14
>>> len(s2)
15
>>>
```

Здесь текст “Spicy Jalapeño” представлен в двух формах. Первая использует полноценный символ “ñ” (U\+00F1). Второй использует латинскую букву “n”, за которой следует дополняющий символ “~” (U\+0303).

Такие множественные представления становятся проблемой для программ, которые занимаются сравнением строк. Чтобы это исправить, вы должны сначала нормализовать текст, то есть привести его к стандартному представлению с помощью модуля *unicodedata*:
```python
>>> import unicodedata
>>> t1 = unicodedata.normalize('NFC', s1)
>>> t2 = unicodedata.normalize('NFC', s2)
>>> t1 == t2
True
>>> print(ascii(t1))
'Spicy Jalape\xf1o'

>>> t3 = unicodedata.normalize('NFD', s1)
>>> t4 = unicodedata.normalize('NFD', s2)
>>> t3 == t4
True
>>> print(ascii(t3))
'Spicy Jalapen\u0303o'
>>>
```

Первый аргумент, передаваемый в *normalize()*, определяет режим нормализации текста. NFC означает, что символы должны быть полноценными (то есть по возможности использовать только одну кодирующую последовательность). NFD означает, что символы должны быть декомпозированными, то есть разделенными на комбинирующиеся символы. 

Python также поддерживает режимы нормализации NFKC и NFKD, которые добавляют возможности совместимости, которые позволяют работать с определенными типами символов. Например:
```python
>>> s = '\ufb01'  # A single character
>>> s
'ﬁ'
>>> unicodedata.normalize('NFD', s)
'ﬁ'

# Notice how the combined letters are broken apart here
>>> unicodedata.normalize('NFKD', s)
'fi'
>>> unicodedata.normalize('NFKC', s)
'fi'
>>>
``` 

### Обсуждение
Нормализация — это важная часть любой программы, в которой присутствует необходимость обработки текста в Unicode разумным и единообразным способом. Это особенно важно, когда обрабатываемые строки поступают из пользовательского ввода, кодировку которого вы практически никак не контролируете.

Нормализация (приведение) также может быть важной частью чистки и фильтрации текста. Предположим, например, что вы хотите удалить из текста диакритические знаки (возможно, для цели поиска совпадений):
```python
>>> t1 = unicodedata.normalize('NFD', s1)
>>> ''.join(c for c in t1 if not unicodedata.combining(c))
'Spicy Jalapeno'
>>>
```     

Последний пример демонстрирует еще один важный аспект модуля *unicodedata*, а именно полезные функции для проверки принадлежности символов к определенным классам символов. Функция *combining()* проверяет, является ли символ объединяющимся. В этом модуле есть и другие функции для поиска символов определенных категорий, проверки цифр и так далее.

Unicode — весьма обширная тема. Для более подробной информации о нормализации посетите [соответствующую страницу](http://www.unicode.org/faq/normalization.html) на сайте Unicode. Нед Батчелдер также разместил на своем сайте [отличную презентацию](http://nedbatchelder.com/text/unipain.html) о решении проблем, связанных с Unicode в Python.  

## 2.10. Использование символов Unicode в регулярных выражениях
### Задача
Вы используете регулярные выражения для обработки текста, однако беспокоитесь о правильном взаимодействии с символами Unicode.

### Решение
По умолчанию модуль *re* уже имеет некоторые зачаточные представления о некоторых типах символов Unicode. Например, \\d совпадает с любым цифровым символом Unicode:
```python
>>> import re
>>> num = re.compile('\d+')
>>> # ASCII digits
>>> num.match('123')
<_sre.SRE_Match object at 0x1007d9ed0>

>>> # Arabic digits
>>> num.match('\u0661\u0662\u0663')
<_sre.SRE_Match object at 0x101234030>
>>>
```

Если вам нужно включить специфические символы Unicode в шаблоны, вы можете использовать обычные последовательности для экранирования символов Unicode (например, \uFFFF или \UFFFFFFF). Например, вот регексп, который найдет совпадения со всеми символами в нескольких разных арабских страницах:
```python
>>> arabic = re.compile('[\u0600-\u06ff\u0750-\u077f\u08a0-\u08ff]+')
>>>
```

При выполнении поиска совпадений следует нормализовывать и по возможноости чистить текст, приводя его к стандартной форме (см. **рецепт 2.9.**) Также нужно знать о некоторых специальных случаях. Например, рассмотрим поведение нечувствительного к регистру поиска совпадений при объединении с приведением к одному регистру:
```python
>>> pat = re.compile('stra\u00dfe', re.IGNORECASE)
>>> s = 'straße'
>>> pat.match(s)  # Matches
<_sre.SRE_Match object at 0x10069d370>
>>> pat.match(s.upper())  # Doesn't match
>>> s.upper()  # Case folds
'STRASSE'
>>>
```

### Обсуждение
Смешивание Unicode и регулярных выражений — отличный способ взорвать себе голову. Если вы собираетесь серьезно в это погрузиться, установите не включенную в стандартную поставку Python библиотеку [regex](https://pypi.python.org/pypi/regex), в которой есть полная поддержка приведения текстов в Unicode к одному регистру, а также множество других интересных возможностей, включая аппроксимирующий поиск совпадений.

## 2.11. Убирание нежелательных символов из строк
### Задача
Вы хотите убрать ненужные символы, такие как пробелы в начале, конце или середине текстовой строки.

### Решение
Метод *strip()* можно использовать для срезания символов в начале или конце строки. *lstrip()* и *rstrip()* выполняют срезание слева и справа соответственно. По умолчанию они срезают пробел, однако им можно передать и другие символы. Например:
```python
>>> # Whitespace stripping
>>> s = ' hello world  \n'
>>> s.strip()
'hello world'
>>> s.lstrip()
'hello world \n'
>>> s.rstrip()
' hello world'

>>>
>>> # Character stripping
>>> t = '-----hello====='
>>> t.lstrip('-')
'hello====='
>>> t.strip('-=')
'hello'
>>>
``` 

### Обсуждение
Различные методы *strip()* часто используются при чтении и чистке данных для последующей обработки. Например, вы можете использовать их, чтобы избавиться от пробелов, удалить кавычки и т.д.

Обратите внимание, что срезание символов нельзя применить к тексту в середине строки. Например:
```python
>>> s = ' hello world  \n'
>>> s = s.strip()
>>> s
'hello world'
>>>
```

Если вам нужно что-то сделать с внутренним пробелом, вам нужно применить другой приём, такой как использование метода *replace()* или подстановку с использованием регулярного выражения. Например:
```python
>>> s.replace(' ', '')
'helloworld'
>>> import re
>>> re.sub('\s+', ' ', s)
'hello world'
>>>
```

Часто вам нужно сочетать срезание символов с другими видами итерационной обработки, таким как чтением строк данных из файла. Если это так, то стоит применить выражение-генератор:
```python
with open(filename) as f:
	lines = (line.strip() for line in f)
	for line in lines:
		...
```

Здесь выражение *lines = (line.strip() for line in f)* работает как преобразователь данных. Это эффективно, потому что оно не читает данные из какого-либо временного списка. Оно просто создает итератор, где ко всем производимым строкам применена операция срезания символов.

Для более продвинутого срезания вам стоит обратиться к методу *translate()*. Детали вы найдете в следующем рецепте, где описана чистка строк.

## 2.12. Чистка строк
### Решение
Некий деятель ввел текст “pýtĥöñ” в форму на вашей веб-странице, и вы хотите как-то почистить эту строку.

### Решение
Проблема чистки текста применяется к широкому спектру задач с использованием парсинга текста и обработки данных. На самом простом уровне вы можете использовать простые строковые функции (например, *str.upper()* и *str.lower()* для приведения текста к стандартному регистру). Простые замены с использованием *str.replace()* или *re.sub()* помогут справиться с удалением или изменением некоторых специфических последовательностей символов. Вы также можете нормализовать текст, используя функцию *unicodedata.normalize()*, как показано в **рецепте 2.9.**

Однако вы можете пожелать сделать следующий шаг в процессе чистки. Предположим, например, что вы хотите удалить целые диапазоны символов или удалить диакритические знаки. Для этого вы можете обратиться к методу *str.translate()*. Предположим, у вас есть вот такая замусоренная строка:
```python
>>> s = 'pýtĥöñ\fis\tawesome\r\n'
>>> s
'pýtĥöñ\x0cis\tawesome\r\n'
>>>
```

Первый шаг — удалить пробел. Сделаем небольшую таблицу перевода и задействуем *translate()*:
```python
>>> remap = {
...   ord('\t') : ' ',
...   ord('\f') : ' ',
...   ord('\r') : None  # Deleted
... }
>>> a = s.translate(remap)
>>> a
'pýtĥöñ is awesome\n'
>>>
```

Как вы можете увидеть, символы пробелов, такие как \t и \f, были приведены к единой форме. Символ возврата каретки \r был удален. 

Вы можете продолжить идею и создать намного более крупные таблицы перевода. Например, давайте удалим все комбинирующиеся символы:
```python
>>> import unicodedata
>>> import sys
>>> cmb_chrs = dict.fromkeys(c for c in range(sys.maxunicode)
...   if unicodedata.combining(chr(c)))
...
>>> b = unicodedata.normalize('NFD', a)
>>> b
'pýtĥöñ is awesome\n'
>>> b.translate(cmb_chrs)
'python is awesome\n'
>>>
``` 

В последнем примере с помощью *dict.fromkeys()* был создан словарь, отображающий все комбинирующиеся символы Unicode на None. 

Первоначальные вводные данные затем были нормализованы в декомпозированную форму с использованием *unicodedata.normalize()*. Далее функция *translate()* используется для удаления значков. Похожие приёмы могут быть использованы для удаления символов другого типа (например, управляющих символов). 

Ещё один пример — таблица перевода, которая отображает все десятичные цифры Unicode на их эквиваленты в ASCII:
```python
>>> digitmap = { c: ord('0') + unicodedata.digit(chr(c))
...   for c in range(sys.maxunicode)
...   if unicodedata.category(chr(c)) == 'Nd' }
...
>>> len(digitmap)
460
>>> # Arabic digits
>>> x = '\u0661\u0662\u0663'
>>> x.translate(digitmap)
'123'
>>>
```

Ещё один приём для чистки текста использует функции кодирования и декодирования ввода-вывода. Идея состоит в выполнении некоторой первичной очистки текста, а затем пропускании его через encode() и decode() для срезания символов или изменения. Например:
```python
>>> a
'pýtĥöñ is awesome\n'
>>> b = unicodedata.normalize('NFD', a)
>>> b.encode('ascii', 'ignore').decode('ascii')
'python is awesome\n'
>>>
```

Здесь процесс нормализации разложил исходный текст на символы вместе с отдельными комбинирующимися символами. Последовательное кодирование и декодирование в ASCII просто удаляет все эти эти символы. Естественно, это сработает только в том случае, если нашей целью было получение ASCII-представления.

### Обсуждение
Большой проблемой с чисткой текста может стать производительность. Общее правило: чем проще обработка, тем быстрее она работает. Для простых замен метод *str.replace()* часто оказывается самым быстрым способом — даже если вызывать его несколько раз. Например, чтобы вычистить пробелы, вы можете использовать такую программу:
```python
def clean_spaces(s):
s = s.replace('\r', '')
s = s.replace('\t', ' ')
s = s.replace('\f', ' ')
return s
``` 

Если вы попробуете это, то обнаружите, что метод немного быстрее использования *translate()* или регулярных выражений.

С другой стороны, метод *translate()* очень быстр, если вам нужно выполнить любую нетривиальную операцию замены символов на другие символы или удаления символов.

Производительность — это нечто, что вам придется изучать в каждом конкретном приложении. К несчастью, невозможно предложить один приём, который будет работать лучше всего во всех возможных ситуациях, поэтому пробуйте разные подходы и измеряйте результы.

Хотя этот рецепт делает акцент на работе с текстом, похожие приёмы могут быть применены к последовательностям байтов.   


## 2.13. Выравнивание текстовых строк
### Задача
Вам нужно отформатировать текст с применением некого выравнивания.

### Решение
Для базового выравнивания строк можно использовать методы *ljust()*, *rjust()* и *center()*. Например:
```python
>>> text = 'Hello World'
>>> text.ljust(20)
'Hello World '
>>> text.rjust(20)
' Hello World'
>>> text.center(20)
' Hello World '
>>>
```

Все эти методы могут принимать опциональный символ заполнения. Например:
```python
>>> text.rjust(20,'=')
'=========Hello World'
>>> text.center(20,'*')
'****Hello World*****'
>>>
``` 

Функция *format()* также может быть использована для выравнивания. Вам нужно просто использовать символы <, > или ^ вместе с желаемой шириной. Например:
```python
>>> format(text, '>20')
' Hello World'
>>> format(text, '<20')
'Hello World '
>>> format(text, '^20')
' Hello World '
>>>
```

Если вы хотите использовать в качестве заполняющего символа не пробел, определите его перед символом выравнивания:
```python
>>> format(text, '=>20s')
'=========Hello World'
>>> format(text, '*^20s')
'****Hello World*****'
>>>
```

Эти коды форматирования могут быть также использованы с методом *format()* при обработке нескольких значений. Например:
```python
>>> '{:>10s} {:>10s}'.format('Hello', 'World')
' Hello World'
>>>
```

У *format()* есть преимущество — он работает не только со строками. Он работает с любыми значениями, что делает его назначение очень широким. Например, вы можете использовать его с числами:
```python
>>> x = 1.2345
>>> format(x, '>10')
' 1.2345'
>>> format(x, '^10.2f')
' 1.23 '
>>>
```

### Обсуждение
В старых программах вы также можете увидеть, как для форматирования текста использовался оператор %. Например:
```python
>>> '%-20s' % text
'Hello World '
>>> '%20s' % text
' Hello World'
>>>
```  

Однако в новых программах вы должны предпочитать функцию или метод *format()*. Онам намного мощнее оператора %. Более того, *format()* может применяться более широко, нежели строковые методы *ljlust()*, *rjust()* или *center()*, поскольку работает с любыми объектами. 

За полным списком возможностей функции *format()* обратитесь к [документации Python](https://docs.python.org/3/library/string.html#formatspec).

## 2.14. Объединение и конкатенация строк
### Задача
Вам нужно объединить много небольших строк в большую строку. 

### Решение
Если строки, которые вы хотите объединить, находятся в последовательности или итерируемом объекте, самый быстрый способ — использовать метод *join()*. Например:
```python
>>> parts = ['Is', 'Chicago', 'Not', 'Chicago?']
>>> ' '.join(parts)
'Is Chicago Not Chicago?'
>>> ','.join(parts)
'Is,Chicago,Not,Chicago?'
>>> ''.join(parts)
'IsChicagoNotChicago?'
>>>
```

На первый взгляд синтаксис может показаться странным, однако операция *join()* относится к строковым методам. Объекты, которые вы хотите объединить, могут приходить из разнообразных последовательностей данных: (списки, кортежи, словари, файлы, множества или генераторы), поэтому было бы избыточным имплементировать метод *join()* для всех этих объектов. Поэтому вы просто задаете нужную строку-разделитель, а затем применяете метод *join()* для склеивания текстовых фрагментов.

Если вы просто объединяете несколько строк, неплохо сработает \+:
```python
>>> a = 'Is Chicago'
>>> b = 'Not Chicago?'
>>> a + ' ' + b
'Is Chicago Not Chicago?'
>>>
```

Оператор \+ также отлично работает в качестве замены более сложным операциям форматирования строк. Например:
```python
>>> print('{} {}'.format(a,b))
Is Chicago Not Chicago?
>>> print(a + ' ' + b)
Is Chicago Not Chicago?
>>>
```

Если вы пытаетесь объединить строковые литералы в исходном коде, вы можете просто разместить их рядом без использования оператора \+. Например:
```python
>>> a = 'Hello' 'World'
>>> a
'HelloWorld'
>>>
```

### Обсуждение
Объединение строк может показаться недостаточно сложным, чтобы писать про него целый рецепт, но часто эта область является критически важной для производительности. 

Важно знать, что использование оператора \+ для объединения большого количества строк крайне неэффективно, посколько в памяти создаются копии, что прибавляет работы сборщику мусора. Никогда не пишите такой код для объединения строк:
```python
s = ''
for p in parts:
	s += p
```

Это работает заметно медленнее метода *join()*, главным образом потому, что каждая \+= операция создает новый строковый объект. Намного лучше собрать все части и только затем объединить.

Еще один классный фокус из этой области — преобразование данных в строки и конкатенация с одновременным использованием выражения-генератора, как описано в **рецепте 1.19.** Например:
```python
>>> data = ['ACME', 50, 91.1]
>>> ','.join(str(d) for d in data)
'ACME,50,91.1'
>>>
```

Берегитесь ненужной конкатенации. Иногда программисты применяют конкатенацию там, где это не нужно. Например:
```python
print(a + ':' + b + ':' + c)  # Ugly
print(':'.join([a, b, c]))  # Still ugly

print(a, b, c, sep=':')  # Better
```

Смешивание операций ввода-вывода и конкатенации строк — момент, с которым нужно быть очень внимательными. Наример, рассмотрим два фрагмента кода:
```python
# Version 1 (string concatenation)
f.write(chunk1 + chunk2)

# Version 2 (separate I/O operations)
f.write(chunk1)
f.write(chunk2)
```

Если две строки невелики, первая может предложить намного большую производительность благодаря дороговизне системного вызова ввода-вывода. Однако если строки велики, вторая версия может быть более эффективной, поскольку в это случае не создается огромный промежуточный результат и не происходит копирования больших блоков памяти. Пробуйте на своих данных и выясняйте, что работает быстрее в вашем конкретном случае.

И последнее: если вы пишите код, который формирует результат из множества небольших строк, подумайте о том, чтобы оформить его как генератор, используя *yield* для производства фрагментов. Например:
```python
def sample():
yield 'Is'
yield 'Chicago'
yield 'Not'
yield 'Chicago?'
```

Интересно, что этот подход не делает предположений по поводу того, как фрагменты будут собираться вместе. Например, вы можете просто объединить фрагменты с помощью *join()*:
```python
text = ''.join(sample())
```

Или же вы можете перенаправить фрагменты на вывод:
```python
for part in sample():
	f.write(part)
```

Или же вы можете создать некую гибридную схему, что умно с точки зрения операций ввода-вывода:
```python
def combine(source, maxsize):
	parts = []
	size = 0
	for part in source:
		parts.append(part)
		size += len(part)
		if size > maxsize:
			yield ''.join(parts)
			parts = []
			size = 0
	yield ''.join(parts)

for part in combine(sample(), 32768):
	f.write(part)
```

Ключевой момент в том, что первоначальный генератор не обязан знать деталей: он просто выдает части.



## 2.15. Интерполяция переменных в строках
## Задача
Вы хотите создать строку, в которой на место переменных будут подставляться строковые представления значений этих переменных.

### Решение
В Python нет прямой поддержки простой подстановки значений переменных в строках. Однако строковый метод *format()* предоставляет приближенную по смыслу возможность: Например:
```python
>>> s = '{name} has {n} messages.'
>>> s.format(name='Guido', n=37)
'Guido has 37 messages.'
>>>
``` 

Если значения, которые должны быть подставлены, на самом деле находятся в переменных, вы можете использовать сочетание *format_map()* и *vars()*, как показано тут:
```python
>>> name = 'Guido'
>>> n = 37
>>> s.format_map(vars())
'Guido has 37 messages.'
>>>
```

Стоит отметить, что *vars()* также работает с экземплярами. Например:
```python
>>> class Info:
...   def __init__(self, name, n):
...   self.name = name
...   self.n = n
...
>>> a = Info('Guido',37)
>>> s.format_map(vars(a))
'Guido has 37 messages.'
>>>
```

Недостаток *format()* и *format(map)* в том, что они не могут аккуратно справиться с отсутствующими значениями. Например:
```python
>>> s.format(name='Guido')
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
KeyError: 'n'
>>>
```

Этого можно избежать путём определения альтернативный класс словаря с методом *__missing__()*, как показано ниже:
```python
class safesub(dict):
	def __missing__(self, key):
		return '{' + key + '}'
```

Теперь этот класс можно использовать, чтобы обернуть значения, которые подаются на вход в *format_map()*:
```python
>>> del n  # Make sure n is undefined
>>> s.format_map(safesub(vars()))
'Guido has {n} messages.'
>>>
``` 

Если вы обнаружите, что часто делаете такие вещи в своей программе, вы можете спрятать процесс подстановки переменных в небольшую функцию, которая использует так называемый “frame hack”. Например:
```python
import sys
def sub(text):
	return text.format_map(safesub(sys._getframe(1).f_locals))
```

Теперь вы можете делать вот так:
```python
>>> name = 'Guido'
>>> n = 37
>>> print(sub('Hello {name}'))
Hello Guido
>>> print(sub('You have {n} messages.'))
You have 37 messages.
>>> print(sub('Your favorite color is {color}'))
Your favorite color is {color}
>>>
```

### Обсуждение
Отсутствие настоящей интерполяции переменных в Python привело к созданию разнообразных решений. В качестве альтернативы описанным выше решениям, вы иногда можете увидеть такой подход к форматированию строк:
```python
>>> name = 'Guido'
>>> n = 37
>>> '%(name) has %(n) messages.' % vars()
'Guido has 37 messages.'
>>>
```

Или же вам могут попасться строки-темплейты:
```python
>>> import string
>>> s = string.Template('$name has $n messages.')
>>> s.substitute(vars())
'Guido has 37 messages.'
>>>
```

Однако методы *format()* и *format_map()* являеются более современными, нежели эти альтернативы, и отдавать предпочтение нужно им. Преимущество использования *format()* заключается в том, что вы также получаете все возможности форматирования строк (выравнивание, отступы, нумерация и т.п.), что недоступно для альтернативных решений, таких как строковые объекты *Template*.

В этом рецепте нам также удалось показать несколько интересных продвинутых возможностей. Малоизвестный метод классов словарей и отображений *__missing()__* позволяет вам определить подход для работы с отсутствующими значениями. В классе *safesub* этот метод был определен таким образом, чтобы возвращать отсутствующие значения в форме заглушки (плейсхолдера). Вместо того, чтобы получить исключение *KeyException*, вы увидите отсутствующие значения появляющимися в строке-результате (что может оказаться полезным для дебаггинга).

Функция *sub()* использует *sys._getframe(1)* чтобы вернуть фрейм стека вызывающего. Отсюда атрибут *f_locals* доступен, чтобы получить локальные переменные. Стоит отметить, что игр с фреймами стека стоит избегать. Однако для утилитарных функций типа строковой подстановки это может оказаться полезным. Отдельно заметим, что *f_locals* — это словарь, который является копией локальных переменных в вызывающей функции. Хотя вы можете изменить содержимое *f_locals*, эти изменения не станут постоянными. Поэтому, хотя доступ другому фрейму стека и может показаться адским злом, невозможно случайно переписать переменные или изменить локальное окружение вызывающей функции (caller).   

## 2.16. Разбивка текста на фиксированное количество колонок
### Задача
У вас есть длинные строки, которые вы хотите переформатировать таким образом, чтобы они распределились по заданному пользователем количеству колонок.

### Решение
Используйте модуль *textwrap* для переформатирования выводимого текста. Предположим, например, что у вас есть такая длинная строка:
```python
s = "Look into my eyes, look into my eyes, the eyes, the eyes, \
the eyes, not around the eyes, don't look around the eyes, \
look into my eyes, you're under."
```

Вот как вы можете использовать модуль *textwrap* чтобы переформатировать её различным образом:
```python
>>> import textwrap
>>> print(textwrap.fill(s, 70))
Look into my eyes, look into my eyes, the eyes, the eyes, the eyes,
not around the eyes, don't look around the eyes, look into my eyes,
you're under.

>>> print(textwrap.fill(s, 40))
Look into my eyes, look into my eyes,
the eyes, the eyes, the eyes, not around
the eyes, don't look around the eyes,
look into my eyes, you're under.

>>> print(textwrap.fill(s, 40, initial_indent=' '))
Look into my eyes, look into my
eyes, the eyes, the eyes, the eyes, not
around the eyes, don't look around the
eyes, look into my eyes, you're under.

>>> print(textwrap.fill(s, 40, subsequent_indent=' '))
Look into my eyes, look into my eyes,
the eyes, the eyes, the eyes, not
around the eyes, don't look around
the eyes, look into my eyes, you're
under.
```

### Обсуждение
Модуль *textwrap* — это простой способ очистить текст — особенно если вы хотите, чтобы вывод соответствовал размерам терминала. К вопросу о размере терминала: вы можете получить его, используя *os.get_terminal_size()*. Например: 
```python
>>> import os
>>> os.get_terminal_size().columns
80
>>>
```

У метода *fill()* есть неколько дополнительных параметров, которые контролируют то, как он обращается с табуляцией, окончаниями предложений и т.д. За подробностями обратитесь к [документации класса textwrap.TextWrapper](https://docs.python.org/3.3/library/textwrap.html#textwrap.TextWrapper).


## 2.17. Работа с HTML- и XML-сущностями в тексте
### Задача
Вы хотите заменить HTML- и XML-сущности, такие как *&entity;* или *&\#code;*, соответствующим текстом. Или же вам нужно произвести текст, но экранировать некоторые символы (например, <, > или &).

### Решение
Если вы производите текст, довольно просто заменить спецсимволы типа < или > с помощью функции *html.escape()*. Например:
```python
>>> s = 'Elements are written as "<tag>text</tag>".'
>>> import html
>>> print(s)
Elements are written as "<tag>text</tag>".
>>> print(html.escape(s))
Elements are written as &quot;&lt;tag&gt;text&lt;/tag&gt;&quot;.

>>> # Disable escaping of quotes
>>> print(html.escape(s, quote=False))
Elements are written as "&lt;tag&gt;text&lt;/tag&gt;".
>>>
```

Если вы хотите произвести текст в кодировке ASCII и вставить коды символов вместо отсутствующих в ASCII символов, вы можете использовать аргумент *errors='xmlcharrefreplace'* с различными функциями ввода-вывода. Например:
```python
>>> s = 'Spicy Jalapeño'
>>> s.encode('ascii', errors='xmlcharrefreplace')
b'Spicy Jalape&#241;o'
>>>
```

Чтобы заменить сущности в тексте, нужен другой подход. Если обрабатываете HTML или XML, попробуйте для начала настоящий парсер HTML или XML. Обычно эти инструменты автоматически позаботятся о замене значений во время парсинга, и вам не придётся об этом беспокоиться. 

Если же по каким-то причинам вы получили голый текст с включением сущностей, и вы хотите заменить их вручную, вы сможете сделать это с помощью различных функций и методов, связанных с парсерами HTML и XML. Например:
```python
>>> s = 'Spicy &quot;Jalape&#241;o&quot.'
>>> from html.parser import HTMLParser
>>> p = HTMLParser()
>>> p.unescape(s)
'Spicy "Jalapeño".'
>>>

>>> t = 'The prompt is &gt;&gt;&gt;'
>>> from xml.sax.saxutils import unescape
>>> unescape(t)
'The prompt is >>>'
>>>
``` 

### Обсуждение
О правильном экранировании спецсимволов при генерировании HTML или XML легко забыть. Это особенно верно, если вы генерируете вывод самостоятельно, используя *print()* или другую базовую функцию строкового форматирования. Есть простое решение — использовать функции типа *html.escape()*.

Если вам нужно произвести обратное преобразование текста, к вашим услугам различные фукции типа *xml.sax.saxutils.unescape()*. Однако мы все же рекомендуем использовать парсер. Например, если при обработке HTML и XML использовать такие парсеры как *html.parser* или *xml.etree.ElementTree*, они самостоятельно позаботятся о замене сущностей в тексте.

## 2.18. Токенизация текста
### Задача
У вас есть строка, которую вы хотите распарсить в поток токенов слева направо.

### Решение
Предположим, у вас есть вот такая строка:
```python
text = 'foo = 23 + 42 * 10'
```

Чтобы токенизировать строку, вам нужно нечто большее, чем простой поиск по шаблонам. Вам также нужен способ определить тип шаблона. Например, вы можете захотеть превратить строку в последовательность пар:
```python
tokens = [('NAME', 'foo'), ('EQ','='), ('NUM', '23'), ('PLUS','+'),
('NUM', '42'), ('TIMES', '*'), ('NUM', 10')]
```

Для разрезания такого типа первым шагом должно быть определение всех возможных токенов, включая пробелы, с помошью шаблонов регулярных выражений, использующих именованные захватывающие группы:
```python
import re
NAME = r'(?P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'
NUM  = r'(?P<NUM>\d+)'
PLUS = r'(?P<PLUS>\+)'
TIMES = r'(?P<TIMES>\*)'
EQ  = r'(?P<EQ>=)'
WS  = r'(?P<WS>\s+)'

master_pat = re.compile('|'.join([NAME, NUM, PLUS, TIMES, EQ, WS]))
```

В этих шаблонах условие *?P<TOKENNAME>* используется для присваивания имени шаблону. Это мы используем позже.

Далее, для собственно токенизации, используем малоизвестный метод объектов шаблонов *scanner()*. Этот метод создает объект сканера, в котором повторно вызывается шаг *match()* для предоставленного текста, выполняя один поиск совпадения за раз. Вот интерактивный пример работы объекта сканера:
```python
>>> scanner = master_pat.scanner('foo = 42')
>>> scanner.match()
<_sre.SRE_Match object at 0x100677738>
>>> _.lastgroup, _.group()
('NAME', 'foo')
>>> scanner.match()
<_sre.SRE_Match object at 0x100677738>
>>> _.lastgroup, _.group()
('WS', ' ')
>>> scanner.match()
<_sre.SRE_Match object at 0x100677738>
>>> _.lastgroup, _.group()
('EQ', '=')
>>> scanner.match()
<_sre.SRE_Match object at 0x100677738>
>>> _.lastgroup, _.group()
('WS', ' ')
>>> scanner.match()
<_sre.SRE_Match object at 0x100677738>
>>> _.lastgroup, _.group()
('NUM', '42')
>>> scanner.match()
>>>
```

Чтобы взять это приём и использовать в программе, он должен быть очищен и упакован в генератор:
```python
from collections import namedtuple

Token = namedtuple('Token', ['type','value'])

def generate_tokens(pat, text):
	scanner = pat.scanner(text)
		for m in iter(scanner.match, None):
			yield Token(m.lastgroup, m.group())

# Example use
for tok in generate_tokens(master_pat, 'foo = 42'):
	print(tok)

# Produces output
# Token(type='NAME', value='foo')
# Token(type='WS', value=' ')
# Token(type='EQ', value='=')
# Token(type='WS', value=' ')
# Token(type='NUM', value='42')
```

Если вы хотите как-то отфильтровать поток токенов, вы можете либо определить больше генераторов, либо использовать выражение-генератор. Например, вот так можно отфильтровать все токены-пробелы:
```python
tokens = (tok for tok in generate_tokens(master_pat, text)
	if tok.type != 'WS')
for tok in tokens:
	print(tok)
```

### Обсуждение
Токенизация часто является первым шагом более продвинутого парсинга и обработки текста. Чтобы использовать показанные приёмы сканирования, нужно держать в уме несколько важных моментов. Во-первых, вы должны убедиться, что вы определили соответствующие шаблоны регулярных выражений для всех возможных текстовых последовательностей, которые могут встретиться во входных данных. Если встретится текст, для которого нельзя найти совпадение, сканирование просто остановится. Вот почему необходимо было определить токен пробела (WS) в примере выше.

Порядок токенов в главном регулярном выражении также важен. При поиске совпадений регулярное выражение пытается отыскать совпадения с шаблонами в заданном порядке. Поэтому если шаблон окажется подстрокой более длинного шаблона, вы должны убедиться, что более длинный шаблон вписан в выражение первым. Например:
```python
LT = r'(?P<LT><)'
LE = r'(?P<LE><=)'
EQ = r'(?P<EQ>=)'

master_pat = re.compile('|'.join([LE, LT, EQ]))  # Correct
# master_pat = re.compile('|'.join([LT, LE, EQ])) # Incorrect
```

Второй шаблон неправильный, потому что он будет отыскивать совпадение с <=, поскольку за токеном LT следует токен EQ, а не LE.

И последнее: вы должны следить за шаблонами, формирующими подстроки. Предположим, например, что у вас есть два шаблона:
```python
PRINT = r'(P<PRINT>print)'
NAME  = r'(P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'

master_pat = re.compile('|'.join([PRINT, NAME]))

for tok in generate_tokens(master_pat, 'printer'):
	print(tok)

# Outputs :
# Token(type='PRINT', value='print')
# Token(type='NAME', value='er')
```

Для более продвинутого токенизирования вы можете обратиться к пакетам [PyParsing](http://pyparsing.wikispaces.com/) или [PLY](http://www.dabeaz.com/ply/index.html). Пример использования PLY вы найдете в следующем рецепте.

## 2.19. Написание простого парсера на основе метода рекурсивного спуска
### Задача
Вам нужно распарсить текст в соответствии с грамматическими правилами и выполнить действия или построить абстрактное синтаксическое дерево, представляющее входные данные.

### Решение
В этой задаче мы сосредоточены на парсинге текста в соответствии с некоторой определенной грамматикой. Чтобы это сделать, вы должны начать с формальной спецификации грамматики в форме BNF (БНФ, форма Бэкуса — Наура) или EBNF (РБНФ, расширенная форма Бэкуса — Наура). Например, грамматика для простых арифметических выражений может выглядеть так:

	expr ::= expr + term
		| expr - term
		| term
	
	term ::= term * factor
		| term / factor
		| factor
	
	factor ::= ( expr )
		| NUM

А вот альтернативная форма РБНФ:

	expr ::= term { (+|-) term }*

	term ::= factor { (*|/) factor }*

	factor ::= ( expr )
		| NUM

В РБНФ части правил, заключенные в { ... }\* являются необязательными. \* означает ноль и более повторений (то есть имеет такое значение, как и в регулярных выражениях).

Теперь, если вы незнакомы с механизмом работы БНФ, думайте о ней как об определении правил замены или подстановки, где символы слева могут быть заменены символами справа (или наоборот). В общем, во время парсинга вы пытаетесь сопоставить входящий текст с грамматикой, делая различные подстановки и расширения с использованием БНФ. Чтобы проиллюстрировать это, предположим, что вы парсите выражение 3 \+ 4 \* 5. Это выражение должно быть сначала разбито на поток токенов с использованием описанных в **рецепте 2.18.** приёмов. Результатом будет последовательность токенов:

	NUM + NUM * NUM

С этого момента парсинг начинает пытаться сопоставить грамматику с входящими токенами, делая подстановки:

	expr
	expr ::= term { (+|-) term }*
	expr ::= factor { (*|/) factor }* { (+|-) term }*
	expr ::= NUM { (*|/) factor }* { (+|-) term }*
	expr ::= NUM { (+|-) term }*
	expr ::= NUM + term { (+|-) term }*
	expr ::= NUM + factor { (*|/) factor }* { (+|-) term }*
	expr ::= NUM + NUM { (*|/) factor}* { (+|-) term }*
	expr ::= NUM + NUM * factor { (*|/) factor }* { (+|-) term }*
	expr ::= NUM + NUM * NUM { (*|/) factor }* { (+|-) term }*
	expr ::= NUM + NUM * NUM { (+|-) term }*
	expr ::= NUM + NUM * NUM

Чтобы пройти по всем шагам подстановки и разобраться, придётся потратить время, но в целом они работают так: смотрят на входящие данные и пытаются сопоставить их с правилами грамматики. Первый входящий токен — это NUM, поэтому подстановки сначала сосредотачиваются на поиске совпадений с этой частью. Когда совпадение найдено, внимание переходит к следующему токену \+ и т.д. Некоторые части правой стороны (например, { (\*/) factor }\*) иcчезают, когда определено, что они не совпадают со следующим токеном. Парсинг проходит успешно, если правая сторона достаточно полна, чтобы охватить все входящие токены. 

Со всей вышеизложенной вводной информацией перейдем к простому рецепту построения «выполнителя» выражений, работающего по методу рекурсивного спуска:
```python
import re
import collections

# Token specification
NUM  = r'(?P<NUM>\d+)'
PLUS  = r'(?P<PLUS>\+)'
MINUS  = r'(?P<MINUS>-)'
TIMES  = r'(?P<TIMES>\*)'
DIVIDE = r'(?P<DIVIDE>/)'
LPAREN = r'(?P<LPAREN>\()'
RPAREN = r'(?P<RPAREN>\))'
WS  = r'(?P<WS>\s+)'

master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES,
                                  DIVIDE, LPAREN, RPAREN, WS]))

# Tokenizer
Token = collections.namedtuple('Token', ['type','value'])

def generate_tokens(text):
	scanner = master_pat.scanner(text)
	for m in iter(scanner.match, None):
		tok = Token(m.lastgroup, m.group())
		if tok.type != 'WS':
			yield tok

# Parser
class ExpressionEvaluator:
	'''
	Implementation of a recursive descent parser. Each method
	implements a single grammar rule. Use the ._accept() method
	to test and accept the current lookahead token. Use the ._expect()
	method to exactly match and discard the next token on on the input
	(or raise a SyntaxError if it doesn't match).
	'''

	def parse(self,text):
		self.tokens = generate_tokens(text)
		self.tok = None  # Last symbol consumed
		self.nexttok = None  # Next symbol tokenized
		self._advance()  # Load first lookahead token
		return self.expr()

	def _advance(self):
		'Advance one token ahead'
		self.tok, self.nexttok = self.nexttok, next(self.tokens, None)

	def _accept(self,toktype):
		'Test and consume the next token if it matches toktype'
		if self.nexttok and self.nexttok.type == toktype:
			self._advance()
			return True
		else:
			return False

	def _expect(self,toktype):
		'Consume next token if it matches toktype or raise SyntaxError'
		if not self._accept(toktype):
			raise SyntaxError('Expected ' + toktype)

	# Grammar rules follow

	def expr(self):
		"expression ::= term { ('+'|'-') term }*"

		exprval = self.term()
		while self._accept('PLUS') or self._accept('MINUS'):
			op = self.tok.type
			right = self.term()
			if op == 'PLUS':
				exprval += right
			elif op == 'MINUS':
				exprval -= right
			return exprval

	def term(self):
		"term ::= factor { ('*'|'/') factor }*"
		
		termval = self.factor()
		while self._accept('TIMES') or self._accept('DIVIDE'):
			op = self.tok.type
			right = self.factor()
			if op == 'TIMES':
				termval *= right
			elif op == 'DIVIDE':
				termval /= right
		return termval

	def factor(self):
		"factor ::= NUM | ( expr )"

		if self._accept('NUM'):
			return int(self.tok.value)
		elif self._accept('LPAREN'):
			exprval = self.expr()
			self._expect('RPAREN')
			return exprval
		else:
			raise SyntaxError('Expected NUMBER or LPAREN')
```   

Вот пример интерактивного использования класса ExpressionEvaluator:
```python
>>> e = ExpressionEvaluator()
>>> e.parse('2')
2
>>> e.parse('2 + 3')
5
>>> e.parse('2 + 3 * 4')
14
>>> e.parse('2 + (3 + 4) * 5')
37
>>> e.parse('2 + (3 + * 4)')
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
	File "exprparse.py", line 40, in parse
		return self.expr()
	File "exprparse.py", line 67, in expr
		right = self.term()
	File "exprparse.py", line 77, in term
		termval = self.factor()
	File "exprparse.py", line 93, in factor
		exprval = self.expr()
	File "exprparse.py", line 67, in expr
		right = self.term()
	File "exprparse.py", line 77, in term
		termval = self.factor()
	File "exprparse.py", line 97, in factor
		raise SyntaxError("Expected NUMBER or LPAREN")
SyntaxError: Expected NUMBER or LPAREN
>>>
```

Если вы хотите сделать что-то другое, а не только простое вычисление, вам нужно изменить класс ExpressionEvaluator. Например, вот альтернативная имплементация, которая конструирует простое дерево разбора (парсинга):
```python
class ExpressionTreeBuilder(ExpressionEvaluator):
	def expr(self):
		"expression ::= term { ('+'|'-') term }"

		exprval = self.term()
		while self._accept('PLUS') or self._accept('MINUS'):
			op = self.tok.type
			right = self.term()
			if op == 'PLUS':
				exprval = ('+', exprval, right)
			elif op == 'MINUS':
				exprval = ('-', exprval, right)
		return exprval

	def term(self):
		"term ::= factor { ('*'|'/') factor }"
		
		termval = self.factor()
		while self._accept('TIMES') or self._accept('DIVIDE'):
			op = self.tok.type
			right = self.factor()
			if op == 'TIMES':
				termval = ('*', termval, right)
			elif op == 'DIVIDE':
				termval = ('/', termval, right)
		return termval

	def factor(self):
		'factor ::= NUM | ( expr )'

		if self._accept('NUM'):
			return int(self.tok.value)
		elif self._accept('LPAREN'):
			exprval = self.expr()
			self._expect('RPAREN')
			return exprval
		else:
			raise SyntaxError('Expected NUMBER or LPAREN')
```

Вот как это работает:
```python
>>> e = ExpressionTreeBuilder()
>>> e.parse('2 + 3')
('+', 2, 3)
>>> e.parse('2 + 3 * 4')
('+', 2, ('*', 3, 4))
>>> e.parse('2 + (3 + 4) * 5')
('+', 2, ('*', ('+', 3, 4), 5))
>>> e.parse('2 + 3 + 4')
('+', ('+', 2, 3), 4)
>>>
```

### Обсуждение
Парсинг — это обширная тема, освоение которой обычно занимает у студентов первые три недели курса изучения компиляторов. Если вы ищите, где бы почерпнуть знания о грамматиках, алгоритмах разбор и прочую подобную информацию, обратитесь к книгам о компиляторах. Нет нужды говорить, что всё это втиснуть в эту книгу просто невозможно.

Тем не менее, общая идея парсера на основе рекурсивного спуска проста. Для начала вы берете каждое правило грамматики и превращаете его в функцию или метод. Если ваша грамматика выглядит так:

	expr ::= term { ('+'|'-') term }*
	term ::= factor { ('*'|'/') factor }*
	factor ::= '(' expr ')'
	| NUM

То вы начинаете с превращения её в такой набор методов:
```python
class ExpressionEvaluator:
	...
	def expr(self):
		...
	def term(self):
		...
	def factor(self):
		...
```

Задача каждого метода проста: он должен пройти слева направо по каждой части грамматического правила, потребляя токены в процессе. Цель метода — либо потребить правило, либо сгенерировать синтаксическую ошибку в случае застревания. Чтобы реализовать это, применяются следующие приёмы:

* Если следующий символ в правиле является именем другого грамматического правила (например, term или factor), вы просто вызываете метод с этим именем. Это  «спуск» алгоритма — управление спускается в другое грамматическое правило. Иногда правила могут использовать вызовы методов, которые уже выполняются (например, вызов expr в правиле factor ::= '(' expr ')'). Это «рекурсивность» алгоритма.  
* Если следующий символ в правиле должен быть конкретным символом (например, (), вы смотрите на следующий токен и проверяете на точное совпадение. Если он не совпадает, то это синтаксическая ошибка. В этом рецепте для выполнения этих шагов используется метод *_expect()*.
* Если следующий символ в правиле может соответствовать нескольким возможным выборам (например, \+ или -), вы должны проверить следующий токен на каждую из этих возможностей и продвигаться вперед только в том случае, если совпадение найдено. В этом рецепте за это отвечает метод *_accept()*. Он похож на более слабую версию метода *_expect()* — в том отношении, что он продвинется вперед только если совпадение найдено, но если нет, то он просто отступает, не возбуждая ошибку (что позволяет сделать другие проверки).
* Для грамматических правил с повторяющимися частями (как, например, в правиле expr ::= term { ('\+'|'-') term }\*), повторение имплементируется циклом *while*. Тело цикла будет в общем собирать или обрабатывать все повторяющиеся значения, пока они не закончатся.
* Если грамматическое правило потреблено, каждый метод возвращает некий результат тому, кто его вызывал. Так значения передаются во время парсинга. Например, в «вычислителе» выражений возвращаемые значения будут представлять частичные результаты разбираемого выражения. В конце концов они все объединятся в высшем методе грамматического правила, который будет выполнен.

Хотя здесь мы показали простой пример, парсеры на основе рекурсивного спуска могут быть использованы для создания весьма сложных парсеров. Например, код самого Python интерпретируется парсером на основе метода рекурсивного спуска. Если вы заинтересовались, вы можете залезть в файл Grammar/Grammar в исходном коде Python и взглянуть на грамматику под капотом. При всём при этом, конечно, в ручном создании парсеров множество ограничений и ловушек.

Одно из таких ограничений парсеров на основе рекурсивного спуска заключается в том, что они не могут быть написаны для грамматических правил, использующих левую рекурсию. Предположим, например, что вам нужно перевести такое правило:

	items ::= items ',' item
	| item

Чтобы сделать это, вы могли бы использовать метод items():
```python
def items(self):
	itemsval = self.items()
	if itemsval and self._accept(','):
		itemsval.append(self.item())
	else:
		itemsval = [ self.item() ]
```

Единственная проблема в том, что это не работает. Такой код вылетит с ошибкой бесконечной рекурсии. 

Вы можете также столкнуться с хитрыми проблемами, касающимися самих грамматических правил. Например, вы можете поразмышлять над тем, могут ли выражения быть описаны вот такой более простой грамматикой:

	expr ::= factor { ('+'|'-'|'*'|'/') factor }*

	factor ::= '(' expression ')'
	| NUM

Эта грамматика технически «работает», но она не соблюдает стандартные правила порядка вычисления арифметических выражений. Например, для выражения “3 + 4 * 5” оно выдаст результат 35 вместо правильного 23. Чтобы решить эту проблему, нужно использовать отдельные правила expr и term.

Для по-настоящему сложных грамматик лучше использовать инструменты парсинга типа [PyParsing](http://pyparsing.wikispaces.com/) или [PLY](http://www.dabeaz.com/ply/index.html). Вот как выглядит код «вычислителя» выражений, созданный с применением PLY:
```python
from ply.lex import lex
from ply.yacc import yacc

# Token list
tokens = [ 'NUM', 'PLUS', 'MINUS', 'TIMES', 'DIVIDE', 'LPAREN', 'RPAREN' ]

# Ignored characters
t_ignore = ' \t\n'

# Token specifications (as regexs)
t_PLUS  = r'\+'
t_MINUS  = r'-'
t_TIMES  = r'\*'
t_DIVIDE = r'/'
t_LPAREN = r'\('
t_RPAREN = r'\)'

# Token processing functions
def t_NUM(t):
	r'\d+'
	t.value = int(t.value)
	return t

# Error handler
def t_error(t):
	print('Bad character: {!r}'.format(t.value[0]))
	t.skip(1)

# Build the lexer
lexer = lex()

# Grammar rules and handler functions
def p_expr(p):
	'''
	expr : expr PLUS term
	| expr MINUS term
	'''
	if p[2] == '+':
		p[0] = p[1] + p[3]
	elif p[2] == '-':
		p[0] = p[1] - p[3]

def p_expr_term(p):
	'''
	expr : term
	'''
	p[0] = p[1]


def p_term(p):
	'''
	term : term TIMES factor
	| term DIVIDE factor
	'''
	if p[2] == '*':
		p[0] = p[1] * p[3]
	elif p[2] == '/':
		p[0] = p[1] / p[3]

def p_term_factor(p):
	'''
	term : factor
	'''
	p[0] = p[1]

def p_factor(p):
	'''
	factor : NUM
	'''
	p[0] = p[1]


def p_factor_group(p):
	'''
	factor : LPAREN expr RPAREN
	'''
	p[0] = p[2]

def p_error(p):
	print('Syntax error')

parser = yacc()
```

В этой программе вы найдете, что всё определено так же, как и ранее написанном парсере, но на намного более высоком уровне. Вы просто пишете регулярные выражения для токенов и высокоуровневые функции-обработчики, которые выполняются, когда возникают совпадения по различным правилам грамматики. А вся механика работы парсера, приёма токенов и так далее полностью реализована в библиотеке. 

Вот пример использования созданного объекта парсера:
```python
>>> parser.parse('2')
2
>>> parser.parse('2+3')
5
>>> parser.parse('2+(3+4)*5')
37
>>>
```

Если вы хотите сделать свою программерскую жизнь более захватывающей, начните писать парсеры и компиляторы. Повторимся, книги про компиляторы предлагают кучу низкоуровневых подробностей и теории. Множество полезных ресурсов и всякой информации вы также найдете в сети. А в Python есть модуль *ast*, на который также стоит посмотреть.

  
## 2.20. Выполнение текстовых операций над байтовыми строками
### Задача
Вы хотите выполнить стандартные текстовые операции (срезание символов, поиск, замену) над строками байтов.

### Решение
Байтовые строки поддерживают большую часть тех же встроенных операций, что и текстовые строки. Например:
```python
>>> data = b'Hello World'
>>> data[0:5]
b'Hello'
>>> data.startswith(b'Hello')
True
>>> data.split()
[b'Hello', b'World']
>>> data.replace(b'Hello', b'Hello Cruel')
b'Hello Cruel World'
>>>
```

Такие операции можно проделать и над байтовыми массивами:
```python
>>> data = bytearray(b'Hello World')
>>> data[0:5]
bytearray(b'Hello')
>>> data.startswith(b'Hello')
True
>>> data.split()
[bytearray(b'Hello'), bytearray(b'World')]
>>> data.replace(b'Hello', b'Hello Cruel')
bytearray(b'Hello Cruel World')
>>>
```

Вы можете просто применить к байтовым строкам поиск совпадений с помощью регулярных выражений, но сами шаблоны должны быть определены как байты. Например:
```python
>>>
>>> data = b'FOO:BAR,SPAM'
>>> import re
>>> re.split('[:,]',data)
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
    File "/usr/local/lib/python3.3/re.py", line 191, in split
        return _compile(pattern, flags).split(string, maxsplit)
TypeError: can't use a string pattern on a bytes-like object

>>> re.split(b'[:,]',data)  # Notice: pattern as bytes
[b'FOO', b'BAR', b'SPAM']
>>>
```  

### Обсуждение
Практически все доступные для текстовых строк операции будут работать и на байтовых строках. Однако есть несколько заметных отличий, о которых нужно знать. Во-первых, при индексировании байтовых строк мы получаем целые числа, а не символы. Например:
```python
>>> a = 'Hello World'  # Text string
>>> a[0]
'H'
>>> a[1]
'e'
>>> b = b'Hello World'  # Byte string
>>> b[0]
72
>>> b[1]
101
>>>
``` 

Эта разница в семантике может воздействовать на программы, которые пытаются обработать байтовые данные так же, как и текстовые.

Во-вторых, байтовые строки не предоставляют красивые строковые представления и не выводятся в симпатичном виде, если сначала не проведено декодирование в текстовую строку. Например:
```python
>>> s = b'Hello World'
>>> print(s)
b'Hello World' # Observe b'...'
>>> print(s.decode('ascii'))
Hello World
>>>
```

Строковые операции форматирования также недоступны для байтовых строк.
```python
>>> b'%10s %10d %10.2f' % (b'ACME', 100, 490.1)
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
TypeError: unsupported operand type(s) for %: 'bytes' and 'tuple'

>>> b'{} {} {}'.format(b'ACME', 100, 490.1)
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
AttributeError: 'bytes' object has no attribute 'format'
>>>
```

Если вы хотите применить какое-то форматирование к байтовой строке, это должно быть проделано с помощью обычных текстовых строк и последующего кодирования. Например:
```python
>>> '{:10s} {:10d} {:10.2f}'.format('ACME', 100, 490.1).encode('ascii')
b'ACME 100 490.10'
>>>
```

И, наконец, вы должны знать, что использование байтовых строк может изменить семантику некоторых операций — особенно тех, что относятся к файловой системе. Например, если вы предоставляете имя файла закодированным в байтовую строку, а не в текстовую, это обычно отключает кодирование и декодирование имени файла. Например:
```python
>>> # Write a UTF-8 filename
>>> with open('jalape\xf1o.txt', 'w') as f:
...   f.write('spicy')
...

>>> # Get a directory listing
>>> import os
>>> os.listdir('.')  # Text string (names are decoded)
['jalapeño.txt']

>>> os.listdir(b'.')  # Byte string (names left as bytes)
[b'jalapen\xcc\x83o.txt']
>>>
```

Посмотрите, как в последней части этого примера передача имени каталога в виде байтовой строки вызывает возврат имен файлов в виде недекодированных байтов. Имя файла, показанное в списке содержимого каталога, содержит «сырую» кодировку UTF-8. См. **рецепт 5.15.**, в нем обсуждается вопрос работы с именами файлов, имеющий отношение к этому случаю.

Некоторые программисты могут склоняться к использованию байтовых строк в качестве альтернативы текстовым из-за возможного выигрыша в производительности. Да, операции над байтами могут быть немного более эффективными, чем работа с текстом (из-за оверхеда на Unicode), однако такой подход приводит к грязному и неидиоматическому году. Вы будете часто сталкиваться с тем, что байтовые строки не очень хорошо сочетаются с другими частями Python, и вы закончите тем, что будете вручную выполнять всевозможные операции кодирования-декодирования, чтобы всё работало. Так что если вы работаете с текстом, используйте обычные текстовые строки, а не байтовые.


# 3. Числа, даты и время
В Python легко выполненять математические вычисления с целыми числами и числами с плавающей точкой. Однако если вам нужно работать с дробями, массивами или датами и временем, придется приложить больше усилий. Эта глава фокусируется как раз на таких темах.

## 3.1. Округление числовых значений
### Задача
Вы хотите округлить число с плавающей точкой до заданного количества знаков после точки.

### Решение
Для простого округления используйте встроенную функцию *round(value, ndigits)*. Например:
```python
>>> round(1.23, 1)
1.2
>>> round(1.27, 1)
1.3
>>> round(-1.27, 1)
-1.3
>>> round(1.25361,3)
1.254
>>>
``` 

Когда значение попадает точно между двух возможных выборов для округления, эта функция будет округлять к ближайшему чётному значению. То есть 1.5 или 2.5 будут округлены до 2.

Количество знаков, которое передается функции *round()*, может быть отрицательным. В этом случае округление будет идти до десятков, сотен, тысяч и т.д. Например:
```python
>>> a = 1627731
>>> round(a, -1)
1627730
>>> round(a, -2)
1627700
>>> round(a, -3)
1628000
>>>
```

### Обсуждение
Не перепутайте округление с форматированием значения для вывода. Если вы хотите просто вывести число с некоторым определенным количеством знаков после точки, обычно вам не требуется *round()*. Вместо этого просто задайте при форматировании, скоро знаков выводить. Пример:
```python
>>> x = 1.23456
>>> format(x, '0.2f')
'1.23'
>>> format(x, '0.3f')
'1.235'
>>> 'value is {:0.3f}'.format(x)
'value is 1.235'
>>>
```

Сопротивляйтесь желанию округлить числа с плавающей точкой, чтобы исправить проблемы с точностью вычислений. Например, вы можете склоняться поступить так:
```python
>>> a = 2.1
>>> b = 4.2
>>> c = a + b
>>> c
6.300000000000001
>>> c = round(c, 2)  # "Fix" result (???)
>>> c
6.3
>>>
```

Для большинства программ, работающих с числами с плавающей точкой, просто не нужно (и не рекомендуется) этого делать. Хотя есть незначительные ошибки в вычислениях, поведение этих ошибок понятно и терпимо. Если необходимо избежать таких ошибок (например, это может быть важно для финансовых приложений), попробуйте модуль *decimal*, который обсуждается в следующем рецепте.

## 3.2. Выполнение точных десятичных вычислений   
### Задача
Вам нужно выполнить точные вычисления с десятичными числами, и вы хотите избавиться от небольших ошибок, которые обычно возникают при работе с числами с плавающей точкой.

### Решение
Широко известный недостаток чисел с плавающей точкой в том, что они не могут точно представить все 10 базовых десятичных цифр. Более того, даже простые математические вычисления приводят к появлению небольших ошибок. Например:
```python
>>> a = 4.2
>>> b = 2.1
>>> a + b
6.300000000000001
>>> (a + b) == 6.3
False
>>>
```  

Эти ошибки — не «бага, а фича» процессора и стандарта представления чисел с плавающей точкой IEEE 754, на основе которого работает модуль процессора для выполнения вычислений с плавающей точкой. Поскольку тип данных «числа с плавающей точкой» Python хранит данные, используя нативное представление, вы ничего не можете сделать, чтобы избавиться от ошибок при использовании экземпляров *float*. 

Если вам нужна большая точность (и вы готовы в некоторой степени поступиться производительностью), вы можете использовать модуль *decimal*:
```python
>>> from decimal import Decimal
>>> a = Decimal('4.2')
>>> b = Decimal('2.1')
>>> a + b
Decimal('6.3')
>>> print(a + b)
6.3
>>> (a + b) == Decimal('6.3')
True
>>>
```

На первый взгляд он может показаться странным (например, определение чисел как строк). Однако объекты *Decimal* работают именно так, как вы можете ожидать (поддерживают все обычные математические операции и т.д.) Если вы выводите их или используете функциях форматирования строк, они выглядят как обычные числа.

Главное преимущество *decimal* в том, что он позволяет контролировать различные аспекты вычислений, такие как число знаков после точки и округление. Чтобы это сделать, вы создаете локальный контекст и меняете его установки. Например:
```python
>>> from decimal import localcontext
>>> a = Decimal('1.3')
>>> b = Decimal('1.7')
>>> print(a / b)
0.7647058823529411764705882353
>>> with localcontext() as ctx:
...   ctx.prec = 3
...   print(a / b)
...
0.765
>>> with localcontext() as ctx:
...   ctx.prec = 50
...   print(a / b)
...
0.76470588235294117647058823529411764705882352941176
>>>
```

### Обсуждение
Модуль *decimal* реализует «Общую спецификацию десятичной арифметики» компании IBM (“General Decimal Arithmetic Specification”). Нет нужды упоминать, что у него есть очень много различных опций для конфигурирования, описание которых лежит за пределами возможностей этой книги.

Новички в Python могут склоняться к повсеместному использованию модуля *decimal* для решения проблемы неточности, которая неизбежна при работе с типом данных *float*. Однако важно понимать область применения вашего приложения. Если вы работаете с научными или инженерными данными, компьютерной графикой, то вполне нормально использовать обычный тип данных чисел с плавающей точкой. В общем-то очень немногие вещи в реальном мире измеряются с точностью до 17-го знака после точки, которую предоставляет *float*. Так что небольшие ошибки не так уж важны. А производительность нативных чисел с плавающей точкой заметно выше, а это важно при выполнении большого количества вычислений.

Но вы не должны просто полностью игнорировать ошибки. Математики проводят немало времени, изучая различные алгоритмы, и некоторые обрабатывают ошибки лучше других. Вы также должны быть осторожными с эффектами таких штук как вычитательная потеря точности и сложение больших и маленьких чисел. Например:
```python
>>> nums = [1.23e+18, 1, -1.23e+18]
>>> sum(nums)  # Notice how 1 disappears
0.0
>>>
```

Ошибка из последнего примера может быть решена путем использования *math.fsum()*:
```python
>>> import math
>>> math.fsum(nums)
1.0
>>>
``` 

Однако для других алгоритмов вам придется изучить реализацию и понять, как он работает с точки зрения подобных ошибок. 

Подведем итог: модуль *decimal* используется в основном в финансовых и им подобных приложениях. В таких программах небольшие ошибки в вычислениях ужасно мешают, а *decimal* позволяет от них избавиться. Также часто можно встретить объекты класса *Decimal* в интерфейсах Python к базам данных — опять же, особенно часто их используют для доступа к финансовым данным.

## 3.3. Форматирование чисел для вывода
### Задача
Вам нужно отформатировать число для вывода, контролируя количество знаков, выравнивание, включение разделителя для разрядов и т.д.

### Решение
Чтобы отформатировать одно число для вывода, используйте встроенную функцию *format()*. Например:
```python
>>> x = 1234.56789

>>> # Two decimal places of accuracy
>>> format(x, '0.2f')
'1234.57'

>>> # Right justified in 10 chars, one-digit accuracy
>>> format(x, '>10.1f')
' 1234.6'

>>> # Left justified
>>> format(x, '<10.1f')
'1234.6 '

>>> # Centered
>>> format(x, '^10.1f')
' 1234.6 '

>>> # Inclusion of thousands separator
>>> format(x, ',')
'1,234.56789'
>>> format(x, '0,.1f')
'1,234.6'
>>>
```

Если вы хотите использовать экспоненциальную нотацию, измените f на e или E (в зависимости от регистра, который вы хотите использовать для обозначения экспоненты). Например:
```python
>>> format(x, 'e')
'1.234568e+03'
>>> format(x, '0.2E')
'1.23E+03'
>>>
```

Общая форма ширины и точности в обоих случаях такова: '[<>^]?width[,]?(.digits)?', где width и digits — целые числа, а ? обозначает необязательные части. Тот же формат используется в строковом методе *format()*. Например:
```python
>>> 'The value is {:0,.2f}'.format(x)
'The value is 1,234.57'
>>>
``` 

### Обсуждение
Форматирование чисел для вывода обычно является прямолинейным. Приём, показанный выше, работает и для чисел с плавающей точкой, и для экземпляров *Decimal* из модуля *decimal*. 

Когда количество знаков ограничено, значения округляются таким же образом, как и при использовании функции *round()*. Например:
```python
>>> x
1234.56789
>>> format(x, '0.1f')
'1234.6'
>>> format(-x, '0.1f')
'-1234.6'
>>>
``` 

Обычное форматирование значений с добавлением разделителя разрядов ничего не знает о принятых в конкретных странах традициях форматирования тысячных разрядов. Если вам нужно принять во внимание эти традиции, обратите внимание на функции модуля *locale*. Вы также можете заменить символ разделителя разрядов, используя строковый метод translate(). Например:
```python
>>> swap_separators = { ord('.'):',', ord(','):'.' }
>>> format(x, ',').translate(swap_separators)
'1.234,56789'
>>>
``` 

В мире всё ещё очень много кода, использующего форматирование чисел на основе оператора %. Например:
```python
>>> '%0.2f' % x
'1234.57'
>>> '%10.1f' % x
' 1234.6'
>>> '%-10.1f' % x
'1234.6 '
>>>
```

Это форматирование всё еще приемлемо, но обладает меньшими возможностями, нежели современный метод *format()*. Например, форматирование с помощью оператора % не поддерживает добавление разделителя разрядов.


## 3.4. Работа с бинарными, восьмеричными и шестнадцатеричными целыми числами
### Задача
Вам нужно преобразовать выводимые целые числа в бинарное, восьмеричное или шестнадцатеричное представление.

### Решение
Чтобы преобразовать целое число в бинарное, восьмеричное или шестнадцатеричное представление, используйте функции *bin()*, *oct()* или *hex()* соответственно:
```python
>>> x = 1234
>>> bin(x)
'0b10011010010'
>>> oct(x)
'0o2322'
>>> hex(x)
'0x4d2'
>>>
```

Или же вы можете использовать функцию *format()*, если не хотите, чтобы появлялись префиксы 0b, 0o или 0x. Например:
```python
>>> format(x, 'b')
'10011010010'
>>> format(x, 'o')
'2322'
>>> format(x, 'x')
'4d2'
>>>
```

Целые числа имеют знак, поэтому если вы работаете с отрицательными значениями, то вывод тоже будет включать знак. Например:
```python
>>> x = -1234
>>> format(x, 'b')
'-10011010010'
>>> format(x, 'x')
'-4d2'
>>>
``` 

Если вы хотите вывести значение без знака, вам нужно добавить максимальное значение, чтобы установить длину бита. Например, чтобы вывести 32-битное значение, можно поступить так:
```python
>>> x = -1234
>>> format(2**32 + x, 'b')
'11111111111111111111101100101110'
>>> format(2**32 + x, 'x')
'fffffb2e'
>>>
```

Чтобы преобразовать строки с целыми числами в числа с разными основаниями, используйте функцию *int()*, указав нужное основание. Например:
```python
>>> int('4d2', 16)
1234
>>> int('10011010010', 2)
1234
>>>
```

### Обсуждение
По большей части работа с бинарными, восьмеричными и шестнадцатеричными целыми числами прямолинейна. Просто запомните, что эти преобразования относятся только выводу разных текстовых представлений чисел. «Под капотом» это один и тот же тип целых чисел.

Предупреждение для программистов, работающих с восьмеричными числами: синтаксис Python для определения восьмеричных значений немного отличается от реализованного в большинстве других языков. Если вы попробуете сделать это так, то получите синтаксическую ошибку:
```python
>>> import os
>>> os.chmod('script.py', 0755)
    File "<stdin>", line 1
        os.chmod('script.py', 0755)
                               ^
SyntaxError: invalid token
>>
```   

Убедитесь, что вы вводите восьмеричное значение с префиксом 0o, как показано тут:
```python
>>> os.chmod('script.py', 0o755)
>>>
```

## 3.5. Упаковка и распаковка больших целых чисел из байтовых строк
### Задача
У вас есть строка байтов, и вам нужно распаковать ее в целочисленное значение. Или же вам нужно конвертировать большое целое число в байтовую строку.

### Решение
Предположим, ваша программа должна работать с 16-тиэлементной байтовой строкой, которая содержит 128-битное целочисленное значение. Например:
```python
data = b'\x00\x124V\x00x\x90\xab\x00\xcd\xef\x01\x00#\x004'
```

Чтобы перевести байты в целое число, используйте *int.from_bytes()*, определив порядок следования байтов таким образом:
```python
>>> len(data)
16
>>> int.from_bytes(data, 'little')
69120565665751139577663547927094891008
>>> int.from_bytes(data, 'big')
94522842520747284487117727783387188
>>>
```

Чтобы преобразовать большое целочисленное значение обратно в байтовую строку, используйте метод *int.to_bytes()*, определив количество байтов и порядок их следования. Например:
```python
>>> x = 94522842520747284487117727783387188
>>> x.to_bytes(16, 'big')
b'\x00\x124V\x00x\x90\xab\x00\xcd\xef\x01\x00#\x004'
>>> x.to_bytes(16, 'little')
b'4\x00#\x00\x01\xef\xcd\x00\xab\x90x\x00V4\x12\x00'
>>>
``` 

### Обсуждение
Преобразование больших целочисленных значений из и в байтовые строки — не самая обычная операция. Однако иногда такая задача возникает в некоторых областях, каких как криптография или работа с сетью. Например, сетевые адреса IPv6 представлены 128-битными целыми числами. Если вы пишете программу, в которой нужно вытягивать такие значения из данных, вы можете столкнуться с этой задачей. 

В качестве альтернативы вы можете попытаться распаковывать значения, используя модуль *struct*, как описано в **рецепте 6.11.** Это работает, но размер целых чисел, которые могут быть распакованы с помощью *struct*, ограничен. Поэтому вам понадобится распаковывать несколько значений и объединять их для создания итогового значения. Например:
```python
>>> data
b'\x00\x124V\x00x\x90\xab\x00\xcd\xef\x01\x00#\x004'
>>> import struct
>>> hi, lo = struct.unpack('>QQ', data)
>>> (hi << 64) + lo
94522842520747284487117727783387188
>>>
```

Определение порядка следования байтов (*little* или *big*), просто указывает, записаны ли байты, из которых составляется целое число, в порядке от старшего к младшему или наоборот. Это легко понять, рассмотрев пример такого специально составленного шестнадцатеричного значения:
```python
>>> x = 0x01020304
>>> x.to_bytes(4, 'big')
b'\x01\x02\x03\x04'
>>> x.to_bytes(4, 'little')
b'\x04\x03\x02\x01'
>>>
```    

Если вы хотите упаковать целое число в строку байтов, но оно не поместится, вы получите ошибку. При необходимости вы можете использовать метод *int.bit_length()*, чтобы определить, сколько байтов потребуется для хранения значения:
```python
>>> x = 523 ** 23
>>> x
335381300113661875107536852714019056160355655333978849017944067
>>> x.to_bytes(16, 'little')
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
OverflowError: int too big to convert
>>> x.bit_length()
208
>>> nbytes, rem = divmod(x.bit_length(), 8)
>>> if rem:
...   nbytes += 1
...
>>>
>>> x.to_bytes(nbytes, 'little')
b'\x03X\xf1\x82iT\x96\xac\xc7c\x16\xf3\xb9\xcf...\xd0'
>>>
```

## 3.6. Вычисления с комплексными числами
### Задача
Возможно, ваша программа для взаимодействия с веб-сервисом для аутентификации последнего поколения столкнулась с сингулярностью, и ваш единственный способ обойти это лежит через комплексную плоскость... Или же вам просто нужно выполнить какие-то вычисления с использованием комплексных чисел.

### Решение
Комплексные числа могут быть определены с использованием функции *complex(real, imag)* или добавлением окончания j к числу с плавающей точкой. Например:
```python
>>> a = complex(2, 4)
>>> b = 3 - 5j
>>> a
(2+4j)
>>> b
(3-5j)
>>>
``` 

Реальное, мнимое и объединенное значения можно легко получить:
```python
>>> a.real
2.0
>>> a.imag
4.0
>>> a.conjugate()
(2-4j)
>>>
```

Работают все обычные математические операторы:
```python
>>> a + b
(5-1j)
>>> a * b
(26+2j)
>>> a / b
(-0.4117647058823529+0.6470588235294118j)
>>> abs(a)
4.47213595499958
>>>
```

Для специальных операций с комплексными числами, таких как синусы, косинусы или квадратные корни, используйте модуль *cmath*:
```python
>>> import cmath
>>> cmath.sin(a)
(24.83130584894638-11.356612711218174j)
>>> cmath.cos(a)
(-11.36423470640106-24.814651485634187j)
>>> cmath.exp(a)
(-4.829809383269385-5.5920560936409816j)
>>>
```   

### Обсуждение
Большинство связанных с математикой модулей Python умеют работать с комплексными числами. Например, если вы используете numpy, то сможете применить прямолинейный подход к созданию массивов комплексных чисел и операций над ними:
```python
>>> import numpy as np
>>> a = np.array([2+3j, 4+5j, 6-7j, 8+9j])
>>> a
array([ 2.+3.j, 4.+5.j, 6.-7.j, 8.+9.j])
>>> a + 2
array([ 4.+3.j, 6.+5.j, 8.-7.j, 10.+9.j])
>>> np.sin(a)
array([ 9.15449915 -4.16890696j, -56.16227422 -48.50245524j,
-153.20827755-526.47684926j, 4008.42651446-589.49948373j])
>>>
```

Стандартные математические функции, включенные в Python, не производят комплексные значения по умолчанию, так что они вряд ли случайно возникнут в вашем коде. Например:
```python
>>> import math
>>> math.sqrt(-1)
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
ValueError: math domain error
>>>
```

Если вы хотите получать в результате вычислений комплексные числа, вы должны явно использовать cmath или соответствующим образом объявить это библиотекам, которые умеют с ними работать. Например:
```python
>>> import cmath
>>> cmath.sqrt(-1)
1j
>>>
```

## 3.7. Работа с бесконечными значениями и NaN
### Задача
Вам нужно создать создать или протестировать такие значения с плавающей точкой: бесконечность, минус бесконечность, NaN (not a number, «не число»).

### Решение
В Python нет специального синтаксиса для представления таких специальных значений с плавающей точкой, но они могут быть созданы с помощью *float()*. Например:
```python
>>> a = float('inf')
>>> b = float('-inf')
>>> c = float('nan')
>>> a
inf
>>> b
-inf
>>> c
nan
>>>
```

Чтобы проверить, не является ли значение таким, используйте функции *math.isinf()* и *math.isnan()*. Например:
```python
>>> math.isinf(a)
True
>>> math.isnan(c)
True
>>>
```

### Обсуждение
За подробностями об этих специальных значениях с плавающей точкой вы можете обратиться к спецификации IEEE 754. Однако здесь есть несколько хитрых деталей, о которых нужно знать, особенно связанные со сравнениями и операторами.

Бесконечные значения распространяются в вычислениях согласно математическим правилам. Например:
```python
>>> a = float('inf')
>>> a + 45
inf
>>> a * 10
inf
>>> 10 / a
0.0
>>>
```

Однако некоторые операции неопределены и выдают NaN. Например:
```python
>>> a = float('inf')
>>> a/a
nan
>>> b = float('-inf')
>>> a + b
nan
>>>
```

Значения NaN распространяются через все операции, не возбуждая исключений. Например:
```python
>>> c = float('nan')
>>> c + 23
nan
>>> c / 2
nan
>>> c * 2
nan
>>> math.sqrt(c)
nan
>>>
```

Тонкость с NaN заключается в том, что они никогда будут равны друг другу. Например:
```python
>>> c = float('nan')
>>> d = float('nan')
>>> c == d
False
>>> c is d
False
>>>
```

По причине этого единственный безопасный способ проверить значение на NaN — это использовать *math.isnan()*, как показано в этом рецепте.

Иногда программисты хотят изменить поведение Python таким образом, чтобы при возникновении в ходе вычислений бесконечностей или NaN возбуждались исключения. Для такого изменения поведения может быть использован модуль *fpectl*, но он не включен в стандартную поставку Python, является платформозависимым и на самом деле предназначен только программистов-экспертов. За деталями обратитесь к [онлайн-документации Python](https://docs.python.org/3/library/fpectl.html).

## 3.8. Вычисления с дробями
### Задача
Вы вошли в машину времени и внезапно обнаружили себя делающим домашку по математике с задачками про дроби. Или же вы просто пишете код, который будет обсчитывать измерения, сделанные в вашей столярной мастерской...

### Решение
Модуль *fractions* может быть использован для выполнения математических операций с дробями. Например:
```python
>>> from fractions import Fraction
>>> a = Fraction(5, 4)
>>> b = Fraction(7, 16)
>>> print(a + b)
27/16
>>> print(a * b)
35/64

>>> # Getting numerator/denominator
>>> c = a * b
>>> c.numerator
35
>>> c.denominator
64

>>> # Converting to a float
>>> float(c)
0.546875
>>> # Limiting the denominator of a value
>>> print(c.limit_denominator(8))
4/7

>>> # Converting a float to a fraction
>>> x = 3.75
>>> y = Fraction(*x.as_integer_ratio())
>>> y
Fraction(15, 4)
>>>
```

### Обсуждение
Вычисления с дробями нечасто возникают в обычных программах, но иногда имеет смысл ими воспользоваться. Например, если данные каких-то измерений поступают в виде дробей, то можно работать прямо с ними, что снимает необходимость конвертирования в десятичные дроби или числа с плавающей точкой.


## 3.9. Вычисления на больших массивах чисел
### Задача
Вам нужно произвести вычисления на больших объемах числовых данных, таких как массивы или решетки.

### Решение
Для любых объемных вычислений с использованием массивов используйте библиотеку [NumPy](http://www.numpy.org/). Ее главное преимущество в том, что она предоставляет Python объект массива, который намного эффективнее и лучше подходит для математических вычислений, нежели стандартный список Python. Вот короткий пример, иллюстрирующий важные различия между обычными списками и массивами NumPy:
```python
>>> # Python lists
>>> x = [1, 2, 3, 4]
>>> y = [5, 6, 7, 8]
>>> x * 2
[1, 2, 3, 4, 1, 2, 3, 4]
>>> x + 10
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
TypeError: can only concatenate list (not "int") to list
>>> x + y
[1, 2, 3, 4, 5, 6, 7, 8]

>>> # Numpy arrays
>>> import numpy as np
>>> ax = np.array([1, 2, 3, 4])
>>> ay = np.array([5, 6, 7, 8])
>>> ax * 2
array([2, 4, 6, 8])
>>> ax + 10
array([11, 12, 13, 14])
>>> ax + ay
array([ 6, 8, 10, 12])
>>> ax * ay
array([ 5, 12, 21, 32])
>>>
``` 

Как вы можете увидеть, базовые математические операции с использованием массивов выполняются по-разному. Конкретно скалярные операции (например, ax * 2 или ax + 10) применяют операцию элемент за элементом. Также отметим, что выполнение таких математических операций, где каждый из операндов является массивом, применяет операцию ко всем элементам и создает новый массив.

Тот факт, что математические операции применяются одновременно ко всем элементам, позволяет очень просто и быстро применить функции к всему массиву. Например, если вы хотите вычислить значение многочлена:
```python
>>> def f(x):
...   return 3*x**2 - 2*x + 7
...
>>> f(ax)
array([ 8, 15, 28, 47])
>>>
``` 

NumPy предоставляет набор «универсальных функций», которые также работают для операций над массивами. Они подменяют похожие функции, доступные в модуле *math*. Например:
```python
>>> np.sqrt(ax)
array([ 1. , 1.41421356, 1.73205081, 2. ])
>>> np.cos(ax)
array([ 0.54030231, -0.41614684, -0.9899925 , -0.65364362])
>>>
``` 

Использование универсальных функций позволяет выполнить вычисление в сотни раз быстрее, чем проход по массиву и применение функций из *math* к каждому элементу. Так что используйте их при любой возможности.

«Под капотом» массивы NumPy устроены похоже на массивы C или Fortran. А именно они представляют собой большие смежные области памяти, состоящие из однородных типов данных. Это позволяет делать массивы намного большими, чем позволяет обычный список Python. Например, если вы хотите создать двумерную решетку размером 10 000 на 10 000 чисел с плавающей точкой, это не проблема:
```python
>>> grid = np.zeros(shape=(10000,10000), dtype=float)
>>> grid
array([[ 0., 0., 0., ..., 0., 0., 0.],
       [ 0., 0., 0., ..., 0., 0., 0.],
       [ 0., 0., 0., ..., 0., 0., 0.],
       ...,
       [ 0., 0., 0., ..., 0., 0., 0.],
       [ 0., 0., 0., ..., 0., 0., 0.],
       [ 0., 0., 0., ..., 0., 0., 0.]])
>>>
```

Все обычные операции все еще применяются к элементам одновременно:
```python
>>> grid += 10
>>> grid
array([[ 10., 10., 10., ..., 10., 10., 10.],
       [ 10., 10., 10., ..., 10., 10., 10.],
       [ 10., 10., 10., ..., 10., 10., 10.],
       ...,
       [ 10., 10., 10., ..., 10., 10., 10.],
       [ 10., 10., 10., ..., 10., 10., 10.],
       [ 10., 10., 10., ..., 10., 10., 10.]])
>>> np.sin(grid)
array([[-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111,
        -0.54402111, -0.54402111],
       [-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111,
        -0.54402111, -0.54402111],
       [-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111,
        -0.54402111, -0.54402111],
       ...,
       [-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111,
        -0.54402111, -0.54402111],
       [-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111,
        -0.54402111, -0.54402111],
       [-0.54402111, -0.54402111, -0.54402111, ..., -0.54402111,
        -0.54402111, -0.54402111]])
>>>
```

Важнейший момент в использовании NumPy — это способ, которым она расширяет функциональность индексирования списков Python (особенно для многомерных массивов). Чтобы проиллюстрировать это, создадим простой двумерный массив и поэкспериментируем:
```python
>>> a = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
>>> a
array([[ 1, 2, 3, 4],
       [ 5, 6, 7, 8],
       [ 9, 10, 11, 12]])

>>> # Select row 1
>>> a[1]
array([5, 6, 7, 8])

>>> # Select column 1
>>> a[:,1]
array([ 2, 6, 10])

>>> # Select a subregion and change it
>>> a[1:3, 1:3]
array([[ 6, 7],
       [10, 11]])
>>> a[1:3, 1:3] += 10
>>> a
array([[ 1, 2, 3, 4],
       [ 5, 16, 17, 8],
       [ 9, 20, 21, 12]])

>>> # Broadcast a row vector across an operation on all rows
>>> a + [100, 101, 102, 103]
array([[101, 103, 105, 107],
       [105, 117, 119, 111],
       [109, 121, 123, 115]])
>>> a
array([[ 1, 2, 3, 4],
       [ 5, 16, 17, 8],
       [ 9, 20, 21, 12]])

>>> # Conditional assignment on an array
>>> np.where(a < 10, a, 10)
array([[ 1, 2, 3, 4],
       [ 5, 10, 10, 8],
       [ 9, 10, 10, 10]])
>>>
``` 

### Обсуждение
NumPy — это основа огромного количества научных и инженерных библиотек для Python. Это также один из крупнейших и самых сложных модулей (из тех, что широко используются). При этом можно делать полезные вещи с помощью NumPy, начинав экспериментировать с простыми примерами.

Стоит отметить, что часто используется конструкция *import numpy as np*, как и показано в нашем примере. Это сокращает название, чтобы было удобно вводить его снова и снова в вашей программе. 

Прочую информацию вы найдёте на [http://www.numpy.org](http://www.numpy.org).


## 3.10. Вычисления с матрицами и линейная алгебра  
### Задача
Вам нужно произвести матричные операции и операции линейной алгебры, такие как умножение матриц, поиск определителей, решение линейных уравнений и т.д.

### Решение
Библиотека [NumPy](http://www.numpy.org) содержит объект *matrix*. Матрицы — это нечто похожее на объекты массивов, описанные в **рецепте 3.9.**, но в вычисления над ними следуют законам линейной алгебры. Вот несколько примеров их основных возможностей:
```python
>>> import numpy as np
>>> m = np.matrix([[1,-2,3],[0,4,5],[7,8,-9]])
>>> m
matrix([[ 1, -2, 3],
        [ 0, 4, 5],
        [ 7, 8, -9]])

>>> # Return transpose
>>> m.T
matrix([[ 1, 0, 7],
        [-2, 4, 8],
        [ 3, 5, -9]])

>>> # Return inverse
>>> m.I
matrix([[ 0.33043478, -0.02608696, 0.09565217],
        [-0.15217391, 0.13043478, 0.02173913],
        [ 0.12173913, 0.09565217, -0.0173913 ]])

>>> # Create a vector and multiply
>>> v = np.matrix([[2],[3],[4]])
>>> v
matrix([[2],
        [3],
        [4]])
>>> m * v
matrix([[ 8],
        [32],
        [ 2]])
>>>
```

Другие операции можно найти в субпакете *numpy.linalg*. Например:
```python
>>> import numpy.linalg

>>> # Determinant
>>> numpy.linalg.det(m)
-229.99999999999983

>>> # Eigenvalues
>>> numpy.linalg.eigvals(m)
array([-13.11474312, 2.75956154, 6.35518158])

>>> # Solve for x in mx = v
>>> x = numpy.linalg.solve(m, v)
>>> x
matrix([[ 0.96521739],
        [ 0.17391304],
        [ 0.46086957]])
>>> m * x
matrix([[ 2.],
        [ 3.],
        [ 4.]])
>>> v
matrix([[2],
        [3],
        [4]])
>>>
```

### Обсуждение
Линейная алгебра, очевидно, является слишком обширной темой, чтобы обсуждать ее в этом сборнике рецептов. Однако если вам нужно работать с матрицами и векторами, начните именно с NumPy. За информацией о библиотеке обращайтесь на [http://www.numpy.org](http://www.numpy.org).


## 3.11. Случайный выбор
### Задача
Вы хотите выбрать случайные элементы из последовательности или сгенерировать случайные числа.

### Решение
Модуль random содержит разнообразные функции для генерации случайных чисел и выбора случайных элементов. Например, чтобы выбрать случайный элемент последовательности используйте *random.choice()*:
```python
>>> import random
>>> values = [1, 2, 3, 4, 5, 6]
>>> random.choice(values)
2
>>> random.choice(values)
3
>>> random.choice(values)
1
>>> random.choice(values)
4
>>> random.choice(values)
6
>>>
```

Чтобы получить выборку из N элементов, используйте *random.sample()*. Каждый элемент выбирается один раз, так что если значения в полученной выборке повторяются, то это разные элементы оригинальной последовательности, имеющие одинаковое значение:
```python
>>> random.sample(values, 2)
[6, 2]
>>> random.sample(values, 2)
[4, 3]
>>> random.sample(values, 3)
[4, 3, 1]
>>> random.sample(values, 3)
[5, 4, 1]
>>>
```

Если вы хотите перемешать элементы в последовательности, используйте *random.shuffle()*:
```python
>>> random.shuffle(values)
>>> values
[2, 4, 6, 5, 3, 1]
>>> random.shuffle(values)
>>> values
[3, 5, 2, 1, 6, 4]
>>>
``` 

Чтобы сгенерировать случайные целые числа, используйте *random.randint()*:
```python
>>> random.randint(0,10)
2
>>> random.randint(0,10)
5
>>> random.randint(0,10)
0
>>> random.randint(0,10)
7
>>> random.randint(0,10)
10
>>> random.randint(0,10)
3
>>>
```

Чтобы сгенерировать одинаковые по формату числа с плавающей точкой в диапазоне от 0 до 1, используйте *random.random()*:
```python
>>> random.random()
0.9406677561675867
>>> random.random()
0.133129581343897
>>> random.random()
0.4144991136919316
>>>
```

Чтобы получить целое число из N случайных битов, используйте *random.getrandbits()*:
```python
>>> random.getrandbits(200)
335837000776573622800628485064121869519521710558559406913275
>>>
```  

### Обсуждение
Модуль *random* вычисляет случайные числа, используя алгоритм «вихрь Мерсенна» (Mersenne twister, MT). Это детерминистский алгоритм, но вы можете изменить начальную инциализацию с помощью функции random.seed():
```python
random.seed() # Seed based on system time or os.urandom()
random.seed(12345) # Seed based on integer given
random.seed(b'bytedata') # Seed based on byte data
```

Вдобавок к уже продемонстрированной функциональности, *random* включает функции для равномерного, гауссового и других распределений вероятности. Например, *random.uniform()* вычисляет равномерно распределенные числа, а *random.gauss()* — нормально распределенные. За описанием других поддерживаемых распределений обратитесь к документации.

Функции в *random* не должны быть использованы в криптографических программах. Если вам нужна такая функциональность, обратитесь к функциям из модуля *ssl*. Например, *ssl.RAND_bytes()* может быть использована для генерации криптографически безопасных последовательностей случайных байтов.


## 3.12. Перевод дней в секунды и другие базовые методы конвертации времени
### Задача
Вашей программе требуется производить простые преобразования времени, такие как выражение дней в секундах, часов в минутах и т.д.

### Решение
Чтобы производить конвертирование и арифметические операции над различными единицами времени, используйте модуль *datetime*. Например, чтобы представить интервал времени, создайте экземпляр *timedelta*:
```python
>>> from datetime import timedelta
>>> a = timedelta(days=2, hours=6)
>>> b = timedelta(hours=4.5)
>>> c = a + b
>>> c.days
2
>>> c.seconds
37800
>>> c.seconds / 3600
10.5
>>> c.total_seconds() / 3600
58.5
>>>
```

Если вам нужно представить определенные даты и определенное время, создайте экземпляры *datetime* и проводите над ними обычные арифметические операции. Например:
```python
>>> from datetime import datetime
>>> a = datetime(2012, 9, 23)
>>> print(a + timedelta(days=10))
2012-10-03 00:00:00
>>>
>>> b = datetime(2012, 12, 21)
>>> d = b - a
>>> d.days
89
>>> now = datetime.today()
>>> print(now)
2012-12-21 14:54:43.094063
>>> print(now + timedelta(minutes=10))
2012-12-21 15:04:43.094063
>>>
```

Стоит отметить, что *datetime* знает о существовании високосных годов. Например:
```python
>>> a = datetime(2012, 3, 1)
>>> b = datetime(2012, 2, 28)
>>> a - b
datetime.timedelta(2)
>>> (a - b).days
2
>>> c = datetime(2013, 3, 1)
>>> d = datetime(2013, 2, 28)
>>> (c - d).days
1
>>>
```

### Обсуждение
Для самых базовых операций над датой и временем модуля *datetime* достаточно. Если перед вами стоят более сложные задачи, такие как работа с временными зонами, нечеткими интервалами времени, подсчет дат выходных дней и так далее, посмотрите на модуль [dateutil](https://pypi.python.org/pypi/python-dateutil).

Например, множество похожих вычислений над временем может быть выполнено с помощью функции *dateutil.relativedelta()*. Одна важная возможность заключается в том, что она заполняет разрывы, которые возникают при работе с месяцами (и отличающимся количеством дней в них). Например:
```python
>>> a = datetime(2012, 9, 23)
>>> a + timedelta(months=1)
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
TypeError: 'months' is an invalid keyword argument for this function
>>>

>>> from dateutil.relativedelta import relativedelta
>>> a + relativedelta(months=+1)
datetime.datetime(2012, 10, 23, 0, 0)
>>> a + relativedelta(months=+4)
datetime.datetime(2013, 1, 23, 0, 0)
>>>

>>> # Time between two dates
>>> b = datetime(2012, 12, 21)
>>> d = b - a
>>> d
datetime.timedelta(89)
>>> d = relativedelta(b, a)
>>> d
relativedelta(months=+2, days=+28)
>>> d.months
2
>>> d.days
28
>>>
```

## 3.13. Определение даты последней пятницы
### Задача
Вы хотите создать общее решение для нахождения даты ближайшего прошедшего дня недели — например, последней прошедшей пятницы.

### Решение
В модуле *datetime* есть полезные функции и классы, которые помогают проводить такого рода вычисления. Хорошее обобщенное решение этой задачи выглядит как-то так:
```python
from datetime import datetime, timedelta

weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday',
            'Friday', 'Saturday', 'Sunday']

def get_previous_byday(dayname, start_date=None):
    if start_date is None:
        start_date = datetime.today()
    day_num = start_date.weekday()
    day_num_target = weekdays.index(dayname)
    days_ago = (7 + day_num - day_num_target) % 7
    if days_ago == 0:
        days_ago = 7
    target_date = start_date - timedelta(days=days_ago)
    return target_date
```     

Использование этой функции в строке интерпретатора выглядит так:
```python
>>> datetime.today()  # For reference
datetime.datetime(2012, 8, 28, 22, 4, 30, 263076)
>>> get_previous_byday('Monday')
datetime.datetime(2012, 8, 27, 22, 3, 57, 29045)
>>> get_previous_byday('Tuesday') # Previous week, not today
datetime.datetime(2012, 8, 21, 22, 4, 12, 629771)
>>> get_previous_byday('Friday')
datetime.datetime(2012, 8, 24, 22, 5, 9, 911393)
>>>
```

Необязательный параметр *start_date* может быть предоставлен с использованием другого экземпляра *datetime*. Например:
```python
>>> get_previous_byday('Sunday', datetime(2012, 12, 21))
datetime.datetime(2012, 12, 16, 0, 0)
>>>
```

### Обсуждение
Этот рецепт работает путем отображения стартовой и нужной даты на номера их позиций в неделе (где понедельник — это 0). Далее используется модульная арифметика, с её помощью мы вычисляем, сколько дней назад была нужная дата. Далее нужная дата высчитывается от стартовой даты путем вычитания соответствующего экземпляра *timedelta*.

Если вы выполняете много подобных вычислений, рекомендуем установить пакет [python-dateutil](https://pypi.python.org/pypi/python-dateutil). Например, вот так можно выполнить аналогичную работу с использованием функции *relativedata()* из модуля *dateutil*:
```python
>>> from datetime import datetime
>>> from dateutil.relativedelta import relativedelta
>>> from dateutil.rrule import *
>>> d = datetime.now()
>>> print(d)
2012-12-23 16:31:52.718111
>>> # Next Friday
>>> print(d + relativedelta(weekday=FR))
2012-12-28 16:31:52.718111
>>>
>>> # Last Friday
>>> print(d + relativedelta(weekday=FR(-1)))
2012-12-21 16:31:52.718111
>>>
```

## 3.14. Поиск диапазона дат для текущего месяца
### Задача
У вас есть код, которому необходимо пройти в цикле по каждой дате текущего месяца, и вы хотите узнать эффективный способ поиска диапазонов дат.

### Решение
Прохождение в цикле по датам не требует предварительного создания списка всех дат. Вы можете просто вычислить стартовую и конечную дату в диапазоне, а затем использовать объекты *datetime.timedelta*, инкрементируя дату.

Вот функция, которая принимает любой объект *datetime* и возвращает кортеж, содержащий первую дату месяца и начальную дату следующего месяца:
```python
from datetime import datetime, date, timedelta
import calendar

def get_month_range(start_date=None):
	if start_date is None:
	start_date = date.today().replace(day=1)
_, days_in_month = calendar.monthrange(start_date.year, start_date.month)
end_date = start_date + timedelta(days=days_in_month)
return (start_date, end_date)
```

Получив эти данные, очень просто пройти в цикле по диапазону дат:
```python
>>> a_day = timedelta(days=1)
>>> first_day, last_day = get_month_range()
>>> while first_day < last_day:
...  print(first_day)
...  first_day += a_day
...
2012-08-01
2012-08-02
2012-08-03
2012-08-04
2012-08-05
2012-08-06
2012-08-07
2012-08-08
2012-08-09
#... and so on...
```

### Обсуждение
Этот рецепт работает так: сначала вычисляется дата, соответствующая первому дню месяца. Быстрый способ сделать это — использовать метод *replace()* объектов *date* или *datetime*, чтобы присвоить атрибуту *days* значение 1. Приятно, что метод *replace()* создает объект того же типа, к которому он был применен. В данном случае, поскольку на входе у нас был экземпляр *date*, результат тоже является экземпляром *date*. Точно так же мы бы получили экземпляр *datetime*, если бы на входе у нас был экземпляр *datetime*. 

Затем функция *calendar.monthrange()* используется для нахождения количества дней в рассматриваемом месяце. Модуль calendar весьма полезен для получения базовых данных о календарях. Функция *monthrange()* возвращает кортеж, который содержит день недели и количество дней в месяце. 

Когда мы знаем количество дней в месяце, конечная дата вычисляется путём добавления соответствующего *timedelta* к стартовой дате.  Тонкий, но важный аспект этого рецепта — конечная дата не включается в диапазон (на самом деле это первая дата следующего месяца). Это отражает присущее срезам и диапазонам Python поведение, которое также не подразумевает включение последнего элемента.

Чтобы пройти в цикле по диапазону дат, используются стандартные математические операции и операторы сравнения. Например, экземпляр timedelta может быть использован для инкрементирования даты. Оператор < используется для проверки того, не достигнута ли конечная дата.

В идеальном случае стоит создать функцию, которая будет работать как встроенная *range()*, но с датами. К счастью, есть чрезвычайно простой способ сделать это с помощью генератора:
```python
def date_range(start, stop, step):
	while start < stop:
		yield start
		start += step
```

Вот пример её использования:
```python
>>> for d in date_range(datetime(2012, 9, 1), datetime(2012,10,1),
timedelta(hours=6)):
... print(d)
...
2012-09-01 00:00:00
2012-09-01 06:00:00
2012-09-01 12:00:00
2012-09-01 18:00:00
2012-09-02 00:00:00
2012-09-02 06:00:00
...
>>>
```

Повторимся, самое большое преимущество такой реализации в том, что датами и временем можно манипулировать с помощью стандартных математических операторов и операторов сравнения.

## 3.15. Конвертирование строк в даты и время
### Задача
Ваше приложение получает временные данные в строковом формате, но вы хотите конвертировать их в объекты *datetime*, чтобы выполнять над ними нестроковые операции.

### Решение
Стандартный модуль *datetime* обычно легко справляется с этой задачей. Например:
```python
>>> from datetime import datetime
>>> text = '2012-09-20'
>>> y = datetime.strptime(text, '%Y-%m-%d')
>>> z = datetime.now()
>>> diff = z - y
>>> diff
datetime.timedelta(3, 77824, 177393)
>>>
```

### Обсуждение
Метод *datetime.strptime()* поддерживает множество параметров форматирования, такие как %Y для года из четырёх цифр и %m для месяца из двух цифр. Также стоит отметить, что эти параметры-плейсхолдеры работают в обратном направлении, что поможет, если вам нужно вывести объект *datetime* в строке и при этом заставить его красиво выглядеть.

Предположим, например, что у ваша программа генерирует объект *datetime*, но вам нужно создать из него красивую, понятную людям дату, чтобы потом вставить ее в заголовок автоматически создаваемого письма или отчёта:
```python
>>> z
datetime.datetime(2012, 9, 23, 21, 37, 4, 177393)
>>> nice_z = datetime.strftime(z, '%A %B %d, %Y')
>>> nice_z
'Sunday September 23, 2012'
>>>
```

Стоит отметить, что производительность метода *strptime()* часто оказывается намного хуже, чем вы могли бы ожидать, поскольку функция написана на чистом Python и должна работать со всеми установками системной локализации. Если вы парсите множество дат в своей программе и знаете их точный формат, вы можете добиться намного более высокой производительности путём написания собственного решения. Например, если вы знаете, что даты представлены в формате “YYYY-MM-DD”, вы могли бы написать такую функцию:
```python
from datetime import datetime
def parse_ymd(s):
	year_s, mon_s, day_s = s.split('-')
	return datetime(int(year_s), int(mon_s), int(day_s))
``` 

При тестировании эта функции оказалась более чем в семь раз быстрее метода *datetime.strptime()*. Это стоит держать в голове, если вы обрабатываете большие объемы данных с датами.

## 3.16. Манипулирование датами с учётом таймзон
### Задача
У вас назначена телефонная конференция на 21 декабря 2012 года в 9:30 a.m. по чикагскому времени. В какое локальное время ваш друг из индийского города Бангалор должен выйти на связь?

### Решение
Для практических любых задач, связанных с таймзонами, вы можете использовать модуль [pytz](https://pypi.python.org/pypi/pytz). Этот пакет предоставляет базу таймзон Олсона (tz databaze), которая является стандартом де-факто для многих языков программирования и операционных систем.

Большая часть случаев использования *pytz* приходится на приведение к локальному времени дат, созданных с помощью библиотеки *datetime*. Например, вот как вы могли бы представить дату с чикагским местным временем:
```python
>>> from datetime import datetime
>>> from pytz import timezone
>>> d = datetime(2012, 12, 21, 9, 30, 0)
>>> print(d)
2012-12-21 09:30:00
>>>

>>> # Localize the date for Chicago
>>> central = timezone('US/Central')
>>> loc_d = central.localize(d)
>>> print(loc_d)
2012-12-21 09:30:00-06:00
>>>
```

Когда дата локализована (привязана к местному времени), ее можно конвертировать в другие таймзоны. Чтобы найти то же бангалорское время, вы можете сделать так:
```python
>>> # Convert to Bangalore time
>>> bang_d = loc_d.astimezone(timezone('Asia/Kolkata'))
>>> print(bang_d)
2012-12-21 21:00:00+05:30
>>>
``` 

Если вы собираетесь выполнять арифметические операции над локализованными датами, вам нужно знать о переводах времени с летнего на зимнее и прочих подобных деталях. Например, в 2013 году стандартное летнее время США началось 13 марта в 2:00 ночи по местному времени городов (время было переведено на час вперед). Если бы провели стандартную арифметическую операцию над датами, то получили бы неверный результат. Например:
```python
>>> d = datetime(2013, 3, 10, 1, 45)
>>> loc_d = central.localize(d)
>>> print(loc_d)
2013-03-10 01:45:00-06:00
>>> later = loc_d + timedelta(minutes=30)
>>> print(later)
2013-03-10 02:15:00-06:00
# WRONG! WRONG!
>>>
```

Ответ получается неверным, поскольку он не учитывает перевод местного времени на один час. Чтобы исправить это, используйте метод таймзон *normalize()*. Например:
```python
>>> from datetime import timedelta
>>> later = central.normalize(loc_d + timedelta(minutes=30))
>>> print(later)
2013-03-10 03:15:00-05:00
>>>
```

### Обсуждение
Чтобы предотвратить взрыв головы, используйте обычную стратегию работы с локальным временем: преобразование всех дат в UTC и использование уже их для хранения и обработки. Например:
```python
>>> print(loc_d)
2013-03-10 01:45:00-06:00
>>> utc_d = loc_d.astimezone(pytz.utc)
>>> print(utc_d)
2013-03-10 07:45:00+00:00
>>>
```
Если время уже в UTC, вы можете не волноваться по поводу проблем, связанных с переходом на летнее время, а также прочих подобных вещах. Вы свободно можете выполнять арифметические операции с датами. Если же вы хотите вывести дату в локальном времени, просто сконвертируйте в нужную таймзону. Например:
```python
>>> later_utc = utc_d + timedelta(minutes=30)
>>> print(later_utc.astimezone(central))
2013-03-10 03:15:00-05:00
>>>
```

С использованием таймзон есть одна проблема: какие имена таймзон использовать? Например, в этом рецепте мы как-то узнали, что “Asia/Kolkata” — это правильное название таймзоны для Индии. Чтобы узнать название нужной зоны, поищите в словаре *pytz.country_timezones*, указывая в качестве ключа код страны по ISO 3166. Например:
```python
>>> pytz.country_timezones['IN']
['Asia/Kolkata']
>>>
```

*К тому времени, как вы это прочтёте, модуль *pytz* может быть признан устаревшим, а ему на смену придёт улучшенная поддержка таймзон по [PEP 431](http://www.python.org/dev/peps/pep-0431). Однако многие из описанных проблем все равно нужно будет учитывать (вопросы работы с UTC и т.п.)*

# 4. Итераторы и генераторы
Итерации — одна из сильнейших сторон Python. На высшем уровне абстракции вы можете рассматривать интерации как способ обработки элементов последовательности. Однако возможности намного шире: они включают создание собственных объектов-итераторов, применение полезных паттернов итераций из модуля *itertools*, создание функций-генераторов и т.д. Эта глава рассматривает типичные задачи, связанные с итерациями.

## 4.1. Ручное прохождение по итератору
### Задача
Вам нужно обработать элементы итерируемого объекта, но по какой-то причине
вы не хотите использовать цикл.

### Решение
Чтобы вручную пройти по итерируемому объекту, используйте функцию *next()* и напишите код так, чтобы он ловил исключение *StopIteration*. Например, в этом случае мы вручную читаем строки из файла:
```python
with open('/etc/passwd') as f:
	try:
		while True:
		line = next(f)
		print(line, end='')
	except StopIteration:
		pass
``` 

Обычно *StopIteration* используется для передачи сигнала о конце итерирования. Однако если вы используете *next()* вручную, вы вместо этого можете запрограммировать возвращение конечного значения, такого как *None*. Например:
```python
with open('/etc/passwd') as f:
	while True:
	line = next(f, None)
		if line is None:
			break
	print(line, end='')
``` 

### Обсуждение
В большинстве случаев для прохода по итерируемому объекту используется цикл *for*. Однако задачи иногда требуют более точного контроля «подкапотного» механизма итераций. Также это полезно для того, чтобы разобраться, как он работает.

Следующий интерактивный пример иллюстрирует базовые механизмы того, что происходит во время итерирования:
```python
>>> items = [1, 2, 3]
>>> # Get the iterator
# Invokes items.__iter__()
>>> it = iter(items)
>>> # Run the iterator
>>> next(it)
# Invokes it.__next__()
1
>>> next(it)
2
>>> next(it)
3
>>> next(it)
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
StopIteration
>>>
```

Последующие рецепты в этой главе раскрывают подробности о приёмах итерирования, что предполагает знание базового протокола итераторов. Убедитесь, что этот первый рецепт прочно улёгся у вас в памяти.

## 4.2. Делегирование итерации
### Задача
Вы создали нестандартный объект-контейнер, который внутри содержит список, кортеж или какой-то другой итерируемый объект. Вы хотите заставить итерации работать с вашим новым контейнером.

### Решение
В типичном случае вам нужно определить метод __iter()__, который делегирует итерацию внутреннему содержимому контейнера. Например:
```python
class Node:
	def __init__(self, value):
		self._value = value
		self._children = []

	def __repr__(self):
		return 'Node({!r})'.format(self._value)

	def add_child(self, node):
		self._children.append(node)

def __iter__(self):
		return iter(self._children)

# Example
if __name__ == '__main__':
	root = Node(0)
	child1 = Node(1)
	child2 = Node(2)
	root.add_child(child1)
	root.add_child(child2)
	for ch in root:
	print(ch)
	# Outputs Node(1), Node(2)
```

В этой программе метод *__iter()__* просто перенаправляет запрос на итерацию содержащемус внутри атрибуту *_children*. 

### Обсуждение
Протокол итераций Python требует, чтобы *__iter()__* возвращал специальный объект-итератор, в котором реализован метод *__next()__*, который и выполняет итерацию. Если вы просто итерируете по содержимому другого контейнера, вам не стоит беспокоиться о деталях внутреннего механизма процесса. Вам нужно просто передать запрос на итерацию.

Использование функции *iter()* здесь позволяет «срезать путь» и написать более чистый код. *iter(s)* просто возвращает внутренний итератор, вызывая *s.__iter__()* — примерно так же, как *len(s)* вызывает *s.__len__()*.


## 4.3. Создание новых итерационных паттернов с помощью генераторов
### Задача
Вы хотите реализовать собственный паттерн итераций, который будет отличаться от обычных встроенных функций (таких как *range()*, *reversed()* и т.п.)

### Решение
Если вы хотите реализовать новый тип итерационного паттерна, определите его с помощью генератора. Вот, например, генератор, который создает диапазон чисел с плавающей точкой:
```python
def frange(start, stop, increment):
	x = start
	while x < stop:
		yield x
		x += increment
```

Чтобы использовать такую функцию, вы должны проитерировать по ней в цикле или применить ее с какой-то другой функцией, которая потребляет итерируемый объект (например, *sum()*, *list()* и т.п.) Например:
```python
>>> for n in frange(0, 4, 0.5):
... 	print(n)
...
0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
>>> list(frange(0, 1, 0.125))
[0, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875]
>>>
```

### Обсуждение
Само присутствие инструкции *yield* в функции превращает её в генератор. В отличие от обычной функции, генератор запускается только в ответ на итерацию. Вот эксперимент, который вы можете провести, чтобы понять внутренний механизм работы таких функций:
```python
>>> def countdown(n):
...print('Starting to count from', n)
...while n > 0:
...	yield n
...	n -= 1
...print('Done!')
...

>>> # Create the generator, notice no output appears
>>> c = countdown(3)
>>> c
<generator object countdown at 0x1006a0af0>

>>> # Run to first yield and emit a value
>>> next(c)
Starting to count from 3
3

>>> # Run to the next yield
>>> next(c)
2

>>> # Run to next yield
>>> next(c)
1

>>> # Run to next yield (iteration stops)
>>> next(c)
Done!
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
StopIteration
>>>
``` 

Ключевая особенность функции-генератора состоит в том, что она запускается только в ответ на операции *next* в ходе итерирования. Когда генератор возвращает значение, итерирование останавливается. Однако цикл *for*, который обычно используется для выполнения итераций, сам заботится об этих деталях, поэтому в большинстве случаев вам не стоит волноваться о них. 

## 4.4. Реализация протокола итератора
### Задача
Вы создаете собственные объекты, которые вы хотите сделать итерируемыми, и ищете простой способ реализовать протокол итератора.

### Решение
На текущий момент простейший способ имплементации итерируемости в объекте — это использование генератора. В **рецепте 4.2.** был представлен класс *Node*, представляющий древовидные структуры. Возможно, вы захотите реализовать итератор, который будет обходить узлы поиском в глубину. Вот как можно это сделать:
```python
class Node:
	def __init__(self, value):
		self._value = value
		self._children = []

	def __repr__(self):
		return 'Node({!r})'.format(self._value)

	def add_child(self, node):
		self._children.append(node)

	def __iter__(self):
		return iter(self._children)

	def depth_first(self):
		yield self
		for c in self:
			yield from c.depth_first()

# Example
if __name__ == '__main__':
	root = Node(0)
	child1 = Node(1)
	child2 = Node(2)
	root.add_child(child1)
	root.add_child(child2)
	child1.add_child(Node(3))
	child1.add_child(Node(4))
	child2.add_child(Node(5))

	for ch in root.depth_first():
		print(ch)
	# Outputs Node(0), Node(1), Node(3), Node(4), Node(2), Node(5)
``` 

В этой программе метод *depth_first()* просто прочесть и описать. Сначала он выдает себя, а затем итерируется по каждому потомку, выдавая элементы, производимые методом *depth_first()* потомка (используя *yield from*). 

### Обсуждение
Протокол итератора Python требует *__iter()__*, чтобы вернуть специальный объект итератора, в котором реализована операция *__next()__*, а исключение *StopIteration* используется для подачи сигнала о завершении. Однако создание таких объектов частов может быть запутанным делом. Например, следующая программа демонстрирует альтернативную имплементацию метода *depth_first()*, использующую связанный класс итератора:
```python
class Node:
	def __init__(self, value):
		self._value = value
		self._children = []
	
	def __repr__(self):
		return 'Node({!r})'.format(self._value)
	
	def add_child(self, other_node):
		self._children.append(other_node)
	
	def __iter__(self):
		return iter(self._children)
	
	def depth_first(self):
		return DepthFirstIterator(self)

class DepthFirstIterator(object):
	'''
	Depth-first traversal
	'''
	
	def __init__(self, start_node):
		self._node = start_node
		self._children_iter = None
		self._child_iter = None
	
	def __iter__(self):
		return self
	
	def __next__(self):
		# Return myself if just started; create an iterator for children
		if self._children_iter is None:
			self._children_iter = iter(self._node)
			return self._node
	
		# If processing a child, return its next item
		elif self._child_iter:
		try:
			nextchild = next(self._child_iter)
			return nextchild
		except StopIteration:
			self._child_iter = None
			return next(self)
		
		# Advance to the next child and start its iteration
		else:
			self._child_iter = next(self._children_iter).depth_first()
			return next(self)
``` 

Класс DepthFirstIterator работает так же, как и версия на основе генератора, но он беспорядочен и некрасив, поскольку итератор вынужден хранить много сложных состояний о состоянии итерационного процесса. Откровенно говоря, никому не нравится писать такой мозговыносящий код. Реализуйте итератор на базе генератора и успокойтесь на этом.

## 4.5. Итерирование в обратном порядке
### Задача
Вы хотите проитерировать по последовательности в обратном порядке.

### Решение
Используйте встроенную функцию *reversed()*. Например:
```python
>>> a = [1, 2, 3, 4]
>>> for x in reversed(a):
... 	print(x)
...
4
3
2
1
```

Обратная итерация сработает только в том случае, если объект имеет определенный размер, или если в нём реализован специальный метод *__reversed__()*. Если ни одно из этих условий не выполнено, вы должны будете сначала конвертировать объект в список. Например:
```python
# Print a file backwards
f = open('somefile')
for line in reversed(list(f)):
	print(line, end='')
```

Обратите внимание, что конвертирование итерируемого объекта в список может съесть много памяти, если список получится большим. 

### Обсуждение
Многие программисты не знают, что итерирование в обратном порядке может быть переопределено в собственном классе, если он реализует метод *__reversed__()*. Например
```python
class Countdown:
	def __init__(self, start):
		self.start = start
	
	# Forward iterator
	def __iter__(self):
		n = self.start
		while n > 0:
			yield n
			n -= 1
	
	# Reverse iterator
	def __reversed__(self):
		n = 1
		while n <= self.start:
			yield n
			n += 1
``` 

Определение обратного итератора делает код намного более эффективным, а также отпадает необходимость предварительного помещения данных в список для выполнения итераций в обратном порядке.

## 4.6. Определение генератора с дополнительным состоянием
### Задача
Вы хотите написать генератор, но функция работает с дополнительным состоянием, которое вам хотелось бы каким-то образом показать пользователю.

### Решение
Если вам нужен генератор, который показывает пользователю дополнительное состояние, не забудьте, что вы можете легко реализовать его в форме класса, поместив код генератора в метод *__iter__()*. Например:
```python
from collections import deque

class linehistory:
	def __init__(self, lines, histlen=3):
		self.lines = lines
		self.history = deque(maxlen=histlen)
	
	def __iter__(self):
		for lineno, line in enumerate(self.lines,1):
			self.history.append((lineno, line))
			yield line
	
	def clear(self):
		self.history.clear()
```

Вы можете обращаться с этим классом так же, как с обычным генератором. Однако, поскольку он создает экземпляр, вы можете обращаться к внутренним атрибутам, таким как *history* или метод *clear()*. Например:
```python
with open('somefile.txt') as f:
	lines = linehistory(f)
	for line in lines:
		if 'python' in line:
			for lineno, hline in lines.history:
				print('{}:{}'.format(lineno, hline), end='')
```

### Обсуждение
С генераторами легко попасть в ловушку, если пытаться делать всё только с помощью функций. В результате может получиться сложный код, если генератору нужно взаимодействовать с другими частями программы некими необычнымыми способами (раскрытие атрибутов, разрешение на управление через вызов методов и т.п.) В этом случае просто используйте определение класса, как показано выше. Определение генератора в методе *__iter__()* не изменит ничего в том, как вы напишете алгоритм. Но тот факт, что генератор станет частью класса, сделает простым предоставление юзерам атрибутов и методов для каких-то взаимодействий.

Потенциально хрупкость в показанном приёме заключается в том, что он может потребовать дополнительного шага: вызова *iter()*, если вы собираетесь провести итерацию не через цикл *for*. Например:
```python
>>> f = open('somefile.txt')
>>> lines = linehistory(f)
>>> next(lines)
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
TypeError: 'linehistory' object is not an iterator

>>> # Call iter() first, then start iterating
>>> it = iter(lines)
>>> next(it)
'hello world\n'
>>> next(it)
'this is a test\n'
>>>
```

## 4.7. Получение среза итератора
### Задача
Вы хотите получить срез данных, производимых итератором, но обычный оператор среза не работает.

### Решение
Функция *itertools.islice()* отлично подходит для получения срезов генераторов и итераторов. Например:
```python
>>> def count(n):
... 	while True:
...			yield n
...			n += 1
...
>>> c = count(0)
>>> c[10:20]
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
TypeError: 'generator' object is not subscriptable

>>> # Now using islice()
>>> import itertools
>>> for x in itertools.islice(c, 10, 20):
... 	print(x)
...
10
11
12
13
14
15
16
17
18
19
>>>
```

### Обсуждение
Из итераторов и генераторов получить срез напрямую нельзя, потому что отсутствует информация об их длине (и в них не реализовано индексирование). Результат *islice()* — это итератор, который создает элементы нужного среза, но делает это путем потребления и выбрасывания всех элементов до стартового индекса среза. Следующие элементы затем производятся объектом *islice*, пока не будет достигнут конечный индекс среза. 

Важно отметить, что *islice()* будут потреблять данные, предоставляемые итератором. Это важно, поскольку итераторы не могут быть отмотаны назад. Если вам нужно возвращаться назад, то вам, наверное, лучше сначала конвертировать данные в список.

### 4.8. Пропуск первой части итерируемого объекта
## Задача
Вы хотите итерировать по элементам в последовательности, но первые несколько элементов вам неинтересны, и вы хотите их опустить.

### Решение
В модуле *itertools* есть несколько функций, которые могут быть использованы для решения этой задачи. Первая — *itertools.dropwhile()*. Чтобы использовать её, вы предоставляете функцию и итерируемый объект. Возвращаемый итератор отбрасывает первые элементы в последовательности до тех пор, пока предоставленная функция возвращает True. А затем выдается вся оставшаяся последовательность. 

Предположим, что вы читаете файл, который начинается со строчек с комментариями:
```python
>>> with open('/etc/passwd') as f:
... for line in f:
... 	print(line, end='')
...
##
# User Database
#
# Note that this file is consulted directly only when the system is running
# in single-user mode. At other times, this information is provided by
# Open Directory.
...
##
nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false
root:*:0:0:System Administrator:/var/root:/bin/sh
...
>>>
```

Если вы хотите пропустить все начальные закомментированные строчки, вот как это можно сделать:
```python
>>> from itertools import dropwhile
>>> with open('/etc/passwd') as f:
...		for line in dropwhile(lambda line: line.startswith('#'), f):
...			print(line, end='')
...
nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false
root:*:0:0:System Administrator:/var/root:/bin/sh
...
>>>
```

Этот пример показывает, как можно пропустить первые элементы в соответствии с возвращаемым значением проверочной функции. Если так случилось, что вы знаете точное количество элементов, которые вы хотите пропустить, то вы можете вместо вышеописанного способа использовать *itertools.islice()*. Например:
```python
>>> from itertools import islice
>>> items = ['a', 'b', 'c', 1, 4, 10, 15]
>>> for x in islice(items, 3, None):
...		print(x)
...
1
4
10
15
>>>
```

В этом примере последний аргумент *islice()* *None* необходим для того, чтобы обозначить, что вам нужно всё за пределами первых трёх элементов (а не первые три элемента). То есть срез [3:0], а не [:3].

### Обсуждение
Главное преимущество функций *dropwhile()* и *islice()* в том, что они позволяют избажеть написания грязного кода наподобие вот такого:
```python
with open('/etc/passwd') as f:
	# Skip over initial comments
	while True:
		line = next(f, '')
		if not line.startswith('#'):
			break

# Process remaining lines
while line:
	# Replace with useful processing	
	print(line, end='')
	line = next(f, None)
```

Отбрасывание первой части итерируемого объекта также немного отличается от простого фильтрования. Например, первая часть этого рецепта может быть переписана вот так:
```python
with open('/etc/passwd') as f:
	lines = (line for line in f if not line.startswith('#'))
	for line in lines:
		print(line, end='')
```

Очевидно, что это отбросит все закомментированные строчки в начале файла, но такое решение отбросит и все остальные такие строчки во всём файле. С другой стороны, решение, которое отбрасывает все элементы до тех пор, пока не будет встречен элемент, не соответствующий условиям отбрасывания, удовлетворяет нашим требованиям: все последующие элементы будут возвращены без фильтрования.

Стоит отметить, что этот рецепт работает со всеми итерируемыми объектами, включая те, размер которых нельзя оценить предварительно: генераторами, файлами и другими подобными объектами.

## 4.9. Итерирование по всем возможным комбинациям и перестановкам
### Задача
Вы хотите проитерировать по всем возможным комбинациям и перестановкам коллекции элементов.

### Решение
Модуль *itertools* предоставляет три функции, подходящие для этой задачи. Первая, *itertools.permutations()*, принимает коллекцию элементов и создает последовательность кортежей со всеми возможными перестановками (то есть она тасует их во всех возможных конфигурациях). Например:
```python
>>> items = ['a', 'b', 'c']
>>> from itertools import permutations
>>> for p in permutations(items):
... 	print(p)
...
('a', 'b', 'c')
('a', 'c', 'b')
('b', 'a', 'c')
('b', 'c', 'a')
('c', 'a', 'b')
('c', 'b', 'a')
>>>
```

Если вы хотите получить все возможные перестановки меньшей длины, вы можете передать функции необязательный аргумент со значением длины. Например:
```python
>>> for p in permutations(items, 2):
...		print(p)
...
('a', 'b')
('a', 'c')
('b', 'a')
('b', 'c')
('c', 'a')
('c', 'b')
>>>
```

Используйте *itertools.combinations()*, чтобы создать последовательность комбинаций элементов входной последовательности. Например:
```python
>>> from itertools import combinations
>>> for c in combinations(items, 3):
...		print(c)
...
('a', 'b', 'c')
>>> for c in combinations(items, 2):
... 	print(c)
...
('a', 'b')
('a', 'c')
('b', 'c')
>>> for c in combinations(items, 1):
...		print(c)
...
('a',)
('b',)
('c',)
>>>
```

Для функции *combinations()* порядок элементов не имеет значения. Поэтому комбинация ('a', 'b') она считает аналогичной ('b', 'a') — поэтому вторая в выводимых результатах отсутствует.

При создании комбинаций выбранные элементы удаляются из коллекции возможных кандидатов (то есть если 'a' уже выбран, он больше не будет рассматриваться). А функция itertools.combinations_with_replacement() выбирает один и тот же элемент более одного раза. Например:
```python
>>> for c in combinations_with_replacement(items, 3):
...		print(c)
...
('a', 'a', 'a')
('a', 'a', 'b')
('a', 'a', 'c')
('a', 'b', 'b')
('a', 'b', 'c')
('a', 'c', 'c')
('b', 'b', 'b')
('b', 'b', 'c')
('b', 'c', 'c')
('c', 'c', 'c')
>>>
``` 

### Обсуждение
Этот рецепт показывает лишь небольшую часть мощи модуля *itertools*. Хотя вы могли бы самостоятельно написать код, который выполняет перестановки и комбинации, это, вероятно, отняло бы у вас больше пары секунд времени. Когда вы сталкиваетесь с нетривиальными задачами итераций, обратитесь к *itertools*, это всегда окупается. Если задача типичная, велик шанс того, что вы найдете готовое решение.

## 4.10. Итерирование по парам «индекс-значение» последовательности 

### Задача
Вы хотите проитерировать по последовательности и при этом хранить информацию о том, какой по счёту элемент сейчас обрабатывается.

### Решение
Встроенная функция enumerate() изящно справляется с этой задачей:
```python
>>> my_list = ['a', 'b', 'c']
>>> for idx, val in enumerate(my_list):
...		print(idx, val)
...
0 a
1 b
2 c
``` 

Для печати вывода с привычными номерами строк (то есть с нумерацией, начинающейся с 1, а не с 0), вы можете передать соответствующий аргумент start:
```python
>>> my_list = ['a', 'b', 'c']
>>> for idx, val in enumerate(my_list, 1):
...		print(idx, val)
...
1 a
2 b
3 c
```

Этот приём особенно полезен для учёта номеров строк в файлах, если нужно будет вывести номер строки в сообщении об ошибке:
```python
def parse_data(filename):
	with open(filename, 'rt') as f:
		for lineno, line in enumerate(f, 1):
			fields = line.split()
			try:
				count = int(fields[1])
				...
				except ValueError as e:
					print('Line {}: Parse error: {}'.format(lineno, e))
```

*enumerate()* удобна, например, для отслеживания смещения (offset) в списке для вхождений определенных значений. Так что если вы хотите отобразить слова в файле к строчкам, в которых они встречаются, это легко сделать с помощью enumerate() — функция отображает каждое слово на смещение строки в файле, где оно найдено:
```python
word_summary = defaultdict(list)

with open('myfile.txt', 'r') as f:
	lines = f.readlines()

for idx, line in enumerate(lines):
	# Create a list of words in current line
	words = [w.strip().lower() for w in line.split()]
	for word in words:
		word_summary[word].append(idx)
```

Если вы выведете *word_summary* после обработки файла, это будет словарь (*default dict*, если быть точными), и каждое слово будет ключом. Значение для каждого ключа — список номеров строк, где встретилось это слово. Если слово встретилось дважды в одной строке, этот номер строки будет записан в список дважды, что делает возможным получение разнообразных простых метрик текста.

### Обсуждение
*enumerate()* — симпатичное решение для ситуаций, где вы могли бы склоняться использованию собственной переменной-счетчика. Вы могли бы написать такой код:
```python
lineno = 1
	for line in f:
	# Process line
	...
	lineno += 1
```

Но часто более элегантным (и менее подверженным ошибкам) способом становится использование *enumerate()*:
```python
for lineno, line in enumerate(f):
	# Process line
	...
```

Значение, возвращаемое функцией *enumerate()*, является объектом *enumerate*. Это итератор, который последовательно возвращает кортежи, состоящие из счётчика и значения, возвращаемого вызовом функции *next()* для последовательности, которую вы обходите.

Стоит отметить, что иногда можно запутаться при применении *enumerate()* к последовательности кортежей, которые при этом распаковываются:
```python
data = [ (1, 2), (3, 4), (5, 6), (7, 8) ]

# Correct!
for n, (x, y) in enumerate(data):
	...

# Error!
	for n, x, y in enumerate(data):
	...
```

## 4.11. Одновременное итерирование по нескольким последовательностям
### Задача
Вы хотите за один раз проитерировать по элементам, содержащимися более чем в одной последовательности.

### Решение
Чтобы итерировать по более чем одной последовательности за раз, используйте функцию *zip()*. Например:
```python
>>> xpts = [1, 5, 4, 2, 10, 7]
>>> ypts = [101, 78, 37, 15, 62, 99]
>>> for x, y in zip(xpts, ypts):
... 	print(x,y)
...
1 101
5 78
4 37
2 15
10 62
7 99
>>>
```

*zip(a, b)* работает путём создания итератора, который производит кортежи (x, y), где x берётся из a, а y — из b. Итерирование останавливается, когда заканчивается одна из последовательностей. Поэтому результат будет таким же по длине, как и самая короткая из входных последовательностей. Например:
```python
>>> a = [1, 2, 3]
>>> b = ['w', 'x', 'y', 'z']
>>> for i in zip(a,b):
...		print(i)
...
(1, 'w')
(2, 'x')
(3, 'y')
```

Если такое поведение нежелательно, используйте функцию *itertools.zip_longest()*. Например:
```python
>>> from itertools import zip_longest
>>> for i in zip_longest(a,b):
...		print(i)
...
(1, 'w')
(2, 'x')
(3, 'y')
(None, 'z')
>>> for i in zip_longest(a, b, fillvalue=0):
... 	print(i)
...
(1, 'w')
(2, 'x')
(3, 'y')
(0, 'z')
>>>
```

### Обсуждение
*zip()* обычно используется тогда, когда вам нужно создать пары из данных. Предположим, например, что у вас есть список заголовков столбцов и значения столбцов:
```python
headers = ['name', 'shares', 'price']
values = ['ACME', 100, 490.1]
```

Используя *zip()*, вы можете создать пары значений и поместить их в словарь:
```python
s = dict(zip(headers,values))
```

Если вы хотите вывести результат, можно поступить так:
```python
for name, val in zip(headers, values):
	print(name, '=', val)
```

Менее распространённое применение *zip()* заключается в том, что функции может быть передано не две последовательности, а больше. В этом случае кортежи результата будут иметь такое количество элементов, каким было количество последовательностей. Например:
```python
>>> a = [1, 2, 3]
>>> b = [10, 11, 12]
>>> c = ['x', 'y', 'z']
>>> for i in zip(a, b, c):
...		print(i)
...
(1, 10, 'x')
(2, 11, 'y')
(3, 12, 'z')
>>>
```

И последнее: важно подчеркнуть, что *zip()* возвращает итератор. Если вам нужны сохраненные в списке спаренные значения, используйте функцию *list()*. Например:
```python
>>> zip(a, b)
<zip object at 0x1007001b8>
>>> list(zip(a, b))
[(1, 10), (2, 11), (3, 12)]
>>>
```

## 4.12. Интерирования по элементам, находящимся в отдельных контейнерах
### Проблема
Вам нужно выполнить одинаковую операцию над большим количеством объектов, но объекты находятся в различных контейнерах, а вам хотелось бы избежать написания вложенных циклов, причем без потери читабельности кода.

### Решение
Для упрощения этой задачи может быть использовать метод *itertools.chain()*. Он принимает список итерируемых объектов и возвращает итератор, который эффективно скрывает тот факт, что вы на самом деле работаете с несколькими контейнерами. Рассмотрим пример:
```python
>>> from itertools import chain
>>> a = [1, 2, 3, 4]
>>> b = ['x', 'y', 'z']
>>> for x in chain(a, b):
... 	print(x)
...
1
2
3
4
x
y
z
>>>
```

Обычно *chain()* используется, если вы хотите выполнить некоторые операции над всеми элементами за один раз, но элементы разнесены по разным рабочим наборам. Например:
```python
# Various working sets of items
active_items = set()
inactive_items = set()

# Iterate over all items
for item in chain(active_items, inactive_items):
	# Process item
	...
``` 

Это решение намного более элегантно, нежели использование двух отдельных циклов, как показано в этом примере:
```python
for item in active_items:
	# Process item
	...

for item in inactive_items:
	# Process item
	...
```

### Обсуждение
*itertools.chain()* принимает один или более итерируемых объектов в качестве аргументов. Далее она создает итератор, который последовательно потребляет и возвращает элементы, производимые каждым из предоставленных итерируемых объектов. Это тонкое различие, но *chain()* эффективнее, чем итерирование по предварительно объединенным последовательностям. Например:
```python
# Inefficent
	for x in a + b:
	...

# Better
	for x in chain(a, b):
	...
```

В первом случае операция a + b создает новую последовательность и дополнительно требует, чтобы a и b относились к одному типу. *chain()* не выполняет такую операцию, намного эффективнее обращается с памятью, если входные последовательности большие, а также легко применяется к итерируемым объектов различных типов.

## 4.13. Создание каналов для обработки данных
### Задача
Вы хотите обрабатывать данные итеративно, в стиле обрабатывающего данные канала (похожего на канал — он же конвейер — Unix). Например, у вас есть огромный объем данных для обработки, который просто не поместится в память целиком.

### Решение
Генераторы хорошо подходят для реализации обрабатывающих каналов. Предположим, например, что у вас есть огромный каталог с файлами логов, который вы хотите обработать:
```
foo/
	access-log-012007.gz
	access-log-022007.gz
	access-log-032007.gz
	...
	access-log-012008
bar/
	access-log-092007.bz2
	...
	access-log-022008
``` 

Предположим, каждый файл содержит такие строки данных:
```
124.115.6.12 - - [10/Jul/2012:00:18:50 -0500] "GET /robots.txt ..." 200 71
210.212.209.67 - - [10/Jul/2012:00:18:51 -0500] "GET /ply/ ..." 200 11875
210.212.209.67 - - [10/Jul/2012:00:18:51 -0500] "GET /favicon.ico ..." 404 369
61.135.216.105 - - [10/Jul/2012:00:20:04 -0500] "GET /blog/atom.xml ..." 304 -
...
```

Чтобы обработать эти файлы, вы могли бы создать коллекцию небольших генераторов, которые будут выполнять специфические замкнутые в себе задачи:
```python
import os
import fnmatch
import gzip
import bz2
import re

def gen_find(filepat, top):
	'''
	Find all filenames in a directory tree that match a shell wildcard pattern
	'''
	for path, dirlist, filelist in os.walk(top):
		for name in fnmatch.filter(filelist, filepat):
			yield os.path.join(path,name)

def gen_opener(filenames):
	'''
	Open a sequence of filenames one at a time producing a file object.
	The file is closed immediately when proceeding to the next iteration.
	'''
	for filename in filenames:
		if filename.endswith('.gz'):
			f = gzip.open(filename, 'rt')
		elif filename.endswith('.bz2'):
			f = bz2.open(filename, 'rt')
		else:
			f = open(filename, 'rt')
		yield f
		f.close()


def gen_concatenate(iterators):
	'''
	Chain a sequence of iterators together into a single sequence.
	'''
	for it in iterators:
		yield from it
	
def gen_grep(pattern, lines):
	'''
	Look for a regex pattern in a sequence of lines
	'''
	pat = re.compile(pattern)
	for line in lines:
		if pat.search(line):
			yield line
```

Теперь вы можете легко совместить эти функции для создания обрабатывающего канала. Например, чтобы найти все файлы логов, которые содержат слово *python*, вы можете поступить так:
```python
lognames = gen_find('access-log*', 'www')
files = gen_opener(lognames)
lines = gen_concatenate(files)
pylines = gen_grep('(?i)python', lines)
for line in pylines:
	print(line)
```

Если вы хотите еще расширить канал, вы можете скармливать данные выражениям-генераторам. Например, эта версия находит количество переданных байтов и подсчитывает общую сумму:
```python
lognames = gen_find('access-log*', 'www')
files = gen_opener(lognames)
lines = gen_concatenate(files)
pylines = gen_grep('(?i)python', lines)
bytecolumn = (line.rsplit(None,1)[1] for line in pylines)
bytes = (int(x) for x in bytecolumn if x != '-')
print('Total', sum(bytes))
```

### Обсуждение
Обработка данных в «каналообразной» манере отлично работает для решения широкого спектра задач: парсинга, чтения из риалтаймовых источников данных, периодического опрашивания и т.д.

В понимании представленного выше кода главное уловить, что инструкция *yield* действует как своего рода производитель данных для цикла *for*, который действует как потребитель данных. Когда генераторы соединены, каждый *yield* скармливает один элемент данных следующему этапу канала, который потребляет его, совершая итерацию. В последнем примере функция *sum()* управляет всей программой, вытягивая один элемент за другим из канала (конвейера) генераторов.

Приятная возможность этого подхода заключается в том, что каждый генератор является маленьким и замкнутым на себе, поэтому их легко писать и поддерживать. Во многих случаях они получаются настолько универсальными, что могут быть переиспользованы в других контекстах. Получающийся код, который «склеивает» компоненты вместе, тоже обычно читается как простой для понимания рецепт. 

Есть небольшая тонкость с использованием функции *gen_concatenate()*. Ее назначение — конкатенировать входные последовательности в одну длинную последовательность строк. *itertools.chain()* выполняет похожую функцию, но требует, чтобы все объединяемые итерируемые объекты были определены в качестве аргументов. В случае этого конкретного рецепта, такой подход потребовал бы инструкции типа *lines = itertools.chain(\*files)*, которая заставила бы генератор *gen_opener()* быть полностью потребленным. Поскольку генератор производит последовательность открытых файлов, которые немедленно закрываются на следующем шаге итерации, *chain()* использовать нельзя. Показанное решение позволяет решить эту проблему.

Также в функции *gen_concatenate()* используется *yield from* для делегирования субгенератору. Объявление *yield from it* просто заставляет *gen_concatenate()* выдать все значения, произведенные генератором *it*. Это описано далее, в **рецепте 4.14.**

И последнее: стоит отметить, что «конвейерный» («канальный») подход не работает для всех на свете задач обработки данных. Иногда вам просто необходимо работать со всеми данными сразу. Однако, даже в этом случае, использование каналов генераторов может стать путём логического разбиения задачи. 

Дэвид Бизли подробно написать об этих приёмах в обучающющей презентации [«Трюки с генераторами для системных программистов»](http://www.dabeaz.com/generators). Если вам нужны дополнительные примеры, обратитесь к ней.

## 4.14. Превращение вложенной последовательности в плоскую 
### Задача
У вас есть вложенная последовательность, и вы хотите превратить ее в один плоский список значений.

### Решение
Это легко решается с помощью рекурсивного генератора с инструкцией *yield from*. Например:
```python
from collections import Iterable

def flatten(items, ignore_types=(str, bytes)):
	for x in items:
		if isinstance(x, Iterable) and not isinstance(x, ignore_types):
			yield from flatten(x)
		else:
			yield x

items = [1, 2, [3, 4, [5, 6], 7], 8]

# Produces 1 2 3 4 5 6 7 8
for x in flatten(items):
	print(x)
```

В этой программе *isinstance(x, Iterable)* просто проверяет, является ли элемент итерируемым объектом. Если это так, то *yield from* используется в качестве некой подпрограммы, чтобы выдать все его значения. Конечный результат — одна последовательность без вложенности.

Дополнительный аргументы *ignore_types* и проверка *not isinstance(x, ignore_types)* нужны для предотвращения определения строк и байтов как итерируемых последовательностей, без чего они были бы разбиты на отдельные символы. Это позволяет вложенным спискам строк работать так, как большинство людей этого и ожидают:
```python
>>> items = ['Dave', 'Paula', ['Thomas', 'Lewis']]
>>> for x in flatten(items):
... 	print(x)
...
Dave
Paula
Thomas
Lewis
>>>
```

### Обсуждение
Инструкция *yield from* — отличный способ написания генераторов, которые вызывают другие генераторы в качестве подпроцедуры. Без использования этой инструкции вам придется вставить в код дополнительный цикл. Например:
```python
def flatten(items, ignore_types=(str, bytes)):
	for x in items:
		if isinstance(x, Iterable) and not isinstance(x, ignore_types):
			for i in flatten(x):
				yield i
		else:
			yield x
```

Хотя это незначительное изменение, инструкция *yield from* просто приятнее и делает код чище.

Как было отмечено, дополнительная проверка на строки и байты нужна для предотвращения их разбивки на отдельные символы. Если есть еще какие-то типы, которые вы не хотите раскрывать, вы просто можете передать другие значения в *ignore_types*.

Стоит отметить, что *yield from* играет более важную роль в продвинутых программах, использующих корутины и основанную на генераторах многопоточность. См. другой пример в **рецепте 12.12.**

## 4.15. Последовательное итерирование по слитым отсортированным итерируемым объектам
### Задача
У вас есть коллекция отсортированных последовательностей, и вы хотите проитерировать по отсортированной последовательности этих последовательностей, слитых воедино.

### Решение
Функция *heapq.merge()* делает именно это:
```python
>>> import heapq
>>> a = [1, 4, 7, 10]
>>> b = [2, 5, 6, 11]
>>> for c in heapq.merge(a, b):
...		print(c)
...
1
2
4
5
6
7
10
11
```

### Обсуждение
Итеративная природа *heapq.merge()* подразумевает, что она никогда не читает одну из переданных ей последовательностей сразу до конца. Это значит, что вы можете использовать ее на длинных последовательностях с очень незначительным оверхедом. Вот, например, как вы можете слить воедино два отсортированных файла:
```python
import heapq
with open('sorted_file_1', 'rt') as file1, \
	open('sorted_file_2') 'rt' as file2, \
	open('merged_file', 'wt') as outf:

for line in heapq.merge(file1, file2):
	outf.write(line)
```

Важно отметить, что *heapq.merge()* требует, чтобы все передаваемые ей последовательности уже были отсортированы. Она не читает предварительно данные в кучу, не выполняет предварительную сортировку. Также она не выполняет никакой валидации входных данных на соответствие требованиям упорядоченности. Она просто проверяет набор элементов из «голов» каждой переданной последовательности и выдает минимальный из найденных. Далее читается новый элемент из выбранной последовательности, и процесс повторяется до тех пор, пока все входные последовательности не будут полностью потреблены.

## 4.16. Замена бесконечных циклов while итератором
### Задача
У вас есть код, который использует цикл while для итеративной обработки данных, потому что в программе присутствует функция или какое-то необычное проверочное условие, которое нельзя вместить в стандартный итерационный паттерн. 

### Решение
Вполне обычный код для программ, работающих с вводом-выводом:
```python
CHUNKSIZE = 8192

def reader(s):
	while True:
		data = s.recv(CHUNKSIZE)
		if data == b'':
			break
		process_data(data)
``` 

Такой код часто можно заменить использованием *iter()*, как показано ниже:
```python
def reader(s):
	for chunk in iter(lambda: s.recv(CHUNKSIZE), b''):
		process_data(data)
```

Если вы сомневаетесь, будет ли это работать, вы можете попробовать похожий пример для обработки файлов:
```python
>>> import sys
>>> f = open('/etc/passwd')
>>> for chunk in iter(lambda: f.read(10), ''):
... 	n = sys.stdout.write(chunk)
...
nobody:*:-2:-2:Unprivileged User:/var/empty:/usr/bin/false
root:*:0:0:System Administrator:/var/root:/bin/sh
daemon:*:1:1:System Services:/var/root:/usr/bin/false
_uucp:*:4:4:Unix to Unix Copy Protocol:/var/spool/uucp:/usr/sbin/uucico
...
>>>
```

### Обсуждение
Малоизвестная возможность встроенной функции *iter()* заключается в том, что она может опционально принимать вызываемый (callable) аргумент и «стража» (завершающее значение). При таком использовании функция создает итератор, который снова и снова повторяет вызов предоставленного вызываемого объекта, пока он не вернет значение, равное «стражу».

Этот конкретный подход хорошо работает с некоторыми типами многократно вызываемых функций, таких как операции ввода-вывода. Например, если вы хотите читать данные кусочками (чанками) из файлов или сокетов, вы обычно должны многократно вызывать *read()* или *recv()* с последующей проверкой достижения конца файла. Представленный выше рецепт просто берет эти две функциональности и совмещает в единственном вызове *iter()*. Использование *lambda* в решении необходимо для создания вызываемого объекта, который не принимает аргументов, но при этом поставляет аргумент нужного размера в *recv()* или *read()*.

# 5. Файлы и ввод-вывод
Всем программам нужно производить ввод и вывод. Эта глава покрывает типичные идиомы для работы с различными типами файлов, включая текстовые и бинарные, кодировки файлов и прочие связанные темы. Также тут освещены приёмы манипулирования именами файлов и каталогов.

## 5.1. Чтение и запись текстовых данных
### Решение
Вам нужно прочитать или записать текстовые данные, возможно представленные в различных кодировках, таких как ASCII, UTF-8 или UTF-16.

### Решение
Используйте функцию *open()* в режиме *rt* для чтения текстового файла. Например:
```python
# Read the entire file as a single string
with open('somefile.txt', 'rt') as f:
	data = f.read()

# Iterate over the lines of the file
with open('somefile.txt', 'rt') as f:
	for line in f:
	# process line
	...
``` 

Похожим образом для записи в текстовый файл используйте *open()* в режиме *wt* (стирает и перезаписывает любое предыдущее содержание файла, если оно было):
```python
# Write chunks of text data
with open('somefile.txt', 'wt') as f:
	f.write(text1)
	f.write(text2)
	...

# Redirected print statement
with open('somefile.txt', 'wt') as f:
	print(line1, file=f)
	print(line2, file=f)
	...
```

Чтобы добавить записываемый текст к концу существующего файла, используйте *open()* в режиме *at*.

По умолчанию файлы читаются и записываются в дефолтной системной кодировке, информацию о которой можно получить из *sys.getdefaultencoding()*. На большинстве компьютеров это будет *utf-8*. Если вы знаете, что текст, который вы читаете или пишите, представлен в другой кодировке, передайте необязательный параметр *encoding* функции *open()*. Например:
```python
with open('somefile.txt', 'rt', encoding='latin-1') as f:
	...
``` 

Python понимает несколько сотен текстовых кодировок. Однако самые распространенные — ascii, latin-1, utf-8 и utf-16. utf-8 обычно является безопасным выбором для работы с веб-приложениями. ascii соответствует 7-битным символам в диапазоне от U+0000 до U+007F. latin-1 — это прямое отображение байтов 0-255 на символы Unicode от U-0000 до U-00FF. latin-1 известна тем, что она никогда не вызовет ошибку декодирования при чтении текста в возможно неизвестной кодировке. Чтение файла как latin-1 может не привести к получению полностью правильно декодированного текста, но этого бывает достаточно для извлечения полезных данных. Также, если вы позже запишете данные обратно, первоначальные данные будут сохранены.

### Обсуждение
Чтение и запись файлов в большинстве случаев совершенно прямолинейны. Однако есть и тонкости. Во-первых, использование инструкции *with* в примере устанавливает контекст, в котором будут использованы файлы. Когда поток управления покидает блок *with*, файл будет автоматически закрыт.  Вы не обязаны использовать инструкцию *with*, но если вы ее не применяете, то не забудьте закрыть файл:
```python
f = open('somefile.txt', 'rt')
data = f.read()
f.close()
``` 

Ещё одна небольшая сложность касается распознавания новых строк, символы которых отличаются в Unix и Windows (\\n и \\r\\n). По умолчанию Python работает в так называемом «универсальном режиме новых строк». В этом режиме все распространённые символы новой строки распознаются, и все они конвертируются в единственный \\n при чтении. Похожим образом символ новой строки \\n конверируется в дефолтный системный символ при выводе. Если вы не хотите использовать такую трансляцию, передайте функции *open()* аргумент *newline=''*:
```pytnon
# Read with disabled newline translation
with open('somefile.txt', 'rt', newline='') as f:
	...
```  

Чтобы продемонстрировать разницу, покажем, что вы увидите на компьютере с Unix, если вы читаете содержание файла в Windows-кодировке, в котором присутствуют сырые данные *hello world!\\r\\n*:
```python
Contents of a Windows-encoded text file containing the raw data hello world!\r\n :
>>> # Newline translation enabled (the default)
>>> f = open('hello.txt', 'rt')
>>> f.read()
'hello world!\n'

>>> # Newline translation disabled
>>> g = open('hello.txt', 'rt', newline='')
>>> g.read()
'hello world!\r\n'
>>>
```

Последняя проблема касается возможных ошибок кодировки в текстовых файлах. При чтении или записи текстового файла вы можете натолкнуться на ошибку кодирования или декодирования. Например:
```python
>>> f = open('sample.txt', 'rt', encoding='ascii')
>>> f.read()
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
	File "/usr/local/lib/python3.3/encodings/ascii.py", line 26, in decode
		return codecs.ascii_decode(input, self.errors)[0]
UnicodeDecodeError: 'ascii' codec can't decode byte 0xc3 in position
12: ordinal not in range(128)
>>>
```

Если вы получили эту ошибку, это обычно означает, что вы не используете правильную кодировку для чтения файла. Вы должны внимательно прочитать спецификацию того, что вы пытаетесь прочесть, и удостовериться, что вы делаете это правильно (то есть не читаете данные как UTF-8 вместо Latin-1 и т.п.) Если ошибки кодирования все еще возникают, вы можете передать необязательный аргумент *errors* функции *open()*, чтобы обрабатывать ошибки. Вот несколько примеров типичных схем обработки ошибок:
```python
>>> # Replace bad chars with Unicode U+fffd replacement char
>>> f = open('sample.txt', 'rt', encoding='ascii', errors='replace')
>>> f.read()
'Spicy Jalape?o!'
>>> # Ignore bad chars entirely
>>> g = open('sample.txt', 'rt', encoding='ascii', errors='ignore')
>>> g.read()
'Spicy Jalapeo!'
>>>
```

Если вы постоянно ловите блох с кодировками, аргументами *errors* функции *open()* и изобретаете хаки, вы, вероятно, зря усложняете себе жизнь. Первое правило работы с текстом: убедитесь, что вы используете правильную кодировку. А если сомневаетесь, какую выбрать, используйте системную установку по умолчанию (обычно это UTF-8). 


## 5.2. Перенаправление вывода в файл
### Задача
Вы хотите перенаправить в файл вывод функции *print()*.

### Решение
Используйте *print()* c именованным аргументом *file*:
```python
with open('somefile.txt', 'rt') as f:
	print('Hello World!', file=f)
```

### Обсуждение
Про вывод в файл добавить больше и нечего. Разве что убедитесь, что файл открыт в текстовом режиме. Выводить в бинарном режиме так нельзя.

## 5.3. Вывод с другим разделителем или символом конца строки
### Задача
Вы хотите вывести данные с помощью *print()*, но вы также хотите поменять символ-разделитель или символ конца строки.

### Решение
Используйте именнованые аргументы *sep* и *end* с функцией *print()*, чтобы изменить вывод так, как вам нужно. Например:
```python
>>> print('ACME', 50, 91.5)
ACME 50 91.5
>>> print('ACME', 50, 91.5, sep=',')
ACME,50,91.5
>>> print('ACME', 50, 91.5, sep=',', end='!!\n')
ACME,50,91.5!!
>>>
```

Использование аргумента *end* также позволяет подавить добавление символа новой строки при выводе. Например:
```python
>>> for i in range(5):
...		print(i)
...
0
1
2
3
4
>>> for i in range(5):
...		print(i, end=' ')
...
0 1 2 3 4 >>>
```

### Обсуждение
Использование *print()* с разными разделителями элементов часто является самым простым способом вывести данные, когда вам нужно вывести данные с другим разделителем элементов. Однако иногда вы можете увидеть, как программисты используют *str.join()* для выполнения этой же задачи:
```python
>>> print(','.join('ACME','50','91.5'))
ACME,50,91.5
>>>
```

Проблема *str.join()* в том, что он работает только со строками. Это значит, что часто необходимо выполнить различные акробатические трюки, чтобы заставить его работать. Например:
```python
>>> row = ('ACME', 50, 91.5)
>>> print(','.join(row))
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
TypeError: sequence item 1: expected str instance, int found
>>> print(','.join(str(x) for x in row))
ACME,50,91.5
>>>
```

Вместо этого вы могли бы просто написать так:
```python
>>> print(*row, sep=',')
ACME,50,91.5
>>>
```

## 5.4. Чтение и запись бинарных данных
### Задача 
Вам нужно прочесть или записать бинарные данные, такие как содержание картинок, звуковых файлов и т.п.

### Решение
Используйте функцию *open()* в режиме *rb* или *wb*, чтобы читать и записывать бинарные данные. Например:
```python
# Read the entire file as a single byte string
with open('somefile.bin', 'rb') as f:
	data = f.read()

# Write binary data to a file
with open('somefile.bin', 'wb') as f:
	f.write(b'Hello World')
```

При чтении бинарных данных важно подчеркнуть, что все получаемые данные будут в форме байтовых, а не текстовых строк. Похожим образом, при записи вы должны предоставить данные в форме объектов, которые представляют данные в форме байтов (байтовые строки, объекты *bytearray* и т.д.)

### Обсуждение
При чтении бинарных данных тонкие сематические различия между байтовыми и текстовыми строками могут привести к проблемам. Нужно помнить, что индексирование и итерирование возвращают целочисленное байтовое значение, а не байтовые строки. Например:
```python
>>> # Text string
>>> t = 'Hello World'
>>> t[0]
'H'
>>> for c in t:
...		print(c)
...
H
e
l
l
o
...
>>> # Byte string
>>> b = b'Hello World'
>>> b[0]
72
>>> for c in b:
... 	print(c)
...
72
101
108
108
111
...
>>>
```

Если вам когда-либо потребуется прочесть или записать текст из или в открытый в бинарном режиме файл, убедитесь, что не забыли декодировать или закодировать его. Например:
```python
with open('somefile.bin', 'rb') as f:
	data = f.read(16)
	text = data.decode('utf-8')

with open('somefile.bin', 'wb') as f:
	text = 'Hello World'
	f.write(text.encode('utf-8'))
```

Менее известный аспект бинарного ввода-вывода заключается в том, что такие объекты как массивы и структуры языка C могут быть использованы для записи без какого-либо промежуточного преобразования в объект *bytes*. Например:
```python
import array
nums = array.array('i', [1, 2, 3, 4])
with open('data.bin','wb') as f:
	f.write(nums)
```

Это применимо к любому объекту, в котором реализован так называемый «буферный интерфейс», который напрямую дает доступ к собственному буферу памяти операциям, которые могут с ним работать. Запись бинарных данных — одна из таких операций.

Многие объекты также позволяют бинарным данным напрямую быть прочитанными в их память с помощью файлового метода *readinto()*. Например:
```python
>>> import array
>>> a = array.array('i', [0, 0, 0, 0, 0, 0, 0, 0])
>>> with open('data.bin', 'rb') as f:
... 	f.readinto(a)
...
16
>>> a
array('i', [1, 2, 3, 4, 0, 0, 0, 0])
>>>
```

Однако нужно принять все меры предосторожности при использовании этого приёма, поскольку он часто является платформозависимым и зависит от таких вещей как размер слова, порядок следования байтов (big-endian или little-endian). См. рецепт *5.9.* для другого примера чтения бинарных данных в изменяемый (mutable) буфер.

## 5.5. Запись в файл, которого ещё нет
### Задача
Вы хотите записать данные в файл, но только в том случае, если его ещё нет в файловой системе.

### Решение
Эта задача легко решается с помощью использования малоизвестного режима *x* работы *open()* (вместо обычного режима *w*):
```python
>>> with open('somefile', 'wt') as f:
...		f.write('Hello\n')
...
>>> with open('somefile', 'xt') as f:
...		f.write('Hello\n')
...
Traceback (most recent call last):
	File "<stdin>", line 1, in <module>
FileExistsError: [Errno 17] File exists: 'somefile'
>>>
```

Если файл в бинарном режиме, используйте режим *xb* вместо *xt*.

### Обсуждение
Этот рецепт демонстрирует удивительно элегантное решение задачи, иногда возникающей при записи в файлы (например, случайной перезаписи существующего файла). Альтернативное решение — предварительная проверка:
```python
>>> import os
>>> if not os.path.exists('somefile'):
... 	with open('somefile', 'wt') as f:
...			f.write('Hello\n')
... else:
...		print('File already exists!')
...
... File already exists!
>>>
```

Очевидно, что использование режима *x* намного более прямолинейно. Важно отметить, что режим *x* доступен для функции *open()* только в Python 3. Этот режим не существовал в ранних версиях Python или низкоуровневневых библиотеках на языке C, использованных в реализации Python.

## 5.6. Выполнение операций ввода-вывода над строками
### Задача
Вы хотите скормить текст или бинарную строку программе, которая способна работать с файлоподобными объектами.

### Решение
Используйте классы *io.StringIO()* и *io.BytesIO()* для создания файлоподобных объектов, которые могут работать со строковыми данными. Например:
```python
>>> s = io.StringIO()
>>> s.write('Hello World\n')
12
>>> print('This is a test', file=s)
15
>>> # Get all of the data written so far
>>> s.getvalue()
'Hello World\nThis is a test\n'
>>>

>>> # Wrap a file interface around an existing string
>>> s = io.StringIO('Hello\nWorld\n')
>>> s.read(4)
'Hell'
>>> s.read()
'o\nWorld\n'
>>>
```  

Класс *io.StringIO* должен быть использован только для работы с текстом. Если вы работаете с бинарными данными, используйте *io.BytesIO*. Например:
```python
>>> s = io.BytesIO()
>>> s.write(b'binary data')
>>> s.getvalue()
b'binary data'
>>>
``` 

### Обсуждение
Классы *StringIO* и *BytesIO* наиболее полезны в случаях, когда вам нужно подменить обычный файл. Например, в юнит-тестах вы могли бы использовать *StringIO* для создания файлоподобного объекта, содержащего тестовые данные, которые скармливаются функции, которая приспособлена для работы с файлами.

Обратите внимание, что экземпляры *StringIO* и *BytesIO* не имеют настоящего целочисленного файлового дескриптора. Поэтому они будут работать с программами, которые требуют использования настоящих системных файлов (файлов, каналов, сокетов).

## 5.7. Чтение и запись сжатых файлов с данными
### Задача
Вам нужно прочесть или записать данные в файл, сжатый gzip или bz2.

### Решение
Модули *gzip* и *bz2* делают работу с такими файлами очень лёгкой. Оба модуля предоставляют альтернативную реализацию функции *open()*, которые могут быть использованы для этой цели. Например, чтобы прочесть сжатые файлы как текст, сделайте так:
```python
# gzip compression
import gzip
with gzip.open('somefile.gz', 'rt') as f:
	text = f.read()

# bz2 compression
import bz2
with bz2.open('somefile.bz2', 'rt') as f:
	text = f.read()
```

Как показано выше, весь ввод и вывод будет использовать текст и проводить кодирование/декодирование в Unicode. Если же вы хотите работать с бинарными данными, используйте файловые режимы *rb* или *wb*. 

### Обсуждение
Чтение и запись сжатых данных по большей части просты. Однако стоит знать, что выбор правильного файлового режима критически важен. Если вы не обозначите режим явно, то будет выбран режим по умолчанию, то есть бинарный, а это сломает программы, которые ожидают получить текст. *gzip.open()* и *bz2.open()* принимают те же параметры, что и встроенная функция *open()*, включая *encoding*, *errors*, *newline* и т.д.

При записи сжатных данных с помощью необязательного именованного аргумента *compresslevel* может быть установлен уровень компрессии. Например:
```python
with gzip.open('somefile.gz', 'wt', compresslevel=5) as f:
	f.write(text)
```

Уровень по умолчанию — это 9, то есть наивысший. Более низкие уровни увеличивают скорость, но снижают степень сжатия данных.

И последнее: малоизвестная особенность *gzip.open()* и *bz2.open()* заключается в том, что они могут работать уровнем выше существующего файла, открытого в бинарном режиме. Например, такой код работает:
```
import 

f = open('somefile.gz', 'rb')
with gzip.open(f, 'rt') as g:
	text = g.read()
```

Это позволяет модулям *gzip* и *bz2* работать с различными файлоподобными объектами, такими как сокеты, каналы и файлы в оперативной памяти.

## 5.8. Итерирование по записям фиксированного размера
### Задача
Вместо того, чтобы итерировать по файлу построчно, вы хотите итерировать по коллекции записей фиксированного размера или кусочкам (чанкам).

### Решение
Используйте функции *iter()* и *functools.partial()*, чтобы выполнить этот клёвый фокус:
```python
from functools import partial

RECORD_SIZE = 32

with open('somefile.data', 'rb') as f:
	records = iter(partial(f.read, RECORD_SIZE), b'')
	for r in records:
		...
```

Объект *records* в этом примере является итерируемым; он будет производить кусочки (чанки) фиксированного размера, пока не будет достигнут конец файла. Однако стоит отметить, что в последнем элементе может быть на несколько байтов меньше, чем ожидается, если размер файла не делится на точную длину размера записи.

### Обсуждение
Малоизвестная возможность функции *iter()* заключается в том, что она може создать итератор, если вы передадите ей вызываемый объект и «значение-страж» (пороговое). Получившийся итератор просто снова и снова вызывает предоставленный вызываемый объект, пока он не вернет значение-страж, что приведёт к завершению итерирования.

В вышеприведённом решении *functools.partial* используется для создания вызываемого объекта, который читает фиксированное количествт байтов из файла каждый раз, когда вызывается. Страж *b''* — то, что будет возвращено при попытке чтения файла, когда будет достигнут его конец.

И последнее: в показанном выше решении файл был открыт в бинарном режиме. Для чтений записей фиксированного размера это является наиболее распространенным случаем. В случае же текстовых файлов более распространенным будет построчное чтение (итератор выполняет его по умолчанию). 

## 5.9. Чтение бинарных данных в изменяемый (мутабельный) буфер
### Задача
Вы хотите читать бинарные данные непосредственно в изменяемый буфер без какого-либо промежуточного копирования. Возможно, вы хотите изменить данные на месте и записать их обратно в файл.

### Решение
Чтобы прочесть данные в изменяемый массив, используйте файловый метод *readinto()*. Например:
```python
import os.path

def read_into_buffer(filename):
	buf = bytearray(os.path.getsize(filename))
	with open(filename, 'rb') as f:
		f.readinto(buf)
	return buf
```

Вот пример использования:
```python
>>> # Write a sample file
>>> with open('sample.bin', 'wb') as f:
...		f.write(b'Hello World')
...
>>> buf = read_into_buffer('sample.bin')
>>> buf
bytearray(b'Hello World')
>>> buf[0:5] = b'Hallo'
>>> buf
bytearray(b'Hallo World')
>>> with open('newsample.bin', 'wb') as f:
...		f.write(buf)
...
11
>>>
```

### Обсуждение
Метод *readinto()* может быть использован для заполнения данными любого предварительно выделенного (preallocated) массива. Это даже включает массивы, созданные с помощью модуля *array* или библиотек типа *numpy*. В отличие от обычного метода *read()*, метод *readinto()* заполняет содержание текущего буфера вместо выделения и возвращения новых объектов. Так что вы можете использовать его, чтобы избежать излишних выделений памяти. Например, если вы читаете бинарный файл, состоящий из записей одинакового размера, вы можете написать такую программу:
```python
record_size = 32 	# Size of each record (adjust value)

buf = bytearray(record_size)
with open('somefile', 'rb') as f:
	while True:
		n = f.readinto(buf)
		if n < record_size:
			break
		# Use the contents of buf
		...
``` 

Ещё одна интересная возможность — функция memoryview(), которая позволяет делать срезы [zero-copy](https://ru.wikipedia.org/wiki/Zero-copy) существующего буфера, и даже менять его содержимое. Например:
```python
>>> buf
bytearray(b'Hello World')
>>> m1 = memoryview(buf)
>>> m2 = m1[-5:]
>>> m2
<memory at 0x100681390>
>>> m2[:] = b'WORLD'
>>> buf
bytearray(b'Hello WORLD')
>>>
```

При использовании метода *f.readinto()* нужно соблюдать осторожность: вы должны всегда проверять его код возврата, который является количеством фактически прочтённых байтов.

Если число байтов меньше размера предоставленного буфера, это может указывать на повреждение данных (например, если вы ожидали, что будет прочитано точное количество байтов).

И последнее: посмотрите на другие функции типа “into” в различных библиотечных модулях (например, *recv_into()*, *pack_into()* и т.д.) Многие другие компоненты Python имеют поддержку прямого ввода-вывода и доступа к данным, которая может быть использована для заполнения или изменения содержания массивов и буферов. 

См. **рецепт 6.12.** для значительно более продвинутого примера интерпретации бинарных структур и использования просмотрщиков памяти (memoryviews). 

## 5.10. Отображаемые в память бинарные файлы
### Задача
Вы хотите отобразить в память бинарный файл в форме изменяемого массива байтов — вероятно, для произвольного доступа к его содержимому или изменений прямо на месте.

### Решение
Используйте модуль *mmap* для отображения файлов в память. Вот полезная функция, с помощью которой можно открыть файл и отобразить его в память переносимым способом:
```python
import os
import mmap

def memory_map(filename, access=mmap.ACCESS_WRITE):
	size = os.path.getsize(filename)
	fd = os.open(filename, os.O_RDWR)
	return mmap.mmap(fd, size, access=access)
```

Чтобы использовать эту функцию, вам нужен уже созданный и наполненный данными файл. Вот пример того, как вы можете сначала создать файл и увеличить его до нужного размера:
```python
>>> size = 1000000
>>> with open('data', 'wb') as f:
...		f.seek(size-1)
...		f.write(b'\x00')
...
>>>
```

А вот пример отображения содержимого в память с помощью функции *memory_map()*:
```python
>>> m = memory_map('data')
>>> len(m)
1000000
>>> m[0:10]
b'\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00'
>>> m[0]
0
>>> # Reassign a slice
>>> m[0:11] = b'Hello World'
>>> m.close()

>>> # Verify that changes were made
>>> with open('data', 'rb') as f:
... 	print(f.read(11))
...
b'Hello World'
>>>
``` 

Объект *mmap*, возвращаемый функцией *mmap()*, может быть также использован в качестве менеджера контекста. В это случае отображенный файл закрывается автоматически. Например:
```python
>>> with memory_map('data') as m:
... 	print(len(m))
...		print(m[0:10])
...
1000000
b'Hello World'
>>> m.closed
True
>>>
```

По умолчанию показанная функция *memory_map()* открывает файл и на чтение, и на запись. Любые изменения данных копируются в исходный файл. Если требуется организовать доступ только для чтения, предоставьте *mmap.ACCESS_READ* в качестве аргумента *access*. Например:
```python
m = memory_map(filename, mmap.ACCESS_READ)
```  

Если вы намерены локально изменять данные, но не хотите, чтобы изменения записывались в исходный файл, используйте *mmap.ACCESS_COPY*:
```python
m = memory_map(filename, mmap.ACCESS_COPY)
```

### Обсуждение
Использование *mmap* для отображения файлов в память может элегантным и эффективным решением для произвольного доступа к содержимому файла. Например, вместо открытия файла и выполнения различных комбинаций вызовов *seek()*, *read()* и *write()*, вы просто отображаете файл и получаете доступ к любым данным через операции извлечения срезов.

Обычно память, выделяемая *mmap()*, выглядить как объект *bytearray*. Однако вы можете интерпретировать данные по-разному, используя функцию *memoryview*. Например:
```python
>>> m = memory_map('data')
>>> # Memoryview of unsigned integers
>>> v = memoryview(m).cast('I')
>>> v[0] = 7
>>> m[0:4]
b'\x07\x00\x00\x00'
>>> m[0:4] = b'\x07\x01\x00\x00'
>>> v[0]
263
>>>
```

Стоит отметить, что отображение файла в память не вызывает чтения файла в память целиком. Он не копируется в некий буфер памяти или массив. Вместо этого операционная система выделяет участок виртуальной памяти под содержимое файла. По мере того, как вы обращаетесь к различным участкам, эти куски файла будут читаться и отображаться в участок памяти по мере необходимости. Однако части файла, к которым никогда не производился доступ, останутся на диске.

Если более чем один интерпретатор Python отображает в память один и тот же файл, получившийся объект *mmap* может быть использован для обмена данными между интерпретаторами. Интерпретаторы могут читать и записывать данные одновременно, и изменения, которые были сделаны в одном интерпретаторе, автоматически будут доступны в других. Очевидно, что синхронизация требует дополнительного внимания, но этот подход иногда используется в качестве альтернативы передаче данных через каналы или сокеты. 

Показанный выше рецепт написан максимально обобщённо, он работает и в Windows, и в Unix. Однако стоит отметить, что есть специфические для каждой платформы отличия в том, как работает *mmap()* «под капотом». Также есть возможности по созданию анонимно отображенных участков памяти. Если вас это интересует, прочтите [соответствующую документацию](http://docs.python.org/3/library/mmap.html) Python.
 

